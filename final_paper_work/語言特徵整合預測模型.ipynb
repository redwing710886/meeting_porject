{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#函式庫引入\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from collections import OrderedDict,defaultdict,Counter\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV \n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output,Image\n",
    "from sklearn.externals import joblib\n",
    "import pydotplus \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#輸入資料\n",
    "\n",
    "classification_name = ['雷震','殷海光','夏道平','傅正','龍平甫','蔣勻田','朱伴耘','胡適','羅鴻詔']\n",
    "classification_topic = ['社論','文章','日記']\n",
    "\n",
    "\n",
    "#建立作者索引，提取各作者文章內容及索引\n",
    "author_index = []\n",
    "for index,name in enumerate(classification_name): #建立作者索引\n",
    "    author_index.append((name,index))\n",
    "author_index = OrderedDict(author_index) #作者索引排序(依文本數量高到低)\n",
    "\n",
    "topic_index = []\n",
    "for index,name in enumerate(classification_topic): #建立作者索引\n",
    "    topic_index.append((name,index))\n",
    "topic_index = OrderedDict(topic_index) #作者索引排序(依文本數量高到低)\n",
    "\n",
    "class_path1 = 'C:\\\\Users\\\\user\\\\Desktop\\\\雙類別\\\\'\n",
    "class_path2 = 'C:\\\\Users\\\\user\\\\Desktop\\\\多類別\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_input(find):\n",
    "    temp_path = ''\n",
    "    if '多' in find:\n",
    "        temp_path = class_path2\n",
    "    elif '雙' in find:\n",
    "        temp_path = class_path1\n",
    "        \n",
    "    type_base = ''    \n",
    "    if 'FC' in find:\n",
    "        type_base = 'FC'\n",
    "    elif 'lei' in find:\n",
    "        type_base = 'lei'\n",
    "        \n",
    "    document_name = ''\n",
    "    feature_name = ''\n",
    "    \n",
    "    for file in os.listdir(temp_path):\n",
    "        if type_base in file:\n",
    "            if 'txt' in file:\n",
    "                feature_name = file\n",
    "            elif 'csv' in file:\n",
    "                document_name = file\n",
    "    \n",
    "    feature = []\n",
    "    with codecs.open(temp_path+feature_name,'rb','utf8') as f:\n",
    "        content = f.readlines()\n",
    "        \n",
    "        for line in content:\n",
    "            if line.strip() == '' or line[0] == '#':\n",
    "                continue\n",
    "            else:\n",
    "                feature.append(line.strip().split()[0])\n",
    "                \n",
    "    X = []\n",
    "    y = []\n",
    "    with codecs.open(temp_path+document_name,'rb','utf8') as f:\n",
    "        content = f.readlines()\n",
    "        \n",
    "        for line in content:\n",
    "            line = line.strip().split(',')\n",
    "            y.append(int(line[0]))\n",
    "            X.append([int(i) for i in list(map(float,line[1:]))])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return feature,X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#預測模型建立\n",
    "def predict_model(X,y,model):\n",
    "    \n",
    "    kernel = ''\n",
    "    \n",
    "    if model == 'RF':\n",
    "        kernel = RandomForestClassifier(n_jobs=-1, oob_score=True,\\\n",
    "                                        class_weight = 'balanced',n_estimators=256,random_state=0,min_samples_leaf=2)\n",
    "    elif model == 'SVM':\n",
    "        kernel = svm.LinearSVC(class_weight='balanced',random_state=0)\n",
    "    elif model == 'DT':\n",
    "        kernel = DecisionTreeClassifier(class_weight='balanced',random_state=0)\n",
    "    elif model == 'GNB':\n",
    "        kernel = GaussianNB()\n",
    "    elif model == 'MNB':\n",
    "        kernel = MultinomialNB()\n",
    "    elif model == 'BNB':\n",
    "        kernel = BernoulliNB()\n",
    "    else:\n",
    "        print ('model error')\n",
    "        return\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    clf = kernel\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print ('訓練耗費時間：',end-start,'秒')\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#輸出介面\n",
    "def main(find):\n",
    "    \n",
    "    feature,X,y = find_input(find)\n",
    "    \n",
    "    test_size = 0.2\n",
    "    kernel = 'RF' #DT/RF/SVM\n",
    "    threshold = 0.5\n",
    "    \n",
    "    def sparsity_ratio(X):\n",
    "        return 1.0 - np.count_nonzero(X) / float(X.shape[0] * X.shape[1])\n",
    "    print(\"輸入稀疏比:\", sparsity_ratio(X))\n",
    "\n",
    "    model = predict_model(X,y,kernel)\n",
    "    \n",
    "    print ('oob error rate:',1-model.oob_score_)\n",
    "    \n",
    "    #for i in sorted([i for i in zip(feature,model.feature_importances_)],key=lambda t: t[1],reverse=True):\n",
    "    #    print (i[0],i[1])\n",
    "    \n",
    "    #joblib.dump(model, 'C:\\\\Users\\\\user\\\\Desktop\\\\RF result\\\\model\\\\'+find+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC 多\n",
      "輸入稀疏比: 0.8552102481617647\n",
      "訓練耗費時間： 0.5382041931152344 秒\n",
      "oob error rate: 0.297794117647\n",
      "\n",
      "lei 多\n",
      "輸入稀疏比: 0.7468098958333333\n",
      "訓練耗費時間： 0.537996768951416 秒\n",
      "oob error rate: 0.141666666667\n",
      "\n",
      "FC 雙\n",
      "輸入稀疏比: 0.8478529411764706\n",
      "訓練耗費時間： 0.5504236221313477 秒\n",
      "oob error rate: 0.419117647059\n",
      "\n",
      "lei 雙\n",
      "輸入稀疏比: 0.7388227513227513\n",
      "訓練耗費時間： 0.5236775875091553 秒\n",
      "oob error rate: 0.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = ['多','雙']\n",
    "base_type = ['FC','lei']\n",
    "\n",
    "for i in model_type:\n",
    "    for j in base_type:\n",
    "            print (j+' '+i)\n",
    "            main(j+' '+i)\n",
    "            print ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
