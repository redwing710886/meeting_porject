{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "from collections import OrderedDict,defaultdict,Counter\n",
    "import time\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "from itertools import permutations\n",
    "\n",
    "input_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\RF result\\\\顯著特徵尋找\\\\特徵值\\\\'\n",
    "vector_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\RF result\\\\vector\\\\'\n",
    "FC_feature_path = \"D:\\\\課業相關\\\\論文資料\\\\論文程式\\\\language_feature\\\\最終版\\\\自由中國\\\\\" #自由中國語言特徵\n",
    "lei_feature_path = \"D:\\\\課業相關\\\\論文資料\\\\論文程式\\\\language_feature\\\\最終版\\\\雷震文本\\\\\" #雷震文本語言特徵\n",
    "condicate_author_path = \"D:\\\\課業相關\\\\論文資料\\\\論文程式\\\\condicate\\\\author\\\\\" #候選作者文本\n",
    "condicate_topic_path = \"D:\\\\課業相關\\\\論文資料\\\\論文程式\\\\condicate\\\\topic\\\\\" #候選主題文本\n",
    "\n",
    "classification_name = ['雷震','殷海光','夏道平','傅正','龍平甫','蔣勻田','朱伴耘','胡適','羅鴻詔']\n",
    "classification_topic = ['社論','文章','日記']\n",
    "feature_condicate = ['高頻','bigram','trigram','標點','N+N','N+V','VH+N','D+V','否定','程度','情態']\n",
    "\n",
    "\n",
    "#建立作者索引，提取各作者文章內容及索引\n",
    "author_index = []\n",
    "for index,name in enumerate(classification_name): #建立作者索引\n",
    "    author_index.append((name,index))\n",
    "author_index = OrderedDict(author_index) #作者索引排序(依文本數量高到低)\n",
    "\n",
    "topic_index = []\n",
    "for index,name in enumerate(classification_topic): #建立作者索引\n",
    "    topic_index.append((name,index))\n",
    "topic_index = OrderedDict(topic_index) #作者索引排序(依文本數量高到低)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#輸入介面\n",
    "def find_input(find):\n",
    "    \n",
    "    feature_file_path = '' #符合尋找的特徵檔案路徑\n",
    "    feature_file_name = '' #符合尋找的特徵檔案名稱\n",
    "    condicate_path = '' #候選類別路徑\n",
    "    condicate_label = '' #候選類別名稱\n",
    "    condicate_index = '' #候選類別索引\n",
    "\n",
    "    temp = find.split()\n",
    "    \n",
    "    if len(temp) != 3:\n",
    "        print ('請輸入正確值')\n",
    "        return False\n",
    "    \n",
    "    if temp[0] == 'SC':\n",
    "        feature_file_path = SC_feature_path\n",
    "    elif temp[0] == 'FC':\n",
    "        feature_file_path = FC_feature_path\n",
    "    elif temp[0] == 'lei':\n",
    "        feature_file_path = lei_feature_path\n",
    "    else:\n",
    "        print ('母體選項不符合')\n",
    "        return False\n",
    "    \n",
    "    feature_file_name = [file for file in os.listdir(feature_file_path) if temp[1] in file]\n",
    "    if len(feature_file_name) == 0:\n",
    "        print ('輸入的語言特徵不在範圍內')\n",
    "        return False\n",
    "    feature_file_name = feature_file_name[0]\n",
    "\n",
    "    if temp[2] == 'name':\n",
    "        condicate_path = condicate_author_path\n",
    "        condicate_label = classification_name\n",
    "        condicate_index = author_index\n",
    "    elif temp[2] == 'topic':\n",
    "        condicate_path = condicate_topic_path\n",
    "        condicate_label = classification_topic\n",
    "        condicate_index = topic_index\n",
    "    else:\n",
    "        print ('領域選項不符合')\n",
    "        return False\n",
    "        \n",
    "    return feature_file_path+feature_file_name,condicate_path,condicate_label,condicate_index\n",
    "\n",
    "#抓取候選文本，並根據特徵轉換成文本向量\n",
    "\n",
    "#抓取候選文本，回傳文章序列及各文章類別代號\n",
    "def article_get(condicate_path,condicate_label):\n",
    "\n",
    "    content_list = defaultdict(list) #所有作者文本內容(未處理)\n",
    "    \n",
    "    for label in condicate_label:\n",
    "        for file in os.listdir(condicate_path):\n",
    "            with codecs.open(condicate_path+file,'rb','utf8') as f:\n",
    "\n",
    "                if label not in file.split('_')[0]:\n",
    "                    continue\n",
    "\n",
    "                title = f.readline()\n",
    "                content = f.readline().strip()\n",
    "\n",
    "                content_list[label].append(content)\n",
    "        \n",
    "    return content_list\n",
    "\n",
    "#選擇語言特徵，回傳文本向量詞組\n",
    "def feature_select(feature_file_path):\n",
    "    \n",
    "    feature_dict = {} #特徵\n",
    "    feature = []\n",
    "    with codecs.open(feature_file_path,'rb','utf8') as ff: #抓取基準特徵\n",
    "        count = 0\n",
    "        for i in ff.readlines():\n",
    "            if '\\ufeff' in i: #去掉開頭BOM\n",
    "                i = i.replace('\\ufeff','')\n",
    "            if i.strip() != '':\n",
    "                feature.append(i.strip().split(',')[0])\n",
    "                feature_dict[i.strip().split(',')[0]] = count\n",
    "                count += 1\n",
    "                \n",
    "    return feature,feature_dict\n",
    "\n",
    "#建立文本向量\n",
    "def article_vector(X_raw,feature,feature_file_name):\n",
    "    \n",
    "    bi_pos_combine = ['N+N','N+V','VH+N','D+V','情態']\n",
    "    more_pos_combine = ['否定','程度']\n",
    "    \n",
    "    def line_vec(line): #將文章轉換為特徵向量並回傳\n",
    "        temp_feature = defaultdict(int)\n",
    "        \n",
    "        if any(word in feature_file_name for word in bi_pos_combine): #詞性組合\n",
    "            line = [line[i]+line[i+1] for i in range(len(line)-1)] \n",
    "        elif any(word in feature_file_name for word in more_pos_combine): #2~3詞性組合\n",
    "            line = [line[i]+line[i+1] for i in range(len(line)-1)] + [line[i]+line[i+1]+line[i+2] for i in range(len(line)-2)]\n",
    "        else: #其他常用語言特徵\n",
    "            if 'bigram' in feature_file_name:\n",
    "                line = [line[i].split('(')[0]+line[i+1].split('(')[0] for i in range(len(line)-1)]\n",
    "            elif 'trigram' in feature_file_name:\n",
    "                line = [line[i].split('(')[0]+line[i+1].split('(')[0]+line[i+2].split('(')[0] for i in range(len(line)-2)]\n",
    "            else:\n",
    "                line = [line[i].split('(')[0] for i in range(len(line))]\n",
    "            \n",
    "        for i in line:\n",
    "            if i in feature:\n",
    "                temp_feature[i] += 1\n",
    "        \n",
    "        return temp_feature \n",
    "    \n",
    "    vector_space = np.zeros((len(X_raw),len(feature)),np.float64)\n",
    "    \n",
    "    all_line = 0\n",
    "        \n",
    "    for index,element in enumerate(X_raw): #依序將文章轉換為特徵向量\n",
    "        line = element.strip().split()\n",
    "        temp_feature = line_vec(line)\n",
    "\n",
    "        for i,j in enumerate(feature):\n",
    "            #vector_space[index, i] = round(temp_feature[j] * 1000000 / len(line)) #取相對頻率\n",
    "            vector_space[index, i] += temp_feature[j]\n",
    "            \n",
    "        all_line += len(line)\n",
    "            \n",
    "    vector_space = np.sum(vector_space,axis=0) * 1000000 / all_line\n",
    "    vector_space = [int(round(i)) for i in vector_space]\n",
    "            \n",
    "    return vector_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC D+V name\n",
      "FC N+N name\n",
      "FC N+V name\n",
      "FC VH+N name\n",
      "FC 否定 name\n",
      "FC 情態 name\n",
      "FC 程度 name\n",
      "lei D+V topic\n",
      "lei N+N topic\n",
      "lei N+V topic\n",
      "lei VH+N topic\n",
      "lei 否定 topic\n",
      "lei 情態 topic\n",
      "lei 程度 topic\n",
      "one: 276\n",
      "more: 127\n",
      "error: 30\n",
      "\n",
      "雷震\n",
      "-: 1\n",
      "最(Dfa)重要(VH) 2.979\n",
      "\n",
      "\n",
      "殷海光\n",
      "-: 17\n",
      "反共(VH)者(Na) 9.098\n",
      "\n",
      "極權(Na)統治(VC) 8.296\n",
      "\n",
      "極(Dfa)少數(Neqa) 6.312\n",
      "\n",
      "是(SHI)反共(VH) 5.943\n",
      "\n",
      "政治(Na)權力(Na) 5.677\n",
      "\n",
      "+-: 7\n",
      "可(D)言(VE) 7.395 ['-', '0', '-', '+', '-', '-', '-', '-', '-'] [142, 211, 14, 242, 9, 83, 163, 0, 48] \n",
      "['-', '0', '-', '-', '-', '-', '-', '-', '-'] [0.276, 0.481, 0.026, 0.2, 0.049, 0.258, 0.448, 0.0, 0.148]\n",
      "\n",
      "不(D)夠(VH) 2.72 ['-', '0', '-', '-', '-', '-', '-', '+', '-'] [47, 100, 42, 0, 14, 25, 69, 118, 72] \n",
      "['-', '0', '-', '-', '-', '-', '+', '-', '-'] [0.103, 0.259, 0.053, 0.0, 0.073, 0.065, 0.276, 0.2, 0.148]\n",
      "\n",
      "很(Dfa)有(V_2) 2.516 ['-', '0', '-', '-', '-', '-', '-', '+', '-'] [16, 67, 56, 0, 27, 8, 6, 78, 0] \n",
      "['-', '0', '-', '-', '-', '-', '-', '-', '-'] [0.034, 0.185, 0.105, 0.0, 0.146, 0.032, 0.034, 0.167, 0.0]\n",
      "\n",
      "大陸(Nc)淪陷(VH) 2.391 ['-', '0', '-', '+', '-', '-', '-', '-', '-'] [16, 44, 14, 66, 0, 0, 13, 13, 0] \n",
      "['-', '0', '-', '-', '-', '-', '-', '-', '-'] [0.034, 0.148, 0.026, 0.05, 0.0, 0.0, 0.034, 0.033, 0.0]\n",
      "\n",
      "是(SHI)想(VE) 2.308 ['-', '0', '+', '-', '-', '-', '-', '-', '-'] [0, 55, 69, 0, 9, 0, 31, 26, 8] \n",
      "['-', '0', '-', '-', '-', '-', '-', '-', '-'] [0.0, 0.185, 0.132, 0.0, 0.049, 0.0, 0.138, 0.067, 0.037]\n",
      "\n",
      "\n",
      "夏道平\n",
      "-: 4\n",
      "大(VH)大地(Na) 4.722\n",
      "\n",
      "總統(Na)連任(VG) 3.409\n",
      "\n",
      "讀者(Na)投書(VC) 3.335\n",
      "\n",
      "來(D)看(VC) 3.098\n",
      "\n",
      "\n",
      "傅正\n",
      "-: 11\n",
      "行政(Na)改革(VC) 8.639\n",
      "\n",
      "所(D)知(VK) 7.093\n",
      "\n",
      "地方(Na)選(VC) 5.758\n",
      "\n",
      "地方(Na)自治(VA) 4.523\n",
      "\n",
      "立法院(Nc)提出(VC) 3.814\n",
      "\n",
      "+-: 1\n",
      "要(D)做到(VE) 2.099 ['-', '-', '+', '0', '-', '-', '-', '-', '-'] [16, 0, 83, 66, 0, 0, 19, 52, 32] \n",
      "['-', '-', '-', '0', '-', '-', '-', '-', '-'] [0.034, 0.0, 0.132, 0.15, 0.0, 0.0, 0.103, 0.133, 0.111]\n",
      "\n",
      "\n",
      "龍平甫\n",
      "-: 19\n",
      "內閣(Na)總理(Na) 9.808\n",
      "\n",
      "不(D)滿意(VK) 7.59\n",
      "\n",
      "歐洲(Nc)聯防(VH) 6.331\n",
      "\n",
      "西方(Ncd)國家(Na) 5.936\n",
      "\n",
      "自由(VH)選舉(Na) 5.6\n",
      "\n",
      "+-: 1\n",
      "中立(VH)主義(Na) 9.235 ['-', '-', '+', '-', '0', '+', '-', '-', '-'] [0, 0, 653, 0, 100, 166, 19, 13, 0] \n",
      "['-', '-', '-', '-', '0', '-', '-', '-', '-'] [0.0, 0.0, 0.026, 0.0, 0.341, 0.032, 0.069, 0.033, 0.0]\n",
      "\n",
      "\n",
      "蔣勻田\n",
      "-: 16\n",
      "一段(Nc)話(Na) 10.539\n",
      "\n",
      "可以(D)看出(VE) 5.962\n",
      "\n",
      "艾森豪(Nb)總統(Na) 5.051\n",
      "\n",
      "無(VJ)人(Na) 4.489\n",
      "\n",
      "自由(VH)意志(Na) 4.353\n",
      "\n",
      "+-: 3\n",
      "中國(Nc)大陸(Nc) 8.4 ['-', '-', '-', '+', '-', '0', '-', '-', '-'] [0, 44, 56, 264, 45, 208, 44, 78, 8] \n",
      "['-', '-', '-', '-', '-', '0', '-', '-', '-'] [0.0, 0.111, 0.079, 0.1, 0.122, 0.452, 0.138, 0.1, 0.037]\n",
      "\n",
      "自由(VH)民主(Na) 2.379 ['+', '+', '-', '+', '-', '0', '-', '+', '-'] [63, 421, 0, 110, 14, 42, 19, 78, 0] \n",
      "['-', '-', '-', '-', '-', '0', '-', '-', '-'] [0.069, 0.074, 0.0, 0.1, 0.049, 0.129, 0.103, 0.1, 0.0]\n",
      "\n",
      "更(D)可(D) 2.203 ['+', '-', '-', '-', '-', '0', '-', '-', '-'] [79, 11, 14, 22, 9, 67, 6, 13, 0] \n",
      "['-', '-', '-', '-', '-', '0', '-', '-', '-'] [0.138, 0.037, 0.026, 0.05, 0.049, 0.194, 0.034, 0.033, 0.0]\n",
      "\n",
      "\n",
      "朱伴耘\n",
      "-: 24\n",
      "要(D)想(VE) 15.941\n",
      "\n",
      "很(Dfa)明顯(VH)的(DE) 11.617\n",
      "\n",
      "要(D)想(VE) 11.113\n",
      "\n",
      "美(Nc)蘇(Nc) 8.262\n",
      "\n",
      "是(SHI)無(VJ) 7.974\n",
      "\n",
      "+-: 6\n",
      "人民(Na)服務(VC) 7.328 ['-', '-', '-', '+', '-', '-', '0', '-', '-'] [0, 0, 0, 176, 0, 8, 57, 0, 0] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.0, 0.0, 0.0, 0.05, 0.0, 0.032, 0.276, 0.0, 0.0]\n",
      "\n",
      "姿態(Na)出現(VH) 3.292 ['-', '-', '-', '+', '-', '-', '0', '-', '-'] [0, 22, 0, 44, 5, 0, 38, 0, 0] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.0, 0.037, 0.0, 0.1, 0.024, 0.0, 0.172, 0.0, 0.0]\n",
      "\n",
      "都(D)知道(VK) 3.152 ['-', '-', '-', '+', '-', '-', '0', '-', '-'] [31, 33, 69, 154, 0, 8, 126, 39, 48] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.069, 0.111, 0.105, 0.35, 0.0, 0.032, 0.483, 0.1, 0.185]\n",
      "\n",
      "是(SHI)希望(VK) 2.869 ['-', '-', '+', '+', '-', '-', '0', '+', '-'] [0, 0, 69, 66, 0, 0, 50, 52, 0] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.0, 0.0, 0.105, 0.1, 0.0, 0.0, 0.276, 0.133, 0.0]\n",
      "\n",
      "是(SHI)毫無(VJ) 2.293 ['-', '-', '-', '+', '-', '-', '0', '-', '-'] [16, 33, 28, 66, 9, 0, 57, 0, 24] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.034, 0.111, 0.053, 0.15, 0.049, 0.0, 0.276, 0.0, 0.111]\n",
      "\n",
      "\n",
      "胡適\n",
      "-: 7\n",
      "先生(Na)說(VE) 12.281\n",
      "\n",
      "言論(Na)自由(Na) 5.296\n",
      "\n",
      "還(D)沒有(VJ) 4.307\n",
      "\n",
      "孤立(VHC)主義(Na) 3.837\n",
      "\n",
      "最(Dfa)有(V_2) 3.834\n",
      "\n",
      "+-: 1\n",
      "很(Dfa)好(VH) 2.958 ['-', '-', '+', '-', '-', '-', '-', '0', '-'] [47, 22, 167, 22, 9, 0, 6, 118, 8] \n",
      "['-', '-', '-', '-', '-', '-', '-', '0', '-'] [0.103, 0.074, 0.053, 0.05, 0.049, 0.0, 0.034, 0.233, 0.037]\n",
      "\n",
      "\n",
      "羅鴻詔\n",
      "-: 17\n",
      "並(D)沒有(VJ) 8.916\n",
      "\n",
      "主義(Na)為(VG) 7.261\n",
      "\n",
      "是(SHI)好(VH) 6.215\n",
      "\n",
      "實(D)為(VG) 6.166\n",
      "\n",
      "多(Dfa)大(VH) 4.945\n",
      "\n",
      "+-: 5\n",
      "共黨(Nb)統治(VC) 3.004 ['-', '+', '-', '-', '-', '-', '-', '-', '0'] [16, 44, 14, 0, 5, 8, 0, 0, 32] \n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '0'] [0.034, 0.037, 0.026, 0.0, 0.024, 0.032, 0.0, 0.0, 0.148]\n",
      "\n",
      "個人(Na)自由(VH) 2.579 ['+', '-', '-', '-', '-', '-', '-', '-', '0'] [252, 0, 0, 0, 5, 17, 6, 13, 88] \n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '0'] [0.034, 0.0, 0.0, 0.0, 0.024, 0.065, 0.034, 0.033, 0.148]\n",
      "\n",
      "要(D)看(VC) 2.245 ['-', '-', '+', '-', '-', '-', '-', '-', '0'] [16, 0, 69, 0, 23, 8, 6, 26, 40] \n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '0'] [0.034, 0.0, 0.132, 0.0, 0.098, 0.032, 0.034, 0.067, 0.148]\n",
      "\n",
      "大(VH)問題(Na) 2.063 ['-', '-', '-', '-', '-', '-', '+', '+', '0'] [16, 11, 0, 0, 5, 8, 38, 52, 24] \n",
      "['-', '-', '-', '-', '-', '-', '+', '-', '0'] [0.034, 0.037, 0.0, 0.0, 0.024, 0.032, 0.138, 0.033, 0.111]\n",
      "\n",
      "是(SHI)正確(VH) 1.749 ['-', '-', '-', '+', '-', '-', '-', '-', '0'] [0, 22, 0, 66, 9, 17, 0, 13, 48] \n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '0'] [0.0, 0.037, 0.0, 0.15, 0.049, 0.065, 0.0, 0.033, 0.185]\n",
      "\n",
      "\n",
      "社論\n",
      "+: 12\n",
      "言論(Na)自由(VH) 6.735\n",
      "\n",
      "是(SHI)一樣(VH) 4.807\n",
      "\n",
      "不(D)對(VH) 4.077\n",
      "\n",
      "不(D)對(VH) 3.445\n",
      "\n",
      "人(Na)出來(VA) 3.097\n",
      "\n",
      "-: 2\n",
      "民主(VH)國家(Na) 6.785\n",
      "\n",
      "不(D)是(SHI) 6.42\n",
      "\n",
      "+-: 2\n",
      "是(SHI)沒有(VJ) 2.89 ['0', '+', '-'] [31, 69, 28] \n",
      "['0', '+', '+'] [0.069, 0.262, 0.633]\n",
      "\n",
      "極(Dfa)不(D) 1.753 ['0', '+', '-'] [31, 44, 23] \n",
      "['0', '+', '+'] [0.069, 0.197, 0.6]\n",
      "\n",
      "\n",
      "文章\n",
      "+: 1\n",
      "不(D)到(VCL) 1.814\n",
      "\n",
      "-: 3\n",
      "可以(D)說(VE) 7.298\n",
      "\n",
      "更(D)進一步(D) 5.175\n",
      "\n",
      "更(D)是(SHI) 3.046\n",
      "\n",
      "\n",
      "日記\n",
      "-: 112\n",
      "要(D)去(VCL) 13.542\n",
      "\n",
      "今日(Nd)天晴(VH) 12.676\n",
      "\n",
      "不(D)悉(D) 9.763\n",
      "\n",
      "太(Dfa)不(D) 9.728\n",
      "\n",
      "信(Na)給(VD) 9.548\n",
      "\n",
      "+-: 4\n",
      "太(Dfa)大(VH) 9.954 ['+', '-', '0'] [47, 19, 43] \n",
      "['-', '-', '0'] [0.103, 0.066, 0.9]\n",
      "\n",
      "可(D)做(VC) 4.247 ['-', '+', '0'] [0, 34, 31] \n",
      "['-', '-', '0'] [0.0, 0.098, 0.667]\n",
      "\n",
      "太(Dfa)大(VH) 2.144 ['+', '-', '0'] [47, 19, 43] \n",
      "['-', '-', '0'] [0.103, 0.066, 0.9]\n",
      "\n",
      "多(Neqa)次(Nf) 1.224 ['-', '+', '0'] [0, 13, 10] \n",
      "['-', '-', '0'] [0.0, 0.049, 0.367]\n",
      "\n",
      "\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "#新版，直接觀察各類別\n",
    "#找出各類別重點詞組\n",
    "#觀察獨特性、鄰近性、群體性及特殊關係(gini特別高)\n",
    "\n",
    "one = 0\n",
    "more = 0\n",
    "error = 0\n",
    "\n",
    "all_class_mark = defaultdict(dict)\n",
    "\n",
    "for file in os.listdir(input_path):\n",
    "    with codecs.open(input_path+file,'rb','utf8') as f:\n",
    "        \n",
    "        if any(i in file.split('.')[0] for i in ['高頻','bigram','trigram','標點']):\n",
    "            continue\n",
    "            \n",
    "        print (file.split('.')[0])\n",
    "        \n",
    "        feature_path,condicate_path,condicate_label,condicate_index = find_input(file.split('.')[0])\n",
    "        feature,feature_dict = feature_select(feature_path)\n",
    "        \n",
    "        content_list = article_get(condicate_path,condicate_label)\n",
    "        for k,v in content_list.items():\n",
    "            content_list[k] = article_vector(v,feature,file.split('.')[0])\n",
    "            \n",
    "        X = []\n",
    "        y = []\n",
    "        with codecs.open(vector_path+file.split('.')[0]+'.csv','rb','utf8') as ff:\n",
    "            content = ff.readlines()\n",
    "\n",
    "            for line in content:\n",
    "                line = line.strip().split(',')\n",
    "                y.append(int(line[0]))\n",
    "                X.append([int(i) for i in list(map(float,line[1:]))])\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        content = f.readlines()\n",
    "        \n",
    "        feature_importance = defaultdict(list) #類別 (特徵,重要值])\n",
    "        feature_appear = defaultdict(list) #特徵 (類別,重要值,oob)\n",
    "        name = ''\n",
    "        count = 1\n",
    "        oob = 0\n",
    "        for line in content:\n",
    "            if line[0] == '#':\n",
    "                name = line[1:].strip()\n",
    "            #elif name != '' and '雷震' not in name:\n",
    "            #    continue\n",
    "            elif count > 0:\n",
    "                oob = float(line.strip().split(':')[1])\n",
    "                count = count - 1\n",
    "            elif line.strip() == '':\n",
    "                count = 1\n",
    "            else:\n",
    "                temp_line = line.strip().split()\n",
    "                if len(temp_line) == 2:\n",
    "                    feature_importance[name].append((temp_line[0],float(temp_line[1])))\n",
    "                    feature_appear[temp_line[0]].append((name,float(temp_line[1]),oob))\n",
    "        \n",
    "        feature_gini_pair = {}\n",
    "        special_label = defaultdict(list)\n",
    "        \n",
    "        for i in feature:\n",
    "            vector_space = np.zeros((len(condicate_label),len(condicate_label)),np.float64)\n",
    "            for x in permutations(condicate_label,2):\n",
    "                for z in feature_appear[i]:\n",
    "                    if x[0] in z[0] and x[1] in z[0]:\n",
    "                        vector_space[condicate_index[x[0]],condicate_index[x[1]]] = z[1]\n",
    "                                    \n",
    "            feature_gini_pair[i] = vector_space\n",
    "            \n",
    "            for x in range(len(condicate_label)):\n",
    "                if len([i for i in vector_space[x] if i > 0.01]) == len(condicate_label)-1:\n",
    "                    mean_value = round(sum(vector_space[x])/(0.01*(len(condicate_label)-1)),3)\n",
    "                    max_value = round(max(vector_space[x])/0.01,3)\n",
    "                    std_value = round(np.std(np.array([i/0.01 for i in vector_space[x] if i > 0.01])),3)\n",
    "                    special_label[i].append((condicate_label[x],mean_value,max_value))\n",
    "                    \n",
    "            if len(special_label[i]) == 1:\n",
    "                one += 1\n",
    "            elif len(special_label[i]) > 1:\n",
    "                more += 1\n",
    "            \n",
    "            #if len(special_label[i]) != 0:\n",
    "            if len(special_label[i]) == 1:\n",
    "                #print (i)\n",
    "                for j in special_label[i]:\n",
    "                    for k in j:\n",
    "                        #print (k,end=' ')\n",
    "                        pass\n",
    "                #print ()\n",
    "                \n",
    "                label_feature_value = [content_list[j][feature_dict[i]] for j in condicate_label]\n",
    "                for j in special_label[i]:\n",
    "                    \n",
    "                    def make_mark(temp_value):\n",
    "                        temp_mark = []\n",
    "                        for k in temp_value:\n",
    "                            check_value = k-temp_value[condicate_index[j[0]]]\n",
    "                            if check_value > 0:\n",
    "                                temp_mark.append('+')\n",
    "                            elif check_value < 0:\n",
    "                                temp_mark.append('-')\n",
    "                            elif check_value == 0:\n",
    "                                temp_mark.append('0')\n",
    "                        #print (j[0],temp_mark)\n",
    "                        return temp_mark\n",
    "                    \n",
    "                    temp_mark = make_mark(label_feature_value)\n",
    "                    \n",
    "                    if '+' in temp_mark and '-' in temp_mark:\n",
    "                        error += 1\n",
    "                    \n",
    "                    if '+' not in temp_mark:\n",
    "                        if '-' not in all_class_mark[j[0]]:\n",
    "                            all_class_mark[j[0]]['-'] = [[i,j[1],temp_mark,label_feature_value]]\n",
    "                        else:\n",
    "                            all_class_mark[j[0]]['-'].append([i,j[1],temp_mark,label_feature_value])\n",
    "                    elif '-' not in temp_mark:\n",
    "                        if '+' not in all_class_mark[j[0]]:\n",
    "                            all_class_mark[j[0]]['+'] = [[i,j[1],temp_mark,label_feature_value]]\n",
    "                        else:\n",
    "                            all_class_mark[j[0]]['+'].append([i,j[1],temp_mark,label_feature_value])\n",
    "                    else:\n",
    "                        temp_array = defaultdict(list)\n",
    "                        for index,e in enumerate(y):\n",
    "                            temp_array[e].append(X[index,feature_dict[i]])\n",
    "                        \n",
    "                        for k,v in temp_array.items():\n",
    "                            #文本中非0比率\n",
    "                            temp_array[k] = round(np.count_nonzero(np.array(temp_array[k])) / float(len(temp_array[k])),3)\n",
    "                            #文本中有使用文本內的相對使用頻率\n",
    "                            #use_list = [x for x in temp_array[k] if x > 0]\n",
    "                            #if len(use_list) > 0:\n",
    "                            #    temp_array[k] = round(sum(use_list)/len(use_list),3)\n",
    "                            #else:\n",
    "                            #    temp_array[k] = 0.0\n",
    "                    \n",
    "                        label_nonzero_value = [temp_array[x] for x in range(len(condicate_label))]\n",
    "                        nonzero_mark = make_mark(label_nonzero_value)\n",
    "                                \n",
    "                        if '+-' not in all_class_mark[j[0]]:\n",
    "                            all_class_mark[j[0]]['+-'] = [[i,j[1],temp_mark,label_feature_value,\\\n",
    "                                                           nonzero_mark,label_nonzero_value]]\n",
    "                        else:\n",
    "                            all_class_mark[j[0]]['+-'].append([i,j[1],temp_mark,label_feature_value,\\\n",
    "                                                               nonzero_mark,label_nonzero_value])\n",
    "                    \n",
    "                #print ('各類別在該語言特徵下的總相對頻率:',label_feature_value)\n",
    "                #print ()\n",
    "            \n",
    "            #time.sleep(0.5)\n",
    "        #print ('--------------------------------')\n",
    "        \n",
    "print ('one:',one)\n",
    "print ('more:',more)\n",
    "print ('error:',error)\n",
    "print ()\n",
    "\n",
    "for i in [classification_name,classification_topic]:\n",
    "    for j in i:\n",
    "        print (j)\n",
    "        for k in ['+','-','+-']:\n",
    "            if k in all_class_mark[j]:\n",
    "                print (k+':',len(all_class_mark[j][k]))\n",
    "                so = sorted(all_class_mark[j][k],key=lambda t:t[1],reverse=True)\n",
    "                for i,e in enumerate(so):\n",
    "                    if i == 5:\n",
    "                        break\n",
    "                    if k != '+-':\n",
    "                        print (e[0],e[1])\n",
    "                    else:\n",
    "                        for t in e[:-2]:\n",
    "                            print (t,end=' ')\n",
    "                        print ()\n",
    "                        print (e[-2],e[-1])\n",
    "                    print ()\n",
    "        print ()\n",
    "        \n",
    "print ('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "雷震\n",
      "-: 1\n",
      "最(Dfa)重要(VH) 2.979\n",
      "\n",
      "\n",
      "殷海光\n",
      "-: 17\n",
      "反共(VH)者(Na) 9.098\n",
      "\n",
      "極權(Na)統治(VC) 8.296\n",
      "\n",
      "極(Dfa)少數(Neqa) 6.312\n",
      "\n",
      "是(SHI)反共(VH) 5.943\n",
      "\n",
      "政治(Na)權力(Na) 5.677\n",
      "\n",
      "+-: 7\n",
      "可(D)言(VE) 7.395 ['-', '0', '-', '+', '-', '-', '-', '-', '-'] [142, 211, 14, 242, 9, 83, 163, 0, 48] \n",
      "['-', '0', '-', '-', '-', '-', '-', '-', '-'] [0.276, 0.481, 0.026, 0.2, 0.049, 0.258, 0.448, 0.0, 0.148]\n",
      "\n",
      "不(D)夠(VH) 2.72 ['-', '0', '-', '-', '-', '-', '-', '+', '-'] [47, 100, 42, 0, 14, 25, 69, 118, 72] \n",
      "['-', '0', '-', '-', '-', '-', '+', '-', '-'] [0.103, 0.259, 0.053, 0.0, 0.073, 0.065, 0.276, 0.2, 0.148]\n",
      "\n",
      "很(Dfa)有(V_2) 2.516 ['-', '0', '-', '-', '-', '-', '-', '+', '-'] [16, 67, 56, 0, 27, 8, 6, 78, 0] \n",
      "['-', '0', '-', '-', '-', '-', '-', '-', '-'] [0.034, 0.185, 0.105, 0.0, 0.146, 0.032, 0.034, 0.167, 0.0]\n",
      "\n",
      "大陸(Nc)淪陷(VH) 2.391 ['-', '0', '-', '+', '-', '-', '-', '-', '-'] [16, 44, 14, 66, 0, 0, 13, 13, 0] \n",
      "['-', '0', '-', '-', '-', '-', '-', '-', '-'] [0.034, 0.148, 0.026, 0.05, 0.0, 0.0, 0.034, 0.033, 0.0]\n",
      "\n",
      "是(SHI)想(VE) 2.308 ['-', '0', '+', '-', '-', '-', '-', '-', '-'] [0, 55, 69, 0, 9, 0, 31, 26, 8] \n",
      "['-', '0', '-', '-', '-', '-', '-', '-', '-'] [0.0, 0.185, 0.132, 0.0, 0.049, 0.0, 0.138, 0.067, 0.037]\n",
      "\n",
      "\n",
      "夏道平\n",
      "-: 4\n",
      "大(VH)大地(Na) 4.722\n",
      "\n",
      "總統(Na)連任(VG) 3.409\n",
      "\n",
      "讀者(Na)投書(VC) 3.335\n",
      "\n",
      "來(D)看(VC) 3.098\n",
      "\n",
      "\n",
      "傅正\n",
      "-: 11\n",
      "行政(Na)改革(VC) 8.639\n",
      "\n",
      "所(D)知(VK) 7.093\n",
      "\n",
      "地方(Na)選(VC) 5.758\n",
      "\n",
      "地方(Na)自治(VA) 4.523\n",
      "\n",
      "立法院(Nc)提出(VC) 3.814\n",
      "\n",
      "+-: 1\n",
      "要(D)做到(VE) 2.099 ['-', '-', '+', '0', '-', '-', '-', '-', '-'] [16, 0, 83, 66, 0, 0, 19, 52, 32] \n",
      "['-', '-', '-', '0', '-', '-', '-', '-', '-'] [0.034, 0.0, 0.132, 0.15, 0.0, 0.0, 0.103, 0.133, 0.111]\n",
      "\n",
      "\n",
      "龍平甫\n",
      "-: 19\n",
      "內閣(Na)總理(Na) 9.808\n",
      "\n",
      "不(D)滿意(VK) 7.59\n",
      "\n",
      "歐洲(Nc)聯防(VH) 6.331\n",
      "\n",
      "西方(Ncd)國家(Na) 5.936\n",
      "\n",
      "自由(VH)選舉(Na) 5.6\n",
      "\n",
      "+-: 1\n",
      "中立(VH)主義(Na) 9.235 ['-', '-', '+', '-', '0', '+', '-', '-', '-'] [0, 0, 653, 0, 100, 166, 19, 13, 0] \n",
      "['-', '-', '-', '-', '0', '-', '-', '-', '-'] [0.0, 0.0, 0.026, 0.0, 0.341, 0.032, 0.069, 0.033, 0.0]\n",
      "\n",
      "\n",
      "蔣勻田\n",
      "-: 16\n",
      "一段(Nc)話(Na) 10.539\n",
      "\n",
      "可以(D)看出(VE) 5.962\n",
      "\n",
      "艾森豪(Nb)總統(Na) 5.051\n",
      "\n",
      "無(VJ)人(Na) 4.489\n",
      "\n",
      "自由(VH)意志(Na) 4.353\n",
      "\n",
      "+-: 3\n",
      "中國(Nc)大陸(Nc) 8.4 ['-', '-', '-', '+', '-', '0', '-', '-', '-'] [0, 44, 56, 264, 45, 208, 44, 78, 8] \n",
      "['-', '-', '-', '-', '-', '0', '-', '-', '-'] [0.0, 0.111, 0.079, 0.1, 0.122, 0.452, 0.138, 0.1, 0.037]\n",
      "\n",
      "自由(VH)民主(Na) 2.379 ['+', '+', '-', '+', '-', '0', '-', '+', '-'] [63, 421, 0, 110, 14, 42, 19, 78, 0] \n",
      "['-', '-', '-', '-', '-', '0', '-', '-', '-'] [0.069, 0.074, 0.0, 0.1, 0.049, 0.129, 0.103, 0.1, 0.0]\n",
      "\n",
      "更(D)可(D) 2.203 ['+', '-', '-', '-', '-', '0', '-', '-', '-'] [79, 11, 14, 22, 9, 67, 6, 13, 0] \n",
      "['-', '-', '-', '-', '-', '0', '-', '-', '-'] [0.138, 0.037, 0.026, 0.05, 0.049, 0.194, 0.034, 0.033, 0.0]\n",
      "\n",
      "\n",
      "朱伴耘\n",
      "-: 24\n",
      "要(D)想(VE) 15.941\n",
      "\n",
      "很(Dfa)明顯(VH)的(DE) 11.617\n",
      "\n",
      "要(D)想(VE) 11.113\n",
      "\n",
      "美(Nc)蘇(Nc) 8.262\n",
      "\n",
      "是(SHI)無(VJ) 7.974\n",
      "\n",
      "+-: 6\n",
      "人民(Na)服務(VC) 7.328 ['-', '-', '-', '+', '-', '-', '0', '-', '-'] [0, 0, 0, 176, 0, 8, 57, 0, 0] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.0, 0.0, 0.0, 0.05, 0.0, 0.032, 0.276, 0.0, 0.0]\n",
      "\n",
      "姿態(Na)出現(VH) 3.292 ['-', '-', '-', '+', '-', '-', '0', '-', '-'] [0, 22, 0, 44, 5, 0, 38, 0, 0] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.0, 0.037, 0.0, 0.1, 0.024, 0.0, 0.172, 0.0, 0.0]\n",
      "\n",
      "都(D)知道(VK) 3.152 ['-', '-', '-', '+', '-', '-', '0', '-', '-'] [31, 33, 69, 154, 0, 8, 126, 39, 48] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.069, 0.111, 0.105, 0.35, 0.0, 0.032, 0.483, 0.1, 0.185]\n",
      "\n",
      "是(SHI)希望(VK) 2.869 ['-', '-', '+', '+', '-', '-', '0', '+', '-'] [0, 0, 69, 66, 0, 0, 50, 52, 0] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.0, 0.0, 0.105, 0.1, 0.0, 0.0, 0.276, 0.133, 0.0]\n",
      "\n",
      "是(SHI)毫無(VJ) 2.293 ['-', '-', '-', '+', '-', '-', '0', '-', '-'] [16, 33, 28, 66, 9, 0, 57, 0, 24] \n",
      "['-', '-', '-', '-', '-', '-', '0', '-', '-'] [0.034, 0.111, 0.053, 0.15, 0.049, 0.0, 0.276, 0.0, 0.111]\n",
      "\n",
      "\n",
      "胡適\n",
      "-: 7\n",
      "先生(Na)說(VE) 12.281\n",
      "\n",
      "言論(Na)自由(Na) 5.296\n",
      "\n",
      "還(D)沒有(VJ) 4.307\n",
      "\n",
      "孤立(VHC)主義(Na) 3.837\n",
      "\n",
      "最(Dfa)有(V_2) 3.834\n",
      "\n",
      "+-: 1\n",
      "很(Dfa)好(VH) 2.958 ['-', '-', '+', '-', '-', '-', '-', '0', '-'] [47, 22, 167, 22, 9, 0, 6, 118, 8] \n",
      "['-', '-', '-', '-', '-', '-', '-', '0', '-'] [0.103, 0.074, 0.053, 0.05, 0.049, 0.0, 0.034, 0.233, 0.037]\n",
      "\n",
      "\n",
      "羅鴻詔\n",
      "-: 17\n",
      "並(D)沒有(VJ) 8.916\n",
      "\n",
      "主義(Na)為(VG) 7.261\n",
      "\n",
      "是(SHI)好(VH) 6.215\n",
      "\n",
      "實(D)為(VG) 6.166\n",
      "\n",
      "多(Dfa)大(VH) 4.945\n",
      "\n",
      "+-: 5\n",
      "共黨(Nb)統治(VC) 3.004 ['-', '+', '-', '-', '-', '-', '-', '-', '0'] [16, 44, 14, 0, 5, 8, 0, 0, 32] \n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '0'] [0.034, 0.037, 0.026, 0.0, 0.024, 0.032, 0.0, 0.0, 0.148]\n",
      "\n",
      "個人(Na)自由(VH) 2.579 ['+', '-', '-', '-', '-', '-', '-', '-', '0'] [252, 0, 0, 0, 5, 17, 6, 13, 88] \n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '0'] [0.034, 0.0, 0.0, 0.0, 0.024, 0.065, 0.034, 0.033, 0.148]\n",
      "\n",
      "要(D)看(VC) 2.245 ['-', '-', '+', '-', '-', '-', '-', '-', '0'] [16, 0, 69, 0, 23, 8, 6, 26, 40] \n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '0'] [0.034, 0.0, 0.132, 0.0, 0.098, 0.032, 0.034, 0.067, 0.148]\n",
      "\n",
      "大(VH)問題(Na) 2.063 ['-', '-', '-', '-', '-', '-', '+', '+', '0'] [16, 11, 0, 0, 5, 8, 38, 52, 24] \n",
      "['-', '-', '-', '-', '-', '-', '+', '-', '0'] [0.034, 0.037, 0.0, 0.0, 0.024, 0.032, 0.138, 0.033, 0.111]\n",
      "\n",
      "是(SHI)正確(VH) 1.749 ['-', '-', '-', '+', '-', '-', '-', '-', '0'] [0, 22, 0, 66, 9, 17, 0, 13, 48] \n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '0'] [0.0, 0.037, 0.0, 0.15, 0.049, 0.065, 0.0, 0.033, 0.185]\n",
      "\n",
      "\n",
      "社論\n",
      "+: 12\n",
      "言論(Na)自由(VH) 6.735\n",
      "\n",
      "是(SHI)一樣(VH) 4.807\n",
      "\n",
      "不(D)對(VH) 4.077\n",
      "\n",
      "不(D)對(VH) 3.445\n",
      "\n",
      "人(Na)出來(VA) 3.097\n",
      "\n",
      "-: 2\n",
      "民主(VH)國家(Na) 6.785\n",
      "\n",
      "不(D)是(SHI) 6.42\n",
      "\n",
      "+-: 2\n",
      "是(SHI)沒有(VJ) 2.89 ['0', '+', '-'] [31, 69, 28] \n",
      "['0', '+', '+'] [0.069, 0.262, 0.633]\n",
      "\n",
      "極(Dfa)不(D) 1.753 ['0', '+', '-'] [31, 44, 23] \n",
      "['0', '+', '+'] [0.069, 0.197, 0.6]\n",
      "\n",
      "\n",
      "文章\n",
      "+: 1\n",
      "不(D)到(VCL) 1.814\n",
      "\n",
      "-: 3\n",
      "可以(D)說(VE) 7.298\n",
      "\n",
      "更(D)進一步(D) 5.175\n",
      "\n",
      "更(D)是(SHI) 3.046\n",
      "\n",
      "\n",
      "日記\n",
      "-: 112\n",
      "要(D)去(VCL) 13.542\n",
      "\n",
      "今日(Nd)天晴(VH) 12.676\n",
      "\n",
      "不(D)悉(D) 9.763\n",
      "\n",
      "太(Dfa)不(D) 9.728\n",
      "\n",
      "信(Na)給(VD) 9.548\n",
      "\n",
      "+-: 4\n",
      "太(Dfa)大(VH) 9.954 ['+', '-', '0'] [47, 19, 43] \n",
      "['-', '-', '0'] [0.103, 0.066, 0.9]\n",
      "\n",
      "可(D)做(VC) 4.247 ['-', '+', '0'] [0, 34, 31] \n",
      "['-', '-', '0'] [0.0, 0.098, 0.667]\n",
      "\n",
      "太(Dfa)大(VH) 2.144 ['+', '-', '0'] [47, 19, 43] \n",
      "['-', '-', '0'] [0.103, 0.066, 0.9]\n",
      "\n",
      "多(Neqa)次(Nf) 1.224 ['-', '+', '0'] [0, 13, 10] \n",
      "['-', '-', '0'] [0.0, 0.049, 0.367]\n",
      "\n",
      "\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "for i in [classification_name,classification_topic]:\n",
    "    for j in i:\n",
    "        print (j)\n",
    "        for k in ['+','-','+-']:\n",
    "            if k in all_class_mark[j]:\n",
    "                print (k+':',len(all_class_mark[j][k]))\n",
    "                so = sorted(all_class_mark[j][k],key=lambda t:t[1],reverse=True)\n",
    "                for i,e in enumerate(so):\n",
    "                    if i == 5:\n",
    "                        break\n",
    "                    if k != '+-':\n",
    "                        print (e[0],e[1])\n",
    "                    else:\n",
    "                        for t in e[:-2]:\n",
    "                            print (t,end=' ')\n",
    "                        print ()\n",
    "                        print (e[-2],e[-1])\n",
    "                    print ()\n",
    "        print ()\n",
    "        \n",
    "print ('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#找出各類別重點詞組\n",
    "#觀察獨特性、鄰近性、群體性及特殊關係(gini特別高)\n",
    "a_threshold = 0.0109\n",
    "b_threshold = 0.00263\n",
    "\n",
    "all_gini_value = []\n",
    "all_class_feature = defaultdict(list)\n",
    "\n",
    "for file in os.listdir(input_path):\n",
    "    with codecs.open(input_path+file,'rb','utf8') as f:\n",
    "        \n",
    "        if file.split('.')[0].split()[1] not in feature_condicate:\n",
    "            continue\n",
    "            \n",
    "        #print (file.split('.')[0])\n",
    "        #print ('詞組','類別','分數','平均','標準差','數值0次數','總合','類別數據')\n",
    "        \n",
    "        feature_path,condicate_label,condicate_index = find_input(file.split('.')[0])\n",
    "        \n",
    "        feature_dict = {} #特徵\n",
    "        feature = []\n",
    "        with codecs.open(feature_path,'rb','utf8') as ff: #抓取基準特徵\n",
    "            count = 0\n",
    "            for i in ff.readlines():\n",
    "                if '\\ufeff' in i: #去掉開頭BOM\n",
    "                    i = i.replace('\\ufeff','')\n",
    "                if i.strip() != '':\n",
    "                    feature.append(i.strip().split(',')[0])\n",
    "                    feature_dict[i.strip().split(',')[0]] = count\n",
    "                    count += 1\n",
    "        \n",
    "        class_vector = defaultdict(list) #各類別文本向量\n",
    "        with codecs.open(vector_path+file.split('.')[0]+'.csv','rb','utf8') as ff:\n",
    "            for i in ff.readlines():\n",
    "                if '\\ufeff' in i: #去掉開頭BOM\n",
    "                    i = i.replace('\\ufeff','')\n",
    "                if i.strip() != '':\n",
    "                    i = i.strip().split(',')\n",
    "                    class_vector[condicate_label[int(i[0])]].append([float(j) for j in i[1:]])\n",
    "        \n",
    "        content = f.readlines()\n",
    "        \n",
    "        feature_importance = defaultdict(list)\n",
    "        feature_appear = defaultdict(list)\n",
    "        name = ''\n",
    "        count = 2\n",
    "        oob = 0\n",
    "        for line in content:\n",
    "            if line[0] == '#':\n",
    "                name = line[1:].strip()\n",
    "            #elif name != '' and '雷震' not in name:\n",
    "            #    continue\n",
    "            elif count > 0:\n",
    "                if count == 1:\n",
    "                    oob = float(line.strip().split(':')[1])\n",
    "                count = count - 1\n",
    "            elif line.strip() == '':\n",
    "                count = 2\n",
    "            else:\n",
    "                temp_line = line.strip().split()\n",
    "                if len(temp_line) == 2:# and float(temp_line[1]) >= 0.01:\n",
    "                    feature_importance[name].append((temp_line[0],float(temp_line[1])))\n",
    "                    feature_appear[temp_line[0]].append((name,float(temp_line[1]),oob))\n",
    "                    all_gini_value.append(float(temp_line[1]))\n",
    "        \n",
    "        feature_gini_pair = {}\n",
    "        for i in feature:\n",
    "            vector_space = np.zeros((len(condicate_label),len(condicate_label)),np.float64)\n",
    "            for x in condicate_label:\n",
    "                for y in condicate_label:\n",
    "                    if x != y and i in feature_appear:\n",
    "                        class_check = True\n",
    "                        for z in feature_appear[i]:\n",
    "                            if x in z[0] and y in z[0]:\n",
    "                                vector_space[condicate_index[x],condicate_index[y]] = z[1]#*(1-z[2])\n",
    "                                #all_gini_value.append(z[1]*(1-z[2]))\n",
    "                                class_check = False\n",
    "                                \n",
    "                        if class_check:\n",
    "                            vector_space[condicate_index[x],condicate_index[y]] = -1.0\n",
    "            if i in feature_appear:                       \n",
    "                feature_gini_pair[i] = vector_space\n",
    "                \n",
    "            '''for j in vector_space:\n",
    "                if -1.53778936498e-18 in j: #美(Nc)蘇(Nc) #蔣勻田 胡適\n",
    "                    print (i)'''\n",
    "        \n",
    "        #特徵觀察\n",
    "        '''for i in feature:\n",
    "            for index,j in enumerate(feature_gini_pair[i]):\n",
    "                if Counter(j.tolist())[0.0] == 1:\n",
    "                    print (i,condicate_label[index],j)'''\n",
    "                    \n",
    "        for i in feature:\n",
    "            if i not in feature_gini_pair:\n",
    "                continue\n",
    "            #分群\n",
    "            temp_group = []\n",
    "            for a in range(len(condicate_label)):\n",
    "                all_check = True\n",
    "                wait_append = []\n",
    "                for b in temp_group:\n",
    "                    if type(b) == int and  0.0 <= feature_gini_pair[i][a,b] < b_threshold:\n",
    "                        temp_group.remove(b)\n",
    "                        wait_append.append([b,a])\n",
    "                        all_check = False\n",
    "                    elif type(b) == list:\n",
    "                        check = True\n",
    "                        for c in b:\n",
    "                            if feature_gini_pair[i][a,c] >= b_threshold or feature_gini_pair[i][a,c] < 0.0:\n",
    "                                check = False\n",
    "                                break\n",
    "                        if check:\n",
    "                            b.append(a)\n",
    "                            all_check = False\n",
    "                    if not all_check:\n",
    "                        break\n",
    "                for d in wait_append:\n",
    "                    temp_group.append(d)\n",
    "                if all_check:\n",
    "                    temp_group.append(a)\n",
    "                    \n",
    "            #找出獨特群\n",
    "            temper = []\n",
    "            for e in temp_group:\n",
    "                if type(e) == int:\n",
    "                    check = True\n",
    "                    for a in range(len(condicate_label)):\n",
    "                        if e != a:\n",
    "                            if feature_gini_pair[i][e,a] < a_threshold:\n",
    "                                check = False\n",
    "                                break\n",
    "                    if check:\n",
    "                        #temp_group.remove(e)\n",
    "                        #temp_group.append([e])\n",
    "                        temper.append([e])\n",
    "                    else:\n",
    "                        temper.append(e)\n",
    "                else:\n",
    "                    temper.append(e)\n",
    "                        \n",
    "            temp_group= temper\n",
    "            \n",
    "            #確保群內相似，群外不相似\n",
    "            temper = []\n",
    "            for e in temp_group:\n",
    "                if type(e) == list:\n",
    "                    check = True\n",
    "                    for a in range(len(condicate_label)):\n",
    "                        if a not in e:\n",
    "                            for t in e:\n",
    "                                if feature_gini_pair[i][t,a] < a_threshold:\n",
    "                                    check = False\n",
    "                                    break\n",
    "                        if not check:\n",
    "                            break\n",
    "                    if not check:\n",
    "                        #temp_group.remove(e)\n",
    "                        for t in e:\n",
    "                            #temp_group.append(t)\n",
    "                            temper.append(t)\n",
    "                    else:\n",
    "                        temper.append(e)\n",
    "                else:\n",
    "                    temper.append(e)\n",
    "                    \n",
    "            temp_group= temper\n",
    "        \n",
    "            #print (feature_gini_pair[i])\n",
    "            #print (i,temp_group)\n",
    "            class_group = []\n",
    "            class_group2 = []\n",
    "            for e in temp_group:\n",
    "                if type(e) == list:\n",
    "                    class_group.append([condicate_label[j] for j in e])\n",
    "                    #class_group2.append([np.mean(np.array(class_vector[condicate_label[j]]), \n",
    "                    #axis=0)[feature_dict[i]] for j in e])\n",
    "            if len(class_group) != 0 and 'lei' in file:# and len([j for j in class_group if len(j) > 1]) > 0:\n",
    "                #print (feature_gini_pair[i])\n",
    "                #print (i,temp_group)\n",
    "                print (i,class_group)\n",
    "                #print (class_group2)\n",
    "                for j in class_group:\n",
    "                    all_class_feature[' '.join(j)].append(i)\n",
    "                \n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        '''feature_importance = defaultdict(list)\n",
    "        name = ''\n",
    "        oob = 0\n",
    "        count = 2\n",
    "        for line in content:\n",
    "            if line[0] == '#':\n",
    "                name = line[1:].strip()\n",
    "            #elif name != '' and '雷震' not in name:\n",
    "            #    continue\n",
    "            elif count > 0:\n",
    "                if count == 1:\n",
    "                    oob = float(line.strip().split(':')[1])\n",
    "                count = count - 1\n",
    "            elif line.strip() == '':\n",
    "                count = 2\n",
    "            else:\n",
    "                temp_line = line.strip().split()\n",
    "                if len(temp_line) == 2:# and float(temp_line[1]) > 0.01:\n",
    "                    feature_importance[name].append((temp_line[0],float(temp_line[1]),oob))\n",
    "                    \n",
    "        #詞組 : [兩兩類別,排序,切割分數,\n",
    "        # (A類別文本該詞組數值最大、最小、平均、標準差、數值0次數、綜合),(B類別文本該詞組數值最大、最小、平均、標準差、數值0次數、綜合)]\n",
    "        feature_appear = defaultdict(list) \n",
    "        for k,v in feature_importance.items():\n",
    "            for index,e in enumerate(v):\n",
    "                a_class = np.array(class_vector[k.split()[0]]) \n",
    "                b_class = np.array(class_vector[k.split()[1]])\n",
    "                \n",
    "                def class_caculator(c): \n",
    "                    class_max = max(c[:,feature_dict[e[0]]])\n",
    "                    class_min = min(c[:,feature_dict[e[0]]])\n",
    "                    class_mean = np.mean(c, axis=0)[feature_dict[e[0]]]\n",
    "                    class_std = np.std(c, axis=0)[feature_dict[e[0]]]\n",
    "                    class_zero = Counter(c[:,feature_dict[e[0]]].tolist())[0]/c.shape[0]\n",
    "                    class_sum = sum(c[:,feature_dict[e[0]]])\n",
    "                    \n",
    "                    return (class_max,class_min,class_mean,class_std,class_zero,class_sum)\n",
    "                \n",
    "                a_class = class_caculator(a_class)\n",
    "                b_class = class_caculator(b_class)\n",
    "                \n",
    "                a_b_zero = 0\n",
    "                if a_class[4] != 0 and b_class[4] != 0:\n",
    "                    a_b_zero = a_class[4] * b_class[4]\n",
    "                elif a_class[4] == 0:\n",
    "                    if b_class[4] != 0:\n",
    "                        a_b_zero = b_class[4]\n",
    "                    else:\n",
    "                        a_b_zero = 0.0000000000001\n",
    "                else:\n",
    "                    a_b_zero = a_class[4]\n",
    "                \n",
    "                #排名分數 = 排名 * (分割數值/0.01)倒數 * 1-oob倒數 * 兩兩0數值比例倒數   數值越小越好 \n",
    "                ranking_value = index \n",
    "                if e[1]/0.01 == 0:\n",
    "                    ranking_value = 100/((1-e[2])*a_b_zero)\n",
    "                else:\n",
    "                    ranking_value = index/((e[1]/0.01)*(1-e[2])*a_b_zero)\n",
    "                    \n",
    "                feature_appear[e[0]].append([k,ranking_value,e[1],a_class,b_class])\n",
    "                \n",
    "        for i in feature:\n",
    "            #if len(feature_appear[i]) == (len(condicate_label)*(len(condicate_label)-1))/2: \n",
    "            #    print (i)\n",
    "            #print (len(feature_appear[i]),condicate_label)\n",
    "            #print (i,feature_appear[i])\n",
    "            #print (i,len(feature_appear[i]),sum([j[1] for j in feature_appear[i]]))\n",
    "            for j in condicate_label:\n",
    "                temp_check = []\n",
    "                for k in feature_appear[i]:\n",
    "                    if j in k[0]:\n",
    "                        temp_check.append(k)\n",
    "                #if len(temp_check) == len(condicate_label)-1 and sum([k[1] for k in temp_check]) < 30:\n",
    "                if len(temp_check) >= len(condicate_label)-2 and sum([k[1] for k in temp_check]) < 30:\n",
    "                    compare = len(temp_check)\n",
    "                    def compare_value(com,num):\n",
    "                        compare = com\n",
    "                        for l in temp_check:\n",
    "                            if l[0].split()[0] == j:\n",
    "                                if l[3][num] > l[4][num]:\n",
    "                                    compare -= 1\n",
    "                            elif l[0].split()[1] == j:\n",
    "                                if l[3][num] < l[4][num]:\n",
    "                                    compare -= 1\n",
    "                        return compare\n",
    "                    \n",
    "                    class_value = ''\n",
    "                    if temp_check[0][0].split()[0] == j:\n",
    "                        class_value = temp_check[0][3]\n",
    "                    elif temp_check[0][0].split()[1] == j:\n",
    "                        class_value = temp_check[0][4]\n",
    "                        \n",
    "                    #if class_value[4] > 0.5:\n",
    "                    #    continue\n",
    "                        \n",
    "                    print (i,j,sum([k[1] for k in temp_check]),compare_value(compare,2),compare_value(compare,3)\n",
    "                           ,compare_value(compare,4),compare_value(compare,5),class_value)\n",
    "                    \n",
    "                    vector_space = np.zeros((len(condicate_label),len(condicate_label)),np.float64)\n",
    "                    for x in condicate_label:\n",
    "                        for y in condicate_label:\n",
    "                            if x != y:\n",
    "                                for z in feature_appear[i]:\n",
    "                                    if x in z[0] and y in z[0]:\n",
    "                                        vector_space[condicate_index[x],condicate_index[y]] = z[2]\n",
    "                    print (vector_space[condicate_index[j]])'''\n",
    "        \n",
    "        #print ()\n",
    "        #time.sleep(3)\n",
    "'''with codecs.open('C:\\\\Users\\\\user\\\\Desktop\\\\all_gini.txt','wb','utf8') as g:\n",
    "    so = sorted(all_gini_value, reverse = True)\n",
    "    for i in so:\n",
    "        g.write(str(i)+'\\r\\n')'''\n",
    "for k,v in all_class_feature.items():\n",
    "    print (k)\n",
    "    #for i in v:\n",
    "    #    print (i)\n",
    "    #print ()\n",
    "print ('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#計算各類別間的OOB error\n",
    "for file in os.listdir(input_path):\n",
    "    with codecs.open(input_path+file,'rb','utf8') as f:\n",
    "        content = f.readlines()\n",
    "        \n",
    "        print (file)\n",
    "        \n",
    "        temp_label = ''\n",
    "        temp_index = ''\n",
    "        if 'name' in file:\n",
    "            temp_label = classification_name\n",
    "            temp_index = author_index\n",
    "        elif 'topic' in file:\n",
    "            temp_label = classification_topic\n",
    "            temp_index = topic_index\n",
    "        \n",
    "        oob_error = []\n",
    "        vector_space = np.zeros((len(temp_index)+1,len(temp_index)+1),np.float64) #多平均\n",
    "        \n",
    "        for i in range(len(content)-1):\n",
    "            if content[i][0] == '#':\n",
    "                oob_error.append((content[i][1:],float(content[i+1].split(':')[1]))) #oob error\n",
    "                \n",
    "        for i in oob_error:\n",
    "            #print (i[0],round(i[1],3))\n",
    "            vector_space[temp_index[i[0].split()[0]],temp_index[i[0].split()[1]]] = round(i[1],3)\n",
    "            vector_space[temp_index[i[0].split()[1]],temp_index[i[0].split()[0]]] = round(i[1],3)\n",
    "            \n",
    "        for i in range(len(temp_index)):\n",
    "            vector_space[i,-1] = round(sum(vector_space[i])/(len(temp_index)-1),3)\n",
    "        for i in range(len(temp_index)):\n",
    "            vector_space[-1,i] = round(sum(vector_space[:,i])/(len(temp_index)-1),3)\n",
    "        vector_space[-1,-1] = round(sum(vector_space[-1])/(len(temp_index)),3)\n",
    "        \n",
    "        print (' '.join(temp_label+['平均']))\n",
    "        print (vector_space)\n",
    "        #df = DataFrame(vector_space,index=temp_label,columns=temp_label)\n",
    "        print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "muti_class_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\RF result\\\\顯著特徵尋找\\\\特徵值全\\\\'\n",
    "\n",
    "for file in os.listdir(muti_class_path):\n",
    "    with codecs.open(muti_class_path+file,'rb','utf8') as f:\n",
    "        name = f.readline()\n",
    "        oob_score = float(f.readline().strip().split(':')[1])\n",
    "        print (file)\n",
    "        print (round(oob_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "傅正_1.txt\n",
      "\n",
      "傅正_10.txt\n",
      "\n",
      "傅正_11.txt\n",
      "\n",
      "傅正_12.txt\n",
      "\n",
      "傅正_13.txt\n",
      "\n",
      "傅正_14.txt\n",
      "只是(D)說出(VE)「(PARENTHESISCATEGORY)但(Cbb)自(P)大陸(Nc)淪陷(VH)」(PARENTHESISCATEGORY)之類(Cab)。(PERIODCATEGORY)但是(Cbb)\n",
      "。(PERIODCATEGORY)但是(Cbb)，(COMMACATEGORY)所謂(VK)「(PARENTHESISCATEGORY)大陸(Nc)淪陷(VH)」(PARENTHESISCATEGORY)之類(Cab)，(COMMACATEGORY)是(SHI)\n",
      "「(PARENTHESISCATEGORY)…(ETCCATEGORY)…(ETCCATEGORY)但(Cbb)自(P)大陸(Nc)淪陷(VH)，(COMMACATEGORY)國家(Na)發生(VJ)重大(VH)\n",
      "\n",
      "傅正_15.txt\n",
      "\n",
      "傅正_16.txt\n",
      "\n",
      "傅正_17.txt\n",
      "\n",
      "傅正_18.txt\n",
      "\n",
      "傅正_19.txt\n",
      "\n",
      "傅正_2.txt\n",
      "\n",
      "傅正_20.txt\n",
      "\n",
      "傅正_3.txt\n",
      "\n",
      "傅正_4.txt\n",
      "\n",
      "傅正_5.txt\n",
      "\n",
      "傅正_6.txt\n",
      "\n",
      "傅正_7.txt\n",
      "\n",
      "傅正_8.txt\n",
      "\n",
      "傅正_9.txt\n",
      "\n",
      "夏道平_1.txt\n",
      "\n",
      "夏道平_10.txt\n",
      "\n",
      "夏道平_11.txt\n",
      "\n",
      "夏道平_12.txt\n",
      "\n",
      "夏道平_13.txt\n",
      "\n",
      "夏道平_14.txt\n",
      "\n",
      "夏道平_15.txt\n",
      "\n",
      "夏道平_16.txt\n",
      "\n",
      "夏道平_17.txt\n",
      "\n",
      "夏道平_18.txt\n",
      "\n",
      "夏道平_19.txt\n",
      "罵(VC)共匪(Na)而(Cbb)罵(VC)到(P)大陸(Nc)淪陷(VH)前(Ng)所謂(VK)「(PARENTHESISCATEGORY)民主(VH)\n",
      "\n",
      "夏道平_2.txt\n",
      "\n",
      "夏道平_20.txt\n",
      "\n",
      "夏道平_21.txt\n",
      "\n",
      "夏道平_22.txt\n",
      "\n",
      "夏道平_23.txt\n",
      "\n",
      "夏道平_24.txt\n",
      "\n",
      "夏道平_25.txt\n",
      "\n",
      "夏道平_26.txt\n",
      "\n",
      "夏道平_27.txt\n",
      "\n",
      "夏道平_28.txt\n",
      "\n",
      "夏道平_29.txt\n",
      "\n",
      "夏道平_3.txt\n",
      "\n",
      "夏道平_30.txt\n",
      "\n",
      "夏道平_31.txt\n",
      "\n",
      "夏道平_32.txt\n",
      "\n",
      "夏道平_33.txt\n",
      "\n",
      "夏道平_34.txt\n",
      "\n",
      "夏道平_35.txt\n",
      "\n",
      "夏道平_36.txt\n",
      "\n",
      "夏道平_37.txt\n",
      "\n",
      "夏道平_38.txt\n",
      "\n",
      "夏道平_4.txt\n",
      "\n",
      "夏道平_5.txt\n",
      "\n",
      "夏道平_6.txt\n",
      "\n",
      "夏道平_7.txt\n",
      "\n",
      "夏道平_8.txt\n",
      "\n",
      "夏道平_9.txt\n",
      "\n",
      "朱伴耘_1.txt\n",
      "\n",
      "朱伴耘_10.txt\n",
      "\n",
      "朱伴耘_11.txt\n",
      "\n",
      "朱伴耘_12.txt\n",
      "\n",
      "朱伴耘_13.txt\n",
      "\n",
      "朱伴耘_14.txt\n",
      "\n",
      "朱伴耘_15.txt\n",
      "太(Dfa)遲(VH)，(COMMACATEGORY)自(P)中國(Nc)大陸(Nc)淪陷(VH)至今(D)，(COMMACATEGORY)美國(Nc)始終(D)\n",
      "在(P)捷克(Nc)政變(Na)以及(Caa)中國(Nc)大陸(Nc)淪陷(VH)後(Ng)，(COMMACATEGORY)美國(Nc)之(DE)\n",
      "\n",
      "朱伴耘_16.txt\n",
      "\n",
      "朱伴耘_17.txt\n",
      "\n",
      "朱伴耘_18.txt\n",
      "\n",
      "朱伴耘_19.txt\n",
      "\n",
      "朱伴耘_2.txt\n",
      "\n",
      "朱伴耘_20.txt\n",
      "\n",
      "朱伴耘_21.txt\n",
      "\n",
      "朱伴耘_22.txt\n",
      "\n",
      "朱伴耘_23.txt\n",
      "\n",
      "朱伴耘_24.txt\n",
      "\n",
      "朱伴耘_25.txt\n",
      "\n",
      "朱伴耘_26.txt\n",
      "\n",
      "朱伴耘_27.txt\n",
      "\n",
      "朱伴耘_28.txt\n",
      "\n",
      "朱伴耘_29.txt\n",
      "\n",
      "朱伴耘_3.txt\n",
      "\n",
      "朱伴耘_4.txt\n",
      "\n",
      "朱伴耘_5.txt\n",
      "\n",
      "朱伴耘_6.txt\n",
      "\n",
      "朱伴耘_7.txt\n",
      "\n",
      "朱伴耘_8.txt\n",
      "\n",
      "朱伴耘_9.txt\n",
      "\n",
      "殷海光_1.txt\n",
      "\n",
      "殷海光_10.txt\n",
      "\n",
      "殷海光_11.txt\n",
      "\n",
      "殷海光_12.txt\n",
      "\n",
      "殷海光_13.txt\n",
      "\n",
      "殷海光_14.txt\n",
      "\n",
      "殷海光_15.txt\n",
      "\n",
      "殷海光_16.txt\n",
      "\n",
      "殷海光_17.txt\n",
      "深厚(VH)有(V_2)以致(Cbb)之(Nh)。(PERIODCATEGORY)大陸(Nc)淪陷(VH)以後(Ng)，(COMMACATEGORY)這(Nep)一(Neu)\n",
      "\n",
      "殷海光_18.txt\n",
      "\n",
      "殷海光_19.txt\n",
      "三(Neu)大(VH)錯誤(Na)觀念(Na)。(PERIODCATEGORY)大陸(Nc)淪陷(VH)是(SHI)哪些(Neqa)因素(Na)形成(VG)\n",
      "\n",
      "殷海光_2.txt\n",
      "\n",
      "殷海光_20.txt\n",
      "\n",
      "殷海光_21.txt\n",
      "的(DE)不(D)夠(Dfa)澈底(VH)。(PERIODCATEGORY)大陸(Nc)淪陷(VH)他們(Nh)一點(Neqa)慣任(Na)也(D)\n",
      "\n",
      "殷海光_22.txt\n",
      "\n",
      "殷海光_23.txt\n",
      "\n",
      "殷海光_24.txt\n",
      "\n",
      "殷海光_25.txt\n",
      "\n",
      "殷海光_26.txt\n",
      "\n",
      "殷海光_27.txt\n",
      "\n",
      "殷海光_3.txt\n",
      "\n",
      "殷海光_4.txt\n",
      "\n",
      "殷海光_5.txt\n",
      "\n",
      "殷海光_6.txt\n",
      "\n",
      "殷海光_7.txt\n",
      "直接(VH)的(DE)因素(Na)。(PERIODCATEGORY)自從(P)大陸(Nc)淪陷(VH)、(PAUSECATEGORY)撤退(VA)臺灣(Nc)以來(Ng)\n",
      "\n",
      "殷海光_8.txt\n",
      "\n",
      "殷海光_9.txt\n",
      "\n",
      "羅鴻詔_1.txt\n",
      "\n",
      "羅鴻詔_10.txt\n",
      "\n",
      "羅鴻詔_11.txt\n",
      "\n",
      "羅鴻詔_12.txt\n",
      "\n",
      "羅鴻詔_13.txt\n",
      "\n",
      "羅鴻詔_14.txt\n",
      "\n",
      "羅鴻詔_15.txt\n",
      "\n",
      "羅鴻詔_16.txt\n",
      "\n",
      "羅鴻詔_17.txt\n",
      "\n",
      "羅鴻詔_18.txt\n",
      "\n",
      "羅鴻詔_19.txt\n",
      "\n",
      "羅鴻詔_2.txt\n",
      "\n",
      "羅鴻詔_20.txt\n",
      "\n",
      "羅鴻詔_21.txt\n",
      "\n",
      "羅鴻詔_22.txt\n",
      "\n",
      "羅鴻詔_23.txt\n",
      "\n",
      "羅鴻詔_24.txt\n",
      "\n",
      "羅鴻詔_25.txt\n",
      "\n",
      "羅鴻詔_26.txt\n",
      "\n",
      "羅鴻詔_27.txt\n",
      "\n",
      "羅鴻詔_3.txt\n",
      "\n",
      "羅鴻詔_4.txt\n",
      "\n",
      "羅鴻詔_5.txt\n",
      "\n",
      "羅鴻詔_6.txt\n",
      "\n",
      "羅鴻詔_7.txt\n",
      "\n",
      "羅鴻詔_8.txt\n",
      "\n",
      "羅鴻詔_9.txt\n",
      "\n",
      "胡適_1.txt\n",
      "\n",
      "胡適_10.txt\n",
      "\n",
      "胡適_11.txt\n",
      "\n",
      "胡適_12.txt\n",
      "\n",
      "胡適_13.txt\n",
      "\n",
      "胡適_14.txt\n",
      "\n",
      "胡適_15.txt\n",
      "\n",
      "胡適_16.txt\n",
      "\n",
      "胡適_17.txt\n",
      "\n",
      "胡適_18.txt\n",
      "\n",
      "胡適_19.txt\n",
      "\n",
      "胡適_2.txt\n",
      "\n",
      "胡適_20.txt\n",
      "\n",
      "胡適_21.txt\n",
      "\n",
      "胡適_22.txt\n",
      "\n",
      "胡適_23.txt\n",
      "\n",
      "胡適_24.txt\n",
      "\n",
      "胡適_25.txt\n",
      "\n",
      "胡適_26.txt\n",
      "\n",
      "胡適_27.txt\n",
      "\n",
      "胡適_28.txt\n",
      "\n",
      "胡適_29.txt\n",
      "\n",
      "胡適_3.txt\n",
      "一九四九年(Nd)兩年(Nd)中(Ng)，(COMMACATEGORY)我國(Nc)大陸(Nc)淪陷(VH)，(COMMACATEGORY)是(SHI)我國(Nc)最(Dfa)\n",
      "\n",
      "胡適_30.txt\n",
      "\n",
      "胡適_4.txt\n",
      "\n",
      "胡適_5.txt\n",
      "\n",
      "胡適_6.txt\n",
      "\n",
      "胡適_7.txt\n",
      "\n",
      "胡適_8.txt\n",
      "\n",
      "胡適_9.txt\n",
      "\n",
      "蔣勻田_1.txt\n",
      "\n",
      "蔣勻田_10.txt\n",
      "\n",
      "蔣勻田_11.txt\n",
      "\n",
      "蔣勻田_12.txt\n",
      "\n",
      "蔣勻田_13.txt\n",
      "\n",
      "蔣勻田_14.txt\n",
      "\n",
      "蔣勻田_15.txt\n",
      "\n",
      "蔣勻田_16.txt\n",
      "\n",
      "蔣勻田_17.txt\n",
      "\n",
      "蔣勻田_18.txt\n",
      "\n",
      "蔣勻田_19.txt\n",
      "\n",
      "蔣勻田_2.txt\n",
      "\n",
      "蔣勻田_20.txt\n",
      "\n",
      "蔣勻田_21.txt\n",
      "\n",
      "蔣勻田_22.txt\n",
      "\n",
      "蔣勻田_23.txt\n",
      "\n",
      "蔣勻田_24.txt\n",
      "\n",
      "蔣勻田_25.txt\n",
      "\n",
      "蔣勻田_26.txt\n",
      "\n",
      "蔣勻田_27.txt\n",
      "\n",
      "蔣勻田_28.txt\n",
      "\n",
      "蔣勻田_29.txt\n",
      "\n",
      "蔣勻田_3.txt\n",
      "\n",
      "蔣勻田_30.txt\n",
      "\n",
      "蔣勻田_31.txt\n",
      "\n",
      "蔣勻田_4.txt\n",
      "\n",
      "蔣勻田_5.txt\n",
      "\n",
      "蔣勻田_6.txt\n",
      "\n",
      "蔣勻田_7.txt\n",
      "\n",
      "蔣勻田_8.txt\n",
      "\n",
      "蔣勻田_9.txt\n",
      "\n",
      "雷震_1.txt\n",
      "政治(Na)腐敗(VH)的(DE)地方(Na)，(COMMACATEGORY)大陸(Nc)淪陷(VH)的(DE)罪案(Na)，(COMMACATEGORY)則(D)\n",
      "\n",
      "雷震_10.txt\n",
      "\n",
      "雷震_11.txt\n",
      "\n",
      "雷震_12.txt\n",
      "\n",
      "雷震_13.txt\n",
      "\n",
      "雷震_14.txt\n",
      "\n",
      "雷震_15.txt\n",
      "\n",
      "雷震_16.txt\n",
      "\n",
      "雷震_17.txt\n",
      "\n",
      "雷震_18.txt\n",
      "\n",
      "雷震_19.txt\n",
      "\n",
      "雷震_2.txt\n",
      "\n",
      "雷震_20.txt\n",
      "\n",
      "雷震_21.txt\n",
      "\n",
      "雷震_22.txt\n",
      "\n",
      "雷震_23.txt\n",
      "\n",
      "雷震_24.txt\n",
      "\n",
      "雷震_25.txt\n",
      "\n",
      "雷震_26.txt\n",
      "\n",
      "雷震_27.txt\n",
      "\n",
      "雷震_28.txt\n",
      "\n",
      "雷震_29.txt\n",
      "\n",
      "雷震_3.txt\n",
      "\n",
      "雷震_4.txt\n",
      "\n",
      "雷震_5.txt\n",
      "\n",
      "雷震_6.txt\n",
      "\n",
      "雷震_7.txt\n",
      "\n",
      "雷震_8.txt\n",
      "\n",
      "雷震_9.txt\n",
      "\n",
      "龍平甫_1.txt\n",
      "\n",
      "龍平甫_10.txt\n",
      "\n",
      "龍平甫_11.txt\n",
      "\n",
      "龍平甫_12.txt\n",
      "\n",
      "龍平甫_13.txt\n",
      "\n",
      "龍平甫_14.txt\n",
      "\n",
      "龍平甫_15.txt\n",
      "\n",
      "龍平甫_16.txt\n",
      "\n",
      "龍平甫_17.txt\n",
      "\n",
      "龍平甫_18.txt\n",
      "\n",
      "龍平甫_19.txt\n",
      "\n",
      "龍平甫_2.txt\n",
      "\n",
      "龍平甫_20.txt\n",
      "\n",
      "龍平甫_21.txt\n",
      "\n",
      "龍平甫_22.txt\n",
      "\n",
      "龍平甫_23.txt\n",
      "\n",
      "龍平甫_24.txt\n",
      "\n",
      "龍平甫_25.txt\n",
      "\n",
      "龍平甫_26.txt\n",
      "\n",
      "龍平甫_27.txt\n",
      "\n",
      "龍平甫_28.txt\n",
      "\n",
      "龍平甫_29.txt\n",
      "\n",
      "龍平甫_3.txt\n",
      "\n",
      "龍平甫_30.txt\n",
      "\n",
      "龍平甫_31.txt\n",
      "\n",
      "龍平甫_32.txt\n",
      "\n",
      "龍平甫_33.txt\n",
      "\n",
      "龍平甫_34.txt\n",
      "\n",
      "龍平甫_35.txt\n",
      "\n",
      "龍平甫_36.txt\n",
      "\n",
      "龍平甫_37.txt\n",
      "\n",
      "龍平甫_38.txt\n",
      "\n",
      "龍平甫_39.txt\n",
      "\n",
      "龍平甫_4.txt\n",
      "\n",
      "龍平甫_40.txt\n",
      "\n",
      "龍平甫_41.txt\n",
      "\n",
      "龍平甫_5.txt\n",
      "\n",
      "龍平甫_6.txt\n",
      "\n",
      "龍平甫_7.txt\n",
      "\n",
      "龍平甫_8.txt\n",
      "\n",
      "龍平甫_9.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "condicate_author_path = \"D:\\\\課業相關\\\\論文資料\\\\論文程式\\\\condicate\\\\author\\\\\" #候選作者文本\n",
    "condicate_topic_path = \"D:\\\\課業相關\\\\論文資料\\\\論文程式\\\\condicate\\\\topic\\\\\" #候選主題文本\n",
    "\n",
    "for file in os.listdir(condicate_author_path):\n",
    "    with codecs.open(condicate_author_path+file,'rb','utf8') as f:\n",
    "        head = f.readline()\n",
    "        content = f.readline().strip().split()\n",
    "        print (file)\n",
    "        #反共(VH)戰爭(Na) 自由(VH)中國(Nc)\n",
    "        for i in range(len(content)-1):\n",
    "            if content[i] == '大陸(Nc)' and content[i+1] == '淪陷(VH)':\n",
    "                if i > 4 and len(content) - i > 5:\n",
    "                    print (''.join(content[i-5:i+6]))\n",
    "                elif i <= 4 and len(content) - i > 5:\n",
    "                    print (''.join(content[:i+6]))\n",
    "                elif i > 4 and len(content) - i <= 5:\n",
    "                    print (''.join(content[i-5:]))\n",
    "                else:\n",
    "                    print (''.join(content))\n",
    "    print ()\n",
    "    #time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#模型觀察\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "model_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\RF result\\\\顯著特徵尋找\\\\model\\\\'\n",
    "\n",
    "def out_tree_image(model,feature,condicate_label,name):\n",
    "    dot_data = export_graphviz(model.estimators_[-1], out_file=None,\n",
    "                                filled=True,feature_names=feature,class_names=condicate_label,\n",
    "                                 proportion=True,rounded=True,special_characters=False) \n",
    "    dot_data = dot_data.replace('helvetica','kaiu') #字型調換\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    graph.write_png(\"C:\\\\Users\\\\user\\\\Desktop\\\\tree2\\\\\"+name+\".png\")\n",
    "\n",
    "for model in os.listdir(model_path):\n",
    "    clf = joblib.load(model_path+model)\n",
    "    if any(i in model for i in ['高頻','bigram','trigram','標點']):\n",
    "        continue\n",
    "    print (model.split('.')[0])\n",
    "    #print (clf.oob_decision_function_)\n",
    "    #print (clf.oob_score_)\n",
    "    \n",
    "    feature_path,condicate_label,condicate_index = find_input(' '.join(model.split('.')[0].split()[:3]))\n",
    "    temp_label = []\n",
    "    for i in condicate_label:\n",
    "        if i in model.split('.')[0].split():\n",
    "            temp_label.append(i)\n",
    "        \n",
    "    feature = []\n",
    "    with codecs.open(feature_path,'rb','utf8') as ff: #抓取基準特徵\n",
    "        for i in ff.readlines():\n",
    "            if '\\ufeff' in i: #去掉開頭BOM\n",
    "                i = i.replace('\\ufeff','')\n",
    "            if i.strip() != '':\n",
    "                feature.append(i.strip().split(',')[0])\n",
    "    \n",
    "    #print (clf.feature_importances_)\n",
    "    so = [(i[0],i[1]) for i in sorted([i for i in zip(feature,clf.feature_importances_)],key=lambda t: t[1],reverse=True)\n",
    "         if i[1] >= 0.01]\n",
    "    for index,e in enumerate(so):\n",
    "        if index < 10:\n",
    "            print (index+1,e)\n",
    "        else:\n",
    "            break\n",
    "    #out_tree_image(clf,feature,temp_label,model.split('.')[0])\n",
    "    \n",
    "    print ()\n",
    "    #time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC D+V name\n",
      "FC N+N name\n",
      "FC N+V name\n",
      "FC VH+N name\n",
      "FC 否定 name\n",
      "FC 情態 name\n",
      "FC 程度 name\n",
      "lei D+V topic\n",
      "lei N+N topic\n",
      "lei N+V topic\n",
      "lei VH+N topic\n",
      "lei 否定 topic\n",
      "lei 情態 topic\n",
      "lei 程度 topic\n",
      "FC D+V name\n",
      "FC N+N name\n",
      "FC N+V name\n",
      "FC VH+N name\n",
      "FC 否定 name\n",
      "FC 情態 name\n",
      "FC 程度 name\n",
      "lei D+V topic\n",
      "lei N+N topic\n",
      "lei N+V topic\n",
      "lei VH+N topic\n",
      "lei 否定 topic\n",
      "lei 情態 topic\n",
      "lei 程度 topic\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "#找出前10排名詞組作為預測\n",
    "input_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\RF result\\\\顯著特徵尋找\\\\'\n",
    "\n",
    "class_path1 = 'C:\\\\Users\\\\user\\\\Desktop\\\\雙類別\\\\'\n",
    "class_path2 = 'C:\\\\Users\\\\user\\\\Desktop\\\\多類別\\\\'\n",
    "\n",
    "os.remove(class_path1+'FC.txt')\n",
    "os.remove(class_path1+'lei.txt')\n",
    "os.remove(class_path2+'FC.txt')\n",
    "os.remove(class_path2+'lei.txt')\n",
    "\n",
    "for path in ['特徵值\\\\','特徵值全\\\\']:\n",
    "    for file in os.listdir(input_path+path):\n",
    "        with codecs.open(input_path+path+file,'rb','utf8') as f:\n",
    "            \n",
    "            temp_path = ''\n",
    "            if path == '特徵值\\\\':\n",
    "                temp_path = class_path1\n",
    "            elif path == '特徵值全\\\\':\n",
    "                temp_path = class_path2\n",
    "\n",
    "            if any(i in file.split('.')[0] for i in ['高頻','bigram','trigram','標點']):\n",
    "                continue\n",
    "\n",
    "            print (file.split('.')[0])\n",
    "\n",
    "            content = f.readlines()\n",
    "\n",
    "            rank_feature = defaultdict(int)\n",
    "\n",
    "            count = 2\n",
    "            index = 0\n",
    "            for line in content:\n",
    "                if count > 0:\n",
    "                    count -= 1\n",
    "                elif line.strip() == '':\n",
    "                    count = 2\n",
    "                    index = 0\n",
    "                else:\n",
    "                    rank_feature[line.strip().split()[0]] += index\n",
    "                    index += 1\n",
    "\n",
    "            so = sorted(rank_feature.items(),key=lambda t: t[1],reverse=False)\n",
    "\n",
    "            with codecs.open(temp_path+file.split('.')[0].split()[0]+'.txt','ab','utf8') as a:\n",
    "                a.write('#'+file.split('.')[0]+'\\r\\n')\n",
    "                for i,(x,y) in enumerate(so):\n",
    "                    if i == 100:\n",
    "                        break\n",
    "                    #print (i+1,x,y)\n",
    "                    a.write(x+' '+str(y)+'\\r\\n')\n",
    "                a.write('\\r\\n')\n",
    "\n",
    "            #print ()\n",
    "print ('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC 雙類別\n",
      "D+V: 39\n",
      "lei 雙類別\n",
      "D+V: 48\n",
      "FC 多類別\n",
      "D+V: 39\n",
      "lei 多類別\n",
      "D+V: 48\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "#整理出重點語言特徵\n",
    "feature_condicate = ['N+N','N+V','VH+N','D+V','否定','程度','情態']\n",
    "\n",
    "class_path1 = 'C:\\\\Users\\\\user\\\\Desktop\\\\雙類別\\\\'\n",
    "class_path2 = 'C:\\\\Users\\\\user\\\\Desktop\\\\多類別\\\\'\n",
    "\n",
    "check_num = 30\n",
    "\n",
    "for model_path in [class_path1,class_path2]:\n",
    "    for base in ['FC','lei']:\n",
    "        \n",
    "        class_path = model_path\n",
    "        search = ''\n",
    "        search2 = ''\n",
    "        \n",
    "        if base == 'FC':\n",
    "            search = 'FC'\n",
    "            search2 = 'lei'\n",
    "        elif base == 'lei':\n",
    "            search = 'lei'\n",
    "            search2 = 'topic'\n",
    "            \n",
    "        print (base,class_path.split('\\\\')[-2])\n",
    "    \n",
    "        condicate_path = ''\n",
    "        condicate_label = ''\n",
    "\n",
    "        if base == 'FC':\n",
    "            condicate_path = condicate_author_path\n",
    "            condicate_label = classification_name\n",
    "        else:\n",
    "            condicate_path = condicate_topic_path\n",
    "            condicate_label = classification_topic\n",
    "\n",
    "\n",
    "        new_feature = defaultdict(list)\n",
    "\n",
    "        with codecs.open(class_path+search+'.txt','rb','utf8') as f:\n",
    "            content = f.readlines()\n",
    "\n",
    "            name = ''\n",
    "            for line in content:\n",
    "                if line[0] == '#':\n",
    "                    name = line.strip().split()[1]\n",
    "                elif line.strip() == '':\n",
    "                    continue\n",
    "                else:\n",
    "                    new_feature[name].append(line.strip().split()[0])\n",
    "                    \n",
    "        temp_remove = []\n",
    "        for i in new_feature['D+V']:\n",
    "            if i in new_feature['否定'] or i in new_feature['程度'] or i in new_feature['情態']:\n",
    "                temp_remove.append(i)\n",
    "        for i in temp_remove:\n",
    "            new_feature['D+V'].remove(i)\n",
    "            \n",
    "        print ('D+V:',len(new_feature['D+V']))\n",
    "            \n",
    "        for k,v in new_feature.items():\n",
    "            new_feature[k] = v[:check_num]\n",
    "\n",
    "        #建立文本向量\n",
    "        def new_article_vector(X_raw,feature,condicate_label):\n",
    "\n",
    "            bi_pos_combine = ['N+N','N+V','VH+N','D+V','情態']\n",
    "            more_pos_combine = ['否定','程度']\n",
    "\n",
    "            def line_vec(line,feature,feature_file_name): #將文章轉換為特徵向量並回傳\n",
    "                temp_feature = defaultdict(int)\n",
    "\n",
    "                if any(word in feature_file_name for word in bi_pos_combine): #詞性組合\n",
    "                    line = [line[i]+line[i+1] for i in range(len(line)-1)] \n",
    "                elif any(word in feature_file_name for word in more_pos_combine): #2~3詞性組合\n",
    "                    line = [line[i]+line[i+1] for i in range(len(line)-1)] + \\\n",
    "                    [line[i]+line[i+1]+line[i+2] for i in range(len(line)-2)]\n",
    "                else: #其他常用語言特徵\n",
    "                    if 'bigram' in feature_file_name:\n",
    "                        line = [line[i].split('(')[0]+line[i+1].split('(')[0] for i in range(len(line)-1)]\n",
    "                    elif 'trigram' in feature_file_name:\n",
    "                        line = [line[i].split('(')[0]+line[i+1].split('(')[0]+\\\n",
    "                                line[i+2].split('(')[0] for i in range(len(line)-2)]\n",
    "                    else:\n",
    "                        line = [line[i].split('(')[0] for i in range(len(line))]\n",
    "\n",
    "                for i in line:\n",
    "                    if i in feature:\n",
    "                        temp_feature[i] += 1\n",
    "\n",
    "                temp_feature = [temp_feature[i] for i in feature]\n",
    "\n",
    "                return temp_feature \n",
    "\n",
    "            feature_length = 0\n",
    "            for k,v in new_feature.items():\n",
    "                feature_length += len(v)\n",
    "\n",
    "            vector_label = defaultdict(list)\n",
    "\n",
    "            for i in condicate_label:\n",
    "\n",
    "                vector_space = np.zeros((len(X_raw[i]),feature_length),np.float64)\n",
    "\n",
    "                for index,element in enumerate(X_raw[i]): #依序將文章轉換為特徵向量\n",
    "                    temp_feature = []\n",
    "                    line = element.strip().split()\n",
    "                    for j in feature_condicate:\n",
    "                        temp_feature += line_vec(line,new_feature[j],j)\n",
    "\n",
    "                    for index2,j in enumerate(temp_feature):\n",
    "                        vector_space[index,index2] = round(j * 1000000 / len(line))\n",
    "\n",
    "                vector_label[i] = vector_space\n",
    "\n",
    "            return vector_label\n",
    "\n",
    "\n",
    "        content_list = article_get(condicate_path,condicate_label)\n",
    "        vector_space = new_article_vector(content_list,new_feature,condicate_label)\n",
    "\n",
    "        with codecs.open(class_path+search+' combine.csv','wb','utf8') as g:\n",
    "            for index,e in enumerate(condicate_label):\n",
    "                for x in vector_space[e]:\n",
    "                    g.write(str(index)+','+','.join(list(map(str,x.tolist())))+'\\r\\n')\n",
    "\n",
    "print ('END')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
