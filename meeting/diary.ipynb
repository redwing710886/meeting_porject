{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#雷震日記\n",
    "#有些字無法判斷\n",
    "import xlrd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from ckip import CKIPSegmenter, CKIPParser\n",
    "segmenter = CKIPSegmenter('104753018', 'sayanouta')\n",
    "\n",
    "file = \"C:/Users/user/Desktop/雷震日記全表單-資訊處理-20160329.xls\"\n",
    "book = xlrd.open_workbook(file)\n",
    "\n",
    "#print (\"The number of worksheets is\", book.nsheets)\n",
    "#print (\"Worksheet name(s):\", book.sheet_names())\n",
    "sh = book.sheet_by_index(0)\n",
    "#print (sh.name, sh.nrows, sh.ncols)\n",
    "'''print (\"Cell D30 is\", sh.cell_value(rowx=1, colx=0))\n",
    "for rx in range(sh.nrows):\n",
    "    #print (type(sh.row(rx)[0]))\n",
    "    print (sh.cell_value(rowx=rx, colx=0))'''\n",
    "\n",
    "#16 21 29 34 36 53 55 66 68\n",
    "for rx in range(sh.nrows):\n",
    "    if rx == 0:\n",
    "        continue\n",
    "    content = sh.cell_value(rowx=rx, colx=8)\n",
    "    \n",
    "    print (rx)\n",
    "    \n",
    "    lines = []\n",
    "    temp = ''\n",
    "    \n",
    "    for word in content:\n",
    "        temp = temp + word\n",
    "        if word == '。' or word == '，':\n",
    "            lines.append(temp)\n",
    "            temp = ''\n",
    "    \n",
    "    for line in lines:\n",
    "        try:\n",
    "            segmented_result = segmenter.process(line)\n",
    "\n",
    "            words = []\n",
    "\n",
    "            if segmented_result['status_code'] != '0':\n",
    "                    print ('Process Failed: ' + segmented_result['status'])\n",
    "            else:\n",
    "                for sentence in segmented_result['result']:\n",
    "                    for term in sentence:\n",
    "                        words.append(term['term']+'('+term['pos']+')')\n",
    "                        '''if term['pos'] == 'COMMACATEGORY' or term['pos'] == 'PERIODCATEGORY' or (term['pos'] == 'QUESTIONCATEGORY' and \n",
    "                            term['pos'] == '?'):\n",
    "                            #print (' '.join(words))\n",
    "                            #print ()\n",
    "                            words = []'''\n",
    "                print (' '.join(words))\n",
    "        except:\n",
    "            e = sys.exc_info()[0]\n",
    "            print (rx,e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XML排版\n",
    "from xml.etree import ElementTree as etree\n",
    "from xml.etree.ElementTree import Element, SubElement, ElementTree\n",
    " \n",
    "#title author bookname publisher publishdate page theme keyword text\n",
    "\n",
    "root = Element('root')\n",
    "\n",
    "article = SubElement(root, 'acticle')\n",
    "article.set(\"no\", \"1\")\n",
    "\n",
    "title = SubElement(article, 'title')\n",
    "author = SubElement(article, 'author')\n",
    "bookname = SubElement(article, 'bookname')\n",
    "publisher = SubElement(article, 'publisher')\n",
    "publishdate = SubElement(article, 'publishdate')\n",
    "page = SubElement(article, 'page')\n",
    "theme= SubElement(article, 'theme')\n",
    "keyword = SubElement(article, 'keyword')\n",
    "text = SubElement(article, 'text')\n",
    "text.text = '雷震日記'\n",
    "\n",
    "tree = ElementTree(root)\n",
    "\n",
    "#tree.write('C:/Users/user/Desktop/result.xml', encoding='utf-8')\n",
    "\n",
    "xml_string = etree.tostring(root,'utf-8')\n",
    "print (xml_string.decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#建立雷震日記XML\n",
    "from xml.etree import ElementTree as etree\n",
    "from xml.etree.ElementTree import Element, SubElement, ElementTree\n",
    "import xlrd\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from ckip import CKIPSegmenter, CKIPParser\n",
    "segmenter = CKIPSegmenter('104753018', 'sayanouta')\n",
    "\n",
    "file = \"C:/Users/user/Desktop/雷震日記全表單-資訊處理-20160329.xls\"\n",
    "output_file = \"C:/Users/user/Desktop/new_diary/diary_{}.xml\"\n",
    "book = xlrd.open_workbook(file)\n",
    "sh = book.sheet_by_index(0)\n",
    " \n",
    "#title author bookname publisher publishdate page theme keyword text\n",
    "\n",
    "li = ['title','author','bookname','publisher','publishdate','page','theme','keyword']\n",
    "\n",
    "root = Element('root')\n",
    "\n",
    "ci = 0\n",
    "fail = False\n",
    "\n",
    "for rx in range(sh.nrows-ci):\n",
    "    #rx = rx + ci\n",
    "    if rx == 0:\n",
    "        continue\n",
    "    \n",
    "    article = SubElement(root, 'acticle')\n",
    "    article.set(\"no\", str(rx))\n",
    "    \n",
    "    for i in range(len(li)):\n",
    "        temp = SubElement(article,li[i])\n",
    "        if li[i] == 'publishdate':\n",
    "            a1_as_datetime = datetime.date(*xlrd.xldate_as_tuple(sh.cell_value(rowx=rx, colx=i), 0)[:3])\n",
    "            temp.text = str(a1_as_datetime)\n",
    "        else:\n",
    "            temp.text = str(sh.cell_value(rowx=rx, colx=i))\n",
    "    text = SubElement(article,'text')\n",
    "    \n",
    "    content = sh.cell_value(rowx=rx, colx=8)\n",
    "    \n",
    "    print (rx)\n",
    "    \n",
    "    lines = []\n",
    "    temp = ''\n",
    "    \n",
    "    #文章終句例外判斷?\n",
    "    for word in content:\n",
    "        temp = temp + word\n",
    "        if word == '。' or word == '，':\n",
    "            lines.append(temp.strip())\n",
    "            temp = ''\n",
    "    \n",
    "    for line in lines:\n",
    "        try:\n",
    "            segmented_result = segmenter.process(line)\n",
    "\n",
    "            words = []\n",
    "            sentence = SubElement(text, 'sentence')\n",
    "            check = False\n",
    "\n",
    "            if segmented_result['status_code'] != '0':\n",
    "                    print ('Process Failed: ' + segmented_result['status'])\n",
    "            else:\n",
    "                for sentences in segmented_result['result']:\n",
    "                    for term in sentences:\n",
    "                        if term['pos'] == 'QUESTIONCATEGORY':\n",
    "                            check = True\n",
    "                        words.append(term['term']+'('+term['pos']+')')\n",
    "                \n",
    "                if check:\n",
    "                    sentence.text = str(line)\n",
    "                    sentence.set('error','古字')\n",
    "                else:\n",
    "                    sentence.text = ' '.join(words)\n",
    "                \n",
    "        except:\n",
    "            sentence.text = str(line)\n",
    "            sentence.set('error','斷詞失敗')\n",
    "            e = sys.exc_info()[0]\n",
    "            print (rx,e)\n",
    "            #fail = True\n",
    "    \n",
    "    if rx % 10 == 0:\n",
    "        '''if fail:\n",
    "            root = Element('root')\n",
    "            rx = rx - 10\n",
    "            print ('return')\n",
    "            fail = False\n",
    "            continue'''\n",
    "        tree = ElementTree(root)\n",
    "        num = str(int(rx / 10))\n",
    "        if len(num) == 1:\n",
    "            num = '00'+num\n",
    "        elif len(num) == 2:\n",
    "            num = '0'+num\n",
    "        tree.write(output_file.format(num), encoding='utf-8')\n",
    "        root = Element('root')\n",
    "\n",
    "tree = ElementTree(root)\n",
    "tree.write(output_file.format('945'), encoding='utf-8')\n",
    "\n",
    "#xml_string = etree.tostring(root,'utf-8')\n",
    "#print (xml_string.decode('utf8'))\n",
    "print ('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diary_001.xml 189 41 0 21.69%\n",
      "diary_002.xml 315 54 0 17.14%\n",
      "diary_003.xml 331 49 2 15.41%\n",
      "diary_004.xml 281 54 1 19.57%\n",
      "diary_005.xml 223 39 0 17.49%\n",
      "diary_006.xml 322 72 0 22.36%\n",
      "diary_007.xml 329 60 0 18.24%\n",
      "diary_008.xml 223 32 0 14.35%\n",
      "diary_009.xml 259 40 0 15.44%\n",
      "diary_010.xml 204 37 0 18.14%\n",
      "diary_011.xml 207 48 0 23.19%\n",
      "diary_012.xml 288 54 0 18.75%\n",
      "diary_013.xml 306 51 1 16.99%\n",
      "diary_014.xml 278 36 0 12.95%\n",
      "diary_015.xml 436 48 1 11.24%\n",
      "diary_016.xml 220 29 0 13.18%\n",
      "diary_017.xml 223 34 1 15.7%\n",
      "diary_018.xml 418 65 1 15.79%\n",
      "diary_019.xml 500 91 2 18.6%\n",
      "diary_020.xml 265 33 0 12.45%\n",
      "diary_021.xml 326 56 0 17.18%\n",
      "diary_022.xml 292 33 0 11.3%\n",
      "diary_023.xml 257 45 0 17.51%\n",
      "diary_024.xml 436 70 0 16.06%\n",
      "diary_025.xml 260 33 0 12.69%\n",
      "diary_026.xml 444 78 0 17.57%\n",
      "diary_027.xml 458 59 1 13.1%\n",
      "diary_028.xml 518 71 0 13.71%\n",
      "diary_029.xml 452 76 1 17.04%\n",
      "diary_030.xml 439 59 0 13.44%\n",
      "diary_031.xml 476 81 0 17.02%\n",
      "diary_032.xml 390 65 2 17.18%\n",
      "diary_033.xml 317 55 0 17.35%\n",
      "diary_034.xml 291 42 0 14.43%\n",
      "diary_035.xml 383 73 1 19.32%\n",
      "diary_036.xml 355 81 0 22.82%\n",
      "diary_037.xml 392 69 0 17.6%\n",
      "diary_038.xml 408 84 0 20.59%\n",
      "diary_039.xml 321 68 0 21.18%\n",
      "diary_040.xml 463 80 0 17.28%\n",
      "diary_041.xml 401 75 1 18.95%\n",
      "diary_042.xml 394 64 1 16.5%\n",
      "diary_043.xml 225 34 0 15.11%\n",
      "diary_044.xml 277 35 0 12.64%\n",
      "diary_045.xml 280 46 0 16.43%\n",
      "diary_046.xml 349 45 0 12.89%\n",
      "diary_047.xml 317 47 1 15.14%\n",
      "diary_048.xml 307 59 0 19.22%\n",
      "diary_049.xml 309 33 0 10.68%\n",
      "diary_050.xml 331 10 2 3.63%\n",
      "diary_051.xml 333 36 0 10.81%\n",
      "diary_052.xml 281 18 3 7.47%\n",
      "diary_053.xml 254 29 1 11.81%\n",
      "diary_054.xml 260 16 0 6.15%\n",
      "diary_055.xml 278 12 0 4.32%\n",
      "diary_056.xml 209 10 0 4.78%\n",
      "diary_057.xml 259 11 0 4.25%\n",
      "diary_058.xml 302 11 0 3.64%\n",
      "diary_059.xml 290 21 0 7.24%\n",
      "diary_060.xml 280 21 0 7.5%\n",
      "diary_061.xml 230 14 0 6.09%\n",
      "diary_062.xml 224 9 0 4.02%\n",
      "diary_063.xml 281 29 0 10.32%\n",
      "diary_064.xml 235 16 0 6.81%\n",
      "diary_065.xml 182 13 0 7.14%\n",
      "diary_066.xml 213 11 0 5.16%\n",
      "diary_067.xml 237 13 0 5.49%\n",
      "diary_068.xml 211 7 0 3.32%\n",
      "diary_069.xml 245 4 0 1.63%\n",
      "diary_070.xml 207 4 0 1.93%\n",
      "diary_071.xml 277 11 0 3.97%\n",
      "diary_072.xml 286 18 0 6.29%\n",
      "diary_073.xml 245 12 0 4.9%\n",
      "diary_074.xml 327 11 0 3.36%\n",
      "diary_075.xml 261 17 1 6.9%\n",
      "diary_076.xml 150 6 0 4.0%\n",
      "diary_077.xml 225 12 0 5.33%\n",
      "diary_078.xml 225 6 0 2.67%\n",
      "diary_079.xml 145 6 0 4.14%\n",
      "diary_080.xml 195 6 0 3.08%\n",
      "diary_081.xml 208 8 0 3.85%\n",
      "diary_082.xml 148 10 0 6.76%\n",
      "diary_083.xml 183 7 1 4.37%\n",
      "diary_084.xml 150 9 0 6.0%\n",
      "diary_085.xml 108 13 1 12.96%\n",
      "diary_086.xml 352 34 0 9.66%\n",
      "diary_087.xml 243 20 0 8.23%\n",
      "diary_088.xml 381 42 1 11.29%\n",
      "diary_089.xml 511 75 1 14.87%\n",
      "diary_090.xml 641 69 0 10.76%\n",
      "diary_091.xml 141 19 0 13.48%\n",
      "diary_092.xml 211 28 1 13.74%\n",
      "diary_093.xml 231 29 0 12.55%\n",
      "diary_094.xml 194 11 0 5.67%\n",
      "diary_095.xml 196 20 0 10.2%\n",
      "diary_096.xml 146 17 0 11.64%\n",
      "diary_097.xml 210 28 2 14.29%\n",
      "diary_098.xml 203 22 0 10.84%\n",
      "diary_099.xml 184 19 0 10.33%\n",
      "diary_100.xml 263 39 3 15.97%\n",
      "diary_101.xml 245 31 0 12.65%\n",
      "diary_102.xml 249 15 1 6.43%\n",
      "diary_103.xml 178 28 0 15.73%\n",
      "diary_104.xml 121 9 0 7.44%\n",
      "diary_105.xml 102 9 0 8.82%\n",
      "diary_106.xml 181 18 0 9.94%\n",
      "diary_107.xml 150 15 0 10.0%\n",
      "diary_108.xml 175 18 0 10.29%\n",
      "diary_109.xml 276 41 0 14.86%\n",
      "diary_110.xml 202 29 0 14.36%\n",
      "diary_111.xml 116 12 0 10.34%\n",
      "diary_112.xml 308 37 0 12.01%\n",
      "diary_113.xml 203 29 0 14.29%\n",
      "diary_114.xml 157 17 0 10.83%\n",
      "diary_115.xml 150 21 0 14.0%\n",
      "diary_116.xml 187 18 0 9.63%\n",
      "diary_117.xml 196 17 1 9.18%\n",
      "diary_118.xml 177 21 0 11.86%\n",
      "diary_119.xml 192 32 0 16.67%\n",
      "diary_120.xml 173 17 0 9.83%\n",
      "diary_121.xml 181 5 0 2.76%\n",
      "diary_122.xml 204 13 0 6.37%\n",
      "diary_123.xml 144 11 0 7.64%\n",
      "diary_124.xml 187 8 0 4.28%\n",
      "diary_125.xml 126 8 0 6.35%\n",
      "diary_126.xml 161 13 0 8.07%\n",
      "diary_127.xml 128 7 0 5.47%\n",
      "diary_128.xml 116 5 0 4.31%\n",
      "diary_129.xml 187 1 0 0.53%\n",
      "diary_130.xml 120 6 0 5.0%\n",
      "diary_131.xml 150 9 0 6.0%\n",
      "diary_132.xml 145 7 0 4.83%\n",
      "diary_133.xml 226 33 0 14.6%\n",
      "diary_134.xml 199 10 0 5.03%\n",
      "diary_135.xml 112 3 0 2.68%\n",
      "diary_136.xml 134 8 0 5.97%\n",
      "diary_137.xml 221 11 0 4.98%\n",
      "diary_138.xml 178 5 0 2.81%\n",
      "diary_139.xml 109 2 0 1.83%\n",
      "diary_140.xml 100 5 0 5.0%\n",
      "diary_141.xml 142 5 0 3.52%\n",
      "diary_142.xml 106 8 0 7.55%\n",
      "diary_143.xml 55 1 0 1.82%\n",
      "diary_144.xml 190 7 0 3.68%\n",
      "diary_145.xml 125 6 0 4.8%\n",
      "diary_146.xml 187 8 1 4.81%\n",
      "diary_147.xml 152 14 0 9.21%\n",
      "diary_148.xml 199 10 0 5.03%\n",
      "diary_149.xml 149 10 0 6.71%\n",
      "diary_150.xml 185 9 0 4.86%\n",
      "diary_151.xml 180 8 0 4.44%\n",
      "diary_152.xml 183 8 0 4.37%\n",
      "diary_153.xml 200 8 1 4.5%\n",
      "diary_154.xml 164 6 0 3.66%\n",
      "diary_155.xml 207 11 2 6.28%\n",
      "diary_156.xml 362 27 0 7.46%\n",
      "diary_157.xml 322 21 0 6.52%\n",
      "diary_158.xml 147 26 0 17.69%\n",
      "diary_159.xml 212 22 0 10.38%\n",
      "diary_160.xml 140 8 1 6.43%\n",
      "diary_161.xml 128 1 0 0.78%\n",
      "diary_162.xml 190 10 1 5.79%\n",
      "diary_163.xml 199 14 2 8.04%\n",
      "diary_164.xml 244 6 0 2.46%\n",
      "diary_165.xml 194 7 0 3.61%\n",
      "diary_166.xml 178 13 0 7.3%\n",
      "diary_167.xml 197 23 0 11.68%\n",
      "diary_168.xml 110 11 1 10.91%\n",
      "diary_169.xml 217 10 0 4.61%\n",
      "diary_170.xml 161 12 1 8.07%\n",
      "diary_171.xml 145 11 0 7.59%\n",
      "diary_172.xml 180 11 0 6.11%\n",
      "diary_173.xml 108 11 0 10.19%\n",
      "diary_174.xml 134 9 0 6.72%\n",
      "diary_175.xml 154 17 0 11.04%\n",
      "diary_176.xml 177 13 0 7.34%\n",
      "diary_177.xml 199 13 0 6.53%\n",
      "diary_178.xml 152 9 0 5.92%\n",
      "diary_179.xml 181 24 0 13.26%\n",
      "diary_180.xml 240 21 0 8.75%\n",
      "diary_181.xml 233 25 0 10.73%\n",
      "diary_182.xml 230 15 0 6.52%\n",
      "diary_183.xml 136 13 0 9.56%\n",
      "diary_184.xml 175 8 0 4.57%\n",
      "diary_185.xml 183 7 0 3.83%\n",
      "diary_186.xml 228 18 0 7.89%\n",
      "diary_187.xml 185 7 1 4.32%\n",
      "diary_188.xml 322 16 0 4.97%\n",
      "diary_189.xml 278 7 0 2.52%\n",
      "diary_190.xml 173 12 0 6.94%\n",
      "diary_191.xml 142 10 0 7.04%\n",
      "diary_192.xml 248 18 0 7.26%\n",
      "diary_193.xml 211 20 0 9.48%\n",
      "diary_194.xml 173 12 0 6.94%\n",
      "diary_195.xml 151 12 0 7.95%\n",
      "diary_196.xml 137 5 0 3.65%\n",
      "diary_197.xml 202 9 0 4.46%\n",
      "diary_198.xml 299 13 0 4.35%\n",
      "diary_199.xml 297 17 0 5.72%\n",
      "diary_200.xml 160 9 0 5.62%\n",
      "diary_201.xml 275 22 0 8.0%\n",
      "diary_202.xml 196 13 0 6.63%\n",
      "diary_203.xml 245 6 0 2.45%\n",
      "diary_204.xml 157 7 0 4.46%\n",
      "diary_205.xml 136 4 0 2.94%\n",
      "diary_206.xml 110 2 0 1.82%\n",
      "diary_207.xml 202 17 1 8.91%\n",
      "diary_208.xml 60 6 0 10.0%\n",
      "diary_209.xml 86 6 0 6.98%\n",
      "diary_210.xml 100 3 1 4.0%\n",
      "diary_211.xml 157 11 0 7.01%\n",
      "diary_212.xml 122 5 1 4.92%\n",
      "diary_213.xml 136 5 0 3.68%\n",
      "diary_214.xml 117 8 0 6.84%\n",
      "diary_215.xml 152 7 0 4.61%\n",
      "diary_216.xml 190 18 2 10.53%\n",
      "diary_217.xml 196 9 0 4.59%\n",
      "diary_218.xml 162 11 0 6.79%\n",
      "diary_219.xml 262 15 0 5.73%\n",
      "diary_220.xml 183 8 0 4.37%\n",
      "diary_221.xml 132 8 0 6.06%\n",
      "diary_222.xml 143 11 0 7.69%\n",
      "diary_223.xml 126 14 0 11.11%\n",
      "diary_224.xml 150 6 0 4.0%\n",
      "diary_225.xml 154 7 0 4.55%\n",
      "diary_226.xml 166 8 0 4.82%\n",
      "diary_227.xml 255 12 0 4.71%\n",
      "diary_228.xml 194 4 0 2.06%\n",
      "diary_229.xml 274 7 0 2.55%\n",
      "diary_230.xml 292 14 0 4.79%\n",
      "diary_231.xml 319 15 0 4.7%\n",
      "diary_232.xml 341 10 0 2.93%\n",
      "diary_233.xml 236 5 0 2.12%\n",
      "diary_234.xml 253 10 0 3.95%\n",
      "diary_235.xml 241 2 0 0.83%\n",
      "diary_236.xml 239 5 0 2.09%\n",
      "diary_237.xml 273 11 0 4.03%\n",
      "diary_238.xml 292 10 1 3.77%\n",
      "diary_239.xml 307 10 0 3.26%\n",
      "diary_240.xml 240 17 0 7.08%\n",
      "diary_241.xml 253 7 0 2.77%\n",
      "diary_242.xml 286 13 0 4.55%\n",
      "diary_243.xml 345 12 1 3.77%\n",
      "diary_244.xml 330 8 0 2.42%\n",
      "diary_245.xml 345 20 0 5.8%\n",
      "diary_246.xml 229 12 0 5.24%\n",
      "diary_247.xml 292 10 0 3.42%\n",
      "diary_248.xml 211 11 0 5.21%\n",
      "diary_249.xml 314 11 0 3.5%\n",
      "diary_250.xml 296 17 0 5.74%\n",
      "diary_251.xml 310 10 0 3.23%\n",
      "diary_252.xml 322 10 0 3.11%\n",
      "diary_253.xml 230 6 0 2.61%\n",
      "diary_254.xml 222 9 0 4.05%\n",
      "diary_255.xml 172 5 0 2.91%\n",
      "diary_256.xml 167 1 0 0.6%\n",
      "diary_257.xml 147 2 0 1.36%\n",
      "diary_258.xml 234 9 0 3.85%\n",
      "diary_259.xml 167 5 0 2.99%\n",
      "diary_260.xml 163 5 0 3.07%\n",
      "diary_261.xml 223 15 0 6.73%\n",
      "diary_262.xml 200 12 0 6.0%\n",
      "diary_263.xml 161 8 0 4.97%\n",
      "diary_264.xml 234 7 0 2.99%\n",
      "diary_265.xml 182 19 0 10.44%\n",
      "diary_266.xml 204 25 0 12.25%\n",
      "diary_267.xml 254 20 0 7.87%\n",
      "diary_268.xml 299 29 0 9.7%\n",
      "diary_269.xml 232 33 0 14.22%\n",
      "diary_270.xml 250 33 0 13.2%\n",
      "diary_271.xml 254 21 0 8.27%\n",
      "diary_272.xml 216 24 0 11.11%\n",
      "diary_273.xml 330 47 0 14.24%\n",
      "diary_274.xml 237 30 0 12.66%\n",
      "diary_275.xml 186 24 1 13.44%\n",
      "diary_276.xml 251 22 1 9.16%\n",
      "diary_277.xml 195 31 0 15.9%\n",
      "diary_278.xml 191 18 0 9.42%\n",
      "diary_279.xml 160 21 0 13.12%\n",
      "diary_280.xml 247 34 0 13.77%\n",
      "diary_281.xml 174 25 0 14.37%\n",
      "diary_282.xml 211 35 1 17.06%\n",
      "diary_283.xml 215 25 0 11.63%\n",
      "diary_284.xml 133 15 0 11.28%\n",
      "diary_285.xml 246 29 0 11.79%\n",
      "diary_286.xml 182 17 0 9.34%\n",
      "diary_287.xml 213 32 0 15.02%\n",
      "diary_288.xml 266 27 0 10.15%\n",
      "diary_289.xml 256 35 1 14.06%\n",
      "diary_290.xml 257 21 0 8.17%\n",
      "diary_291.xml 201 16 1 8.46%\n",
      "diary_292.xml 138 6 0 4.35%\n",
      "diary_293.xml 177 23 0 12.99%\n",
      "diary_294.xml 233 25 0 10.73%\n",
      "diary_295.xml 209 30 0 14.35%\n",
      "diary_296.xml 213 17 0 7.98%\n",
      "diary_297.xml 279 29 0 10.39%\n",
      "diary_298.xml 223 20 0 8.97%\n",
      "diary_299.xml 211 27 0 12.8%\n",
      "diary_300.xml 204 23 0 11.27%\n",
      "diary_301.xml 255 10 0 3.92%\n",
      "diary_302.xml 309 19 0 6.15%\n",
      "diary_303.xml 227 9 0 3.96%\n",
      "diary_304.xml 192 10 0 5.21%\n",
      "diary_305.xml 268 16 0 5.97%\n",
      "diary_306.xml 355 12 0 3.38%\n",
      "diary_307.xml 202 8 0 3.96%\n",
      "diary_308.xml 213 9 0 4.23%\n",
      "diary_309.xml 320 16 0 5.0%\n",
      "diary_310.xml 219 9 0 4.11%\n",
      "diary_311.xml 249 9 0 3.61%\n",
      "diary_312.xml 163 10 0 6.13%\n",
      "diary_313.xml 229 10 0 4.37%\n",
      "diary_314.xml 51 0 0 0.0%\n",
      "diary_315.xml 129 5 0 3.88%\n",
      "diary_316.xml 134 8 0 5.97%\n",
      "diary_317.xml 184 9 0 4.89%\n",
      "diary_318.xml 136 4 0 2.94%\n",
      "diary_319.xml 135 2 0 1.48%\n",
      "diary_320.xml 150 4 0 2.67%\n",
      "diary_321.xml 201 12 0 5.97%\n",
      "diary_322.xml 118 4 0 3.39%\n",
      "diary_323.xml 174 3 0 1.72%\n",
      "diary_324.xml 293 6 0 2.05%\n",
      "diary_325.xml 158 10 0 6.33%\n",
      "diary_326.xml 261 10 0 3.83%\n",
      "diary_327.xml 186 9 0 4.84%\n",
      "diary_328.xml 77 6 0 7.79%\n",
      "diary_329.xml 115 4 0 3.48%\n",
      "diary_330.xml 182 11 0 6.04%\n",
      "diary_331.xml 209 19 0 9.09%\n",
      "diary_332.xml 295 28 0 9.49%\n",
      "diary_333.xml 241 21 0 8.71%\n",
      "diary_334.xml 195 5 0 2.56%\n",
      "diary_335.xml 185 7 0 3.78%\n",
      "diary_336.xml 197 5 0 2.54%\n",
      "diary_337.xml 145 9 0 6.21%\n",
      "diary_338.xml 208 7 0 3.37%\n",
      "diary_339.xml 102 2 0 1.96%\n",
      "diary_340.xml 89 6 0 6.74%\n",
      "diary_341.xml 234 28 0 11.97%\n",
      "diary_342.xml 167 9 0 5.39%\n",
      "diary_343.xml 126 9 1 7.94%\n",
      "diary_344.xml 160 11 0 6.88%\n",
      "diary_345.xml 157 9 0 5.73%\n",
      "diary_346.xml 149 4 0 2.68%\n",
      "diary_347.xml 119 6 1 5.88%\n",
      "diary_348.xml 127 5 0 3.94%\n",
      "diary_349.xml 118 5 0 4.24%\n",
      "diary_350.xml 137 5 0 3.65%\n",
      "diary_351.xml 108 7 0 6.48%\n",
      "diary_352.xml 73 3 0 4.11%\n",
      "diary_353.xml 131 6 0 4.58%\n",
      "diary_354.xml 184 4 0 2.17%\n",
      "diary_355.xml 155 1 0 0.65%\n",
      "diary_356.xml 187 15 0 8.02%\n",
      "diary_357.xml 203 9 0 4.43%\n",
      "diary_358.xml 119 4 0 3.36%\n",
      "diary_359.xml 72 5 0 6.94%\n",
      "diary_360.xml 101 2 0 1.98%\n",
      "diary_361.xml 168 7 0 4.17%\n",
      "diary_362.xml 108 6 0 5.56%\n",
      "diary_363.xml 202 11 0 5.45%\n",
      "diary_364.xml 126 9 0 7.14%\n",
      "diary_365.xml 146 9 0 6.16%\n",
      "diary_366.xml 161 10 0 6.21%\n",
      "diary_367.xml 147 2 0 1.36%\n",
      "diary_368.xml 281 16 0 5.69%\n",
      "diary_369.xml 244 9 0 3.69%\n",
      "diary_370.xml 300 17 0 5.67%\n",
      "diary_371.xml 82 2 0 2.44%\n",
      "diary_372.xml 261 14 0 5.36%\n",
      "diary_373.xml 209 13 0 6.22%\n",
      "diary_374.xml 300 13 0 4.33%\n",
      "diary_375.xml 218 15 0 6.88%\n",
      "diary_376.xml 160 4 0 2.5%\n",
      "diary_377.xml 273 14 1 5.49%\n",
      "diary_378.xml 259 13 0 5.02%\n",
      "diary_379.xml 390 23 0 5.9%\n",
      "diary_380.xml 180 12 0 6.67%\n",
      "diary_381.xml 225 13 0 5.78%\n",
      "diary_382.xml 308 12 0 3.9%\n",
      "diary_383.xml 272 9 0 3.31%\n",
      "diary_384.xml 139 6 0 4.32%\n",
      "diary_385.xml 77 5 0 6.49%\n",
      "diary_386.xml 205 8 0 3.9%\n",
      "diary_387.xml 120 6 0 5.0%\n",
      "diary_388.xml 177 15 0 8.47%\n",
      "diary_389.xml 149 7 1 5.37%\n",
      "diary_390.xml 237 2 0 0.84%\n",
      "diary_391.xml 182 6 0 3.3%\n",
      "diary_392.xml 115 5 0 4.35%\n",
      "diary_393.xml 142 12 0 8.45%\n",
      "diary_394.xml 228 11 0 4.82%\n",
      "diary_395.xml 145 7 0 4.83%\n",
      "diary_396.xml 87 3 0 3.45%\n",
      "diary_397.xml 93 6 0 6.45%\n",
      "diary_398.xml 81 2 1 3.7%\n",
      "diary_399.xml 123 4 0 3.25%\n",
      "diary_400.xml 204 4 0 1.96%\n",
      "diary_401.xml 148 4 0 2.7%\n",
      "diary_402.xml 223 12 0 5.38%\n",
      "diary_403.xml 251 11 1 4.78%\n",
      "diary_404.xml 64 3 0 4.69%\n",
      "diary_405.xml 105 3 1 3.81%\n",
      "diary_406.xml 170 8 0 4.71%\n",
      "diary_407.xml 72 7 0 9.72%\n",
      "diary_408.xml 181 13 0 7.18%\n",
      "diary_409.xml 288 11 0 3.82%\n",
      "diary_410.xml 150 4 0 2.67%\n",
      "diary_411.xml 155 13 0 8.39%\n",
      "diary_412.xml 198 8 0 4.04%\n",
      "diary_413.xml 238 13 1 5.88%\n",
      "diary_414.xml 188 14 0 7.45%\n",
      "diary_415.xml 166 9 0 5.42%\n",
      "diary_416.xml 255 5 0 1.96%\n",
      "diary_417.xml 260 8 1 3.46%\n",
      "diary_418.xml 246 7 0 2.85%\n",
      "diary_419.xml 311 9 1 3.22%\n",
      "diary_420.xml 254 7 0 2.76%\n",
      "diary_421.xml 206 9 0 4.37%\n",
      "diary_422.xml 276 11 1 4.35%\n",
      "diary_423.xml 227 9 0 3.96%\n",
      "diary_424.xml 113 3 0 2.65%\n",
      "diary_425.xml 143 10 0 6.99%\n",
      "diary_426.xml 183 1 0 0.55%\n",
      "diary_427.xml 184 4 0 2.17%\n",
      "diary_428.xml 161 8 0 4.97%\n",
      "diary_429.xml 138 8 0 5.8%\n",
      "diary_430.xml 138 6 0 4.35%\n",
      "diary_431.xml 166 6 0 3.61%\n",
      "diary_432.xml 157 4 0 2.55%\n",
      "diary_433.xml 182 7 0 3.85%\n",
      "diary_434.xml 299 7 0 2.34%\n",
      "diary_435.xml 237 13 0 5.49%\n",
      "diary_436.xml 116 3 0 2.59%\n",
      "diary_437.xml 110 3 0 2.73%\n",
      "diary_438.xml 176 9 0 5.11%\n",
      "diary_439.xml 154 30 0 19.48%\n",
      "diary_440.xml 111 15 0 13.51%\n",
      "diary_441.xml 114 25 0 21.93%\n",
      "diary_442.xml 185 35 0 18.92%\n",
      "diary_443.xml 293 46 0 15.7%\n",
      "diary_444.xml 280 43 0 15.36%\n",
      "diary_445.xml 211 40 0 18.96%\n",
      "diary_446.xml 197 29 0 14.72%\n",
      "diary_447.xml 258 32 0 12.4%\n",
      "diary_448.xml 139 20 0 14.39%\n",
      "diary_449.xml 265 43 0 16.23%\n",
      "diary_450.xml 241 38 0 15.77%\n",
      "diary_451.xml 220 41 0 18.64%\n",
      "diary_452.xml 257 50 0 19.46%\n",
      "diary_453.xml 210 37 0 17.62%\n",
      "diary_454.xml 181 35 0 19.34%\n",
      "diary_455.xml 242 34 0 14.05%\n",
      "diary_456.xml 273 41 0 15.02%\n",
      "diary_457.xml 207 27 0 13.04%\n",
      "diary_458.xml 229 30 0 13.1%\n",
      "diary_459.xml 114 15 0 13.16%\n",
      "diary_460.xml 130 28 0 21.54%\n",
      "diary_461.xml 145 23 0 15.86%\n",
      "diary_462.xml 152 13 0 8.55%\n",
      "diary_463.xml 141 29 0 20.57%\n",
      "diary_464.xml 207 33 0 15.94%\n",
      "diary_465.xml 218 36 0 16.51%\n",
      "diary_466.xml 123 16 0 13.01%\n",
      "diary_467.xml 175 18 0 10.29%\n",
      "diary_468.xml 158 23 0 14.56%\n",
      "diary_469.xml 156 19 0 12.18%\n",
      "diary_470.xml 127 16 0 12.6%\n",
      "diary_471.xml 128 21 0 16.41%\n",
      "diary_472.xml 139 24 0 17.27%\n",
      "diary_473.xml 206 26 0 12.62%\n",
      "diary_474.xml 220 31 1 14.55%\n",
      "diary_475.xml 236 42 0 17.8%\n",
      "diary_476.xml 181 23 0 12.71%\n",
      "diary_477.xml 215 32 0 14.88%\n",
      "diary_478.xml 239 39 0 16.32%\n",
      "diary_479.xml 139 26 0 18.71%\n",
      "diary_480.xml 223 31 1 14.35%\n",
      "diary_481.xml 239 35 0 14.64%\n",
      "diary_482.xml 218 28 0 12.84%\n",
      "diary_483.xml 197 25 0 12.69%\n",
      "diary_484.xml 294 37 0 12.59%\n",
      "diary_485.xml 213 35 0 16.43%\n",
      "diary_486.xml 141 18 0 12.77%\n",
      "diary_487.xml 240 35 0 14.58%\n",
      "diary_488.xml 211 43 0 20.38%\n",
      "diary_489.xml 262 41 0 15.65%\n",
      "diary_490.xml 225 34 1 15.56%\n",
      "diary_491.xml 225 28 0 12.44%\n",
      "diary_492.xml 210 29 1 14.29%\n",
      "diary_493.xml 264 36 1 14.02%\n",
      "diary_494.xml 200 30 1 15.5%\n",
      "diary_495.xml 258 40 0 15.5%\n",
      "diary_496.xml 180 26 0 14.44%\n",
      "diary_497.xml 499 69 2 14.23%\n",
      "diary_498.xml 644 69 0 10.71%\n",
      "diary_499.xml 544 71 1 13.24%\n",
      "diary_500.xml 213 20 0 9.39%\n",
      "diary_501.xml 194 22 0 11.34%\n",
      "diary_502.xml 303 25 0 8.25%\n",
      "diary_503.xml 240 27 0 11.25%\n",
      "diary_504.xml 212 15 0 7.08%\n",
      "diary_505.xml 220 25 0 11.36%\n",
      "diary_506.xml 198 32 0 16.16%\n",
      "diary_507.xml 131 22 0 16.79%\n",
      "diary_508.xml 205 27 0 13.17%\n",
      "diary_509.xml 162 29 0 17.9%\n",
      "diary_510.xml 192 19 0 9.9%\n",
      "diary_511.xml 164 16 0 9.76%\n",
      "diary_512.xml 128 12 0 9.38%\n",
      "diary_513.xml 210 24 0 11.43%\n",
      "diary_514.xml 212 21 0 9.91%\n",
      "diary_515.xml 202 22 0 10.89%\n",
      "diary_516.xml 229 39 0 17.03%\n",
      "diary_517.xml 198 28 0 14.14%\n",
      "diary_518.xml 129 24 0 18.6%\n",
      "diary_519.xml 198 28 0 14.14%\n",
      "diary_520.xml 162 20 0 12.35%\n",
      "diary_521.xml 161 24 0 14.91%\n",
      "diary_522.xml 137 18 0 13.14%\n",
      "diary_523.xml 176 21 0 11.93%\n",
      "diary_524.xml 134 17 0 12.69%\n",
      "diary_525.xml 103 7 0 6.8%\n",
      "diary_526.xml 170 26 0 15.29%\n",
      "diary_527.xml 157 17 0 10.83%\n",
      "diary_528.xml 212 21 0 9.91%\n",
      "diary_529.xml 101 10 0 9.9%\n",
      "diary_530.xml 149 19 1 13.42%\n",
      "diary_531.xml 195 27 0 13.85%\n",
      "diary_532.xml 218 33 1 15.6%\n",
      "diary_533.xml 198 19 1 10.1%\n",
      "diary_534.xml 201 19 0 9.45%\n",
      "diary_535.xml 306 40 0 13.07%\n",
      "diary_536.xml 288 40 0 13.89%\n",
      "diary_537.xml 298 34 1 11.74%\n",
      "diary_538.xml 314 61 0 19.43%\n",
      "diary_539.xml 359 51 0 14.21%\n",
      "diary_540.xml 370 48 1 13.24%\n",
      "diary_541.xml 288 38 1 13.54%\n",
      "diary_542.xml 208 34 0 16.35%\n",
      "diary_543.xml 258 27 0 10.47%\n",
      "diary_544.xml 287 37 0 12.89%\n",
      "diary_545.xml 230 24 1 10.87%\n",
      "diary_546.xml 159 23 0 14.47%\n",
      "diary_547.xml 264 47 0 17.8%\n",
      "diary_548.xml 209 23 0 11.0%\n",
      "diary_549.xml 294 38 0 12.93%\n",
      "diary_550.xml 218 20 0 9.17%\n",
      "diary_551.xml 226 24 0 10.62%\n",
      "diary_552.xml 232 19 0 8.19%\n",
      "diary_553.xml 244 26 0 10.66%\n",
      "diary_554.xml 341 36 0 10.56%\n",
      "diary_555.xml 189 26 0 13.76%\n",
      "diary_556.xml 201 27 0 13.43%\n",
      "diary_557.xml 347 49 0 14.12%\n",
      "diary_558.xml 220 30 0 13.64%\n",
      "diary_559.xml 258 35 0 13.57%\n",
      "diary_560.xml 393 53 0 13.49%\n",
      "diary_561.xml 294 40 0 13.61%\n",
      "diary_562.xml 297 48 0 16.16%\n",
      "diary_563.xml 304 34 0 11.18%\n",
      "diary_564.xml 259 30 0 11.58%\n",
      "diary_565.xml 301 37 0 12.29%\n",
      "diary_566.xml 285 41 0 14.39%\n",
      "diary_567.xml 309 30 0 9.71%\n",
      "diary_568.xml 213 27 0 12.68%\n",
      "diary_569.xml 204 24 0 11.76%\n",
      "diary_570.xml 248 30 0 12.1%\n",
      "diary_571.xml 227 30 1 13.66%\n",
      "diary_572.xml 341 37 0 10.85%\n",
      "diary_573.xml 346 48 0 13.87%\n",
      "diary_574.xml 283 26 0 9.19%\n",
      "diary_575.xml 362 30 0 8.29%\n",
      "diary_576.xml 174 20 0 11.49%\n",
      "diary_577.xml 339 30 0 8.85%\n",
      "diary_578.xml 330 35 0 10.61%\n",
      "diary_579.xml 156 16 0 10.26%\n",
      "diary_580.xml 194 26 0 13.4%\n",
      "diary_581.xml 212 23 1 11.32%\n",
      "diary_582.xml 170 19 0 11.18%\n",
      "diary_583.xml 127 11 0 8.66%\n",
      "diary_584.xml 241 33 0 13.69%\n",
      "diary_585.xml 192 33 0 17.19%\n",
      "diary_586.xml 250 34 0 13.6%\n",
      "diary_587.xml 263 43 1 16.73%\n",
      "diary_588.xml 207 25 0 12.08%\n",
      "diary_589.xml 213 14 0 6.57%\n",
      "diary_590.xml 321 36 0 11.21%\n",
      "diary_591.xml 227 20 1 9.25%\n",
      "diary_592.xml 245 31 0 12.65%\n",
      "diary_593.xml 260 28 1 11.15%\n",
      "diary_594.xml 190 25 0 13.16%\n",
      "diary_595.xml 227 22 1 10.13%\n",
      "diary_596.xml 132 13 0 9.85%\n",
      "diary_597.xml 234 32 0 13.68%\n",
      "diary_598.xml 203 27 0 13.3%\n",
      "diary_599.xml 305 34 0 11.15%\n",
      "diary_600.xml 194 22 0 11.34%\n",
      "diary_601.xml 171 19 0 11.11%\n",
      "diary_602.xml 353 43 0 12.18%\n",
      "diary_603.xml 168 15 0 8.93%\n",
      "diary_604.xml 194 24 0 12.37%\n",
      "diary_605.xml 175 17 0 9.71%\n",
      "diary_606.xml 138 21 0 15.22%\n",
      "diary_607.xml 177 29 0 16.38%\n",
      "diary_608.xml 168 27 0 16.07%\n",
      "diary_609.xml 222 26 0 11.71%\n",
      "diary_610.xml 306 37 0 12.09%\n",
      "diary_611.xml 271 23 0 8.49%\n",
      "diary_612.xml 172 24 0 13.95%\n",
      "diary_613.xml 115 19 0 16.52%\n",
      "diary_614.xml 202 26 0 12.87%\n",
      "diary_615.xml 207 30 0 14.49%\n",
      "diary_616.xml 168 18 0 10.71%\n",
      "diary_617.xml 142 17 0 11.97%\n",
      "diary_618.xml 224 29 0 12.95%\n",
      "diary_619.xml 127 16 0 12.6%\n",
      "diary_620.xml 133 11 0 8.27%\n",
      "diary_621.xml 134 13 0 9.7%\n",
      "diary_622.xml 125 20 0 16.0%\n",
      "diary_623.xml 100 12 0 12.0%\n",
      "diary_624.xml 135 14 0 10.37%\n",
      "diary_625.xml 149 21 0 14.09%\n",
      "diary_626.xml 168 17 0 10.12%\n",
      "diary_627.xml 103 14 0 13.59%\n",
      "diary_628.xml 243 22 1 9.47%\n",
      "diary_629.xml 145 18 0 12.41%\n",
      "diary_630.xml 187 21 0 11.23%\n",
      "diary_631.xml 114 7 0 6.14%\n",
      "diary_632.xml 107 11 0 10.28%\n",
      "diary_633.xml 149 16 0 10.74%\n",
      "diary_634.xml 183 20 0 10.93%\n",
      "diary_635.xml 224 32 0 14.29%\n",
      "diary_636.xml 70 6 0 8.57%\n",
      "diary_637.xml 252 34 0 13.49%\n",
      "diary_638.xml 134 17 0 12.69%\n",
      "diary_639.xml 196 25 0 12.76%\n",
      "diary_640.xml 209 33 0 15.79%\n",
      "diary_641.xml 122 13 0 10.66%\n",
      "diary_642.xml 163 21 0 12.88%\n",
      "diary_643.xml 128 16 0 12.5%\n",
      "diary_644.xml 121 12 0 9.92%\n",
      "diary_645.xml 212 29 0 13.68%\n",
      "diary_646.xml 291 27 0 9.28%\n",
      "diary_647.xml 150 24 0 16.0%\n",
      "diary_648.xml 216 22 1 10.65%\n",
      "diary_649.xml 335 35 1 10.75%\n",
      "diary_650.xml 195 24 0 12.31%\n",
      "diary_651.xml 154 22 0 14.29%\n",
      "diary_652.xml 211 32 0 15.17%\n",
      "diary_653.xml 97 12 0 12.37%\n",
      "diary_654.xml 200 20 0 10.0%\n",
      "diary_655.xml 154 20 0 12.99%\n",
      "diary_656.xml 150 16 1 11.33%\n",
      "diary_657.xml 212 41 0 19.34%\n",
      "diary_658.xml 122 20 0 16.39%\n",
      "diary_659.xml 132 11 0 8.33%\n",
      "diary_660.xml 147 22 0 14.97%\n",
      "diary_661.xml 179 25 0 13.97%\n",
      "diary_662.xml 129 12 0 9.3%\n",
      "diary_663.xml 214 23 0 10.75%\n",
      "diary_664.xml 134 10 0 7.46%\n",
      "diary_665.xml 150 14 0 9.33%\n",
      "diary_666.xml 124 12 1 10.48%\n",
      "diary_667.xml 146 14 0 9.59%\n",
      "diary_668.xml 60 7 0 11.67%\n",
      "diary_669.xml 213 19 1 9.39%\n",
      "diary_670.xml 211 17 0 8.06%\n",
      "diary_671.xml 133 11 0 8.27%\n",
      "diary_672.xml 77 9 0 11.69%\n",
      "diary_673.xml 166 17 0 10.24%\n",
      "diary_674.xml 101 11 0 10.89%\n",
      "diary_675.xml 127 16 0 12.6%\n",
      "diary_676.xml 143 23 0 16.08%\n",
      "diary_677.xml 107 10 0 9.35%\n",
      "diary_678.xml 110 4 0 3.64%\n",
      "diary_679.xml 78 13 0 16.67%\n",
      "diary_680.xml 223 28 0 12.56%\n",
      "diary_681.xml 187 27 0 14.44%\n",
      "diary_682.xml 176 19 0 10.8%\n",
      "diary_683.xml 143 12 0 8.39%\n",
      "diary_684.xml 232 14 0 6.03%\n",
      "diary_685.xml 170 17 0 10.0%\n",
      "diary_686.xml 103 9 0 8.74%\n",
      "diary_687.xml 136 15 0 11.03%\n",
      "diary_688.xml 191 25 0 13.09%\n",
      "diary_689.xml 119 9 0 7.56%\n",
      "diary_690.xml 182 23 0 12.64%\n",
      "diary_691.xml 191 20 0 10.47%\n",
      "diary_692.xml 149 13 0 8.72%\n",
      "diary_693.xml 154 16 0 10.39%\n",
      "diary_694.xml 173 18 0 10.4%\n",
      "diary_695.xml 125 15 0 12.0%\n",
      "diary_696.xml 157 8 0 5.1%\n",
      "diary_697.xml 120 13 0 10.83%\n",
      "diary_698.xml 146 12 0 8.22%\n",
      "diary_699.xml 197 16 0 8.12%\n",
      "diary_700.xml 110 10 0 9.09%\n",
      "diary_701.xml 148 12 0 8.11%\n",
      "diary_702.xml 155 31 0 20.0%\n",
      "diary_703.xml 118 17 0 14.41%\n",
      "diary_704.xml 98 9 0 9.18%\n",
      "diary_705.xml 112 12 0 10.71%\n",
      "diary_706.xml 107 7 1 7.48%\n",
      "diary_707.xml 84 10 1 13.1%\n",
      "diary_708.xml 109 17 0 15.6%\n",
      "diary_709.xml 119 12 0 10.08%\n",
      "diary_710.xml 47 2 0 4.26%\n",
      "diary_711.xml 91 6 0 6.59%\n",
      "diary_712.xml 157 16 0 10.19%\n",
      "diary_713.xml 135 16 0 11.85%\n",
      "diary_714.xml 124 15 0 12.1%\n",
      "diary_715.xml 202 8 0 3.96%\n",
      "diary_716.xml 100 11 0 11.0%\n",
      "diary_717.xml 159 22 0 13.84%\n",
      "diary_718.xml 196 20 0 10.2%\n",
      "diary_719.xml 235 21 0 8.94%\n",
      "diary_720.xml 114 7 0 6.14%\n",
      "diary_721.xml 81 6 0 7.41%\n",
      "diary_722.xml 171 19 0 11.11%\n",
      "diary_723.xml 282 29 0 10.28%\n",
      "diary_724.xml 247 22 0 8.91%\n",
      "diary_725.xml 201 15 0 7.46%\n",
      "diary_726.xml 112 9 0 8.04%\n",
      "diary_727.xml 129 12 0 9.3%\n",
      "diary_728.xml 147 15 0 10.2%\n",
      "diary_729.xml 177 14 0 7.91%\n",
      "diary_730.xml 73 7 0 9.59%\n",
      "diary_731.xml 137 8 0 5.84%\n",
      "diary_732.xml 171 24 0 14.04%\n",
      "diary_733.xml 132 8 0 6.06%\n",
      "diary_734.xml 111 9 0 8.11%\n",
      "diary_735.xml 199 15 0 7.54%\n",
      "diary_736.xml 170 15 0 8.82%\n",
      "diary_737.xml 167 12 0 7.19%\n",
      "diary_738.xml 86 3 0 3.49%\n",
      "diary_739.xml 101 5 0 4.95%\n",
      "diary_740.xml 146 17 0 11.64%\n",
      "diary_741.xml 103 7 0 6.8%\n",
      "diary_742.xml 176 18 0 10.23%\n",
      "diary_743.xml 109 7 0 6.42%\n",
      "diary_744.xml 161 15 0 9.32%\n",
      "diary_745.xml 142 7 0 4.93%\n",
      "diary_746.xml 163 25 0 15.34%\n",
      "diary_747.xml 132 11 0 8.33%\n",
      "diary_748.xml 123 7 0 5.69%\n",
      "diary_749.xml 158 16 0 10.13%\n",
      "diary_750.xml 136 13 0 9.56%\n",
      "diary_751.xml 61 2 0 3.28%\n",
      "diary_752.xml 53 2 0 3.77%\n",
      "diary_753.xml 91 9 0 9.89%\n",
      "diary_754.xml 147 18 0 12.24%\n",
      "diary_755.xml 83 3 0 3.61%\n",
      "diary_756.xml 127 4 0 3.15%\n",
      "diary_757.xml 143 16 0 11.19%\n",
      "diary_758.xml 143 7 0 4.9%\n",
      "diary_759.xml 153 12 0 7.84%\n",
      "diary_760.xml 78 3 0 3.85%\n",
      "diary_761.xml 143 7 0 4.9%\n",
      "diary_762.xml 55 3 0 5.45%\n",
      "diary_763.xml 101 10 0 9.9%\n",
      "diary_764.xml 154 13 0 8.44%\n",
      "diary_765.xml 187 11 0 5.88%\n",
      "diary_766.xml 132 18 0 13.64%\n",
      "diary_767.xml 142 9 0 6.34%\n",
      "diary_768.xml 65 8 0 12.31%\n",
      "diary_769.xml 100 13 0 13.0%\n",
      "diary_770.xml 82 3 0 3.66%\n",
      "diary_771.xml 128 11 0 8.59%\n",
      "diary_772.xml 85 8 0 9.41%\n",
      "diary_773.xml 135 24 0 17.78%\n",
      "diary_774.xml 89 9 0 10.11%\n",
      "diary_775.xml 184 23 0 12.5%\n",
      "diary_776.xml 144 19 0 13.19%\n",
      "diary_777.xml 162 17 0 10.49%\n",
      "diary_778.xml 183 29 0 15.85%\n",
      "diary_779.xml 108 7 0 6.48%\n",
      "diary_780.xml 175 28 0 16.0%\n",
      "diary_781.xml 208 31 0 14.9%\n",
      "diary_782.xml 198 24 0 12.12%\n",
      "diary_783.xml 116 12 0 10.34%\n",
      "diary_784.xml 168 10 0 5.95%\n",
      "diary_785.xml 182 17 0 9.34%\n",
      "diary_786.xml 245 28 2 12.24%\n",
      "diary_787.xml 219 29 0 13.24%\n",
      "diary_788.xml 152 19 0 12.5%\n",
      "diary_789.xml 173 15 0 8.67%\n",
      "diary_790.xml 162 21 0 12.96%\n",
      "diary_791.xml 176 18 0 10.23%\n",
      "diary_792.xml 190 17 0 8.95%\n",
      "diary_793.xml 164 27 0 16.46%\n",
      "diary_794.xml 171 28 0 16.37%\n",
      "diary_795.xml 238 30 0 12.61%\n",
      "diary_796.xml 245 21 0 8.57%\n",
      "diary_797.xml 99 18 0 18.18%\n",
      "diary_798.xml 281 29 0 10.32%\n",
      "diary_799.xml 259 32 0 12.36%\n",
      "diary_800.xml 202 27 0 13.37%\n",
      "diary_801.xml 90 11 0 12.22%\n",
      "diary_802.xml 75 4 0 5.33%\n",
      "diary_803.xml 200 29 0 14.5%\n",
      "diary_804.xml 122 14 0 11.48%\n",
      "diary_805.xml 134 10 0 7.46%\n",
      "diary_806.xml 164 17 0 10.37%\n",
      "diary_807.xml 82 6 0 7.32%\n",
      "diary_808.xml 75 8 1 12.0%\n",
      "diary_809.xml 190 17 0 8.95%\n",
      "diary_810.xml 119 12 0 10.08%\n",
      "diary_811.xml 174 20 0 11.49%\n",
      "diary_812.xml 160 21 0 13.12%\n",
      "diary_813.xml 234 30 0 12.82%\n",
      "diary_814.xml 175 23 0 13.14%\n",
      "diary_815.xml 79 7 0 8.86%\n",
      "diary_816.xml 79 11 0 13.92%\n",
      "diary_817.xml 128 16 0 12.5%\n",
      "diary_818.xml 194 15 0 7.73%\n",
      "diary_819.xml 191 26 0 13.61%\n",
      "diary_820.xml 239 25 0 10.46%\n",
      "diary_821.xml 194 25 0 12.89%\n",
      "diary_822.xml 354 46 0 12.99%\n",
      "diary_823.xml 113 13 0 11.5%\n",
      "diary_824.xml 143 13 0 9.09%\n",
      "diary_825.xml 108 9 0 8.33%\n",
      "diary_826.xml 104 10 0 9.62%\n",
      "diary_827.xml 201 17 0 8.46%\n",
      "diary_828.xml 108 8 0 7.41%\n",
      "diary_829.xml 145 14 0 9.66%\n",
      "diary_830.xml 122 7 0 5.74%\n",
      "diary_831.xml 147 12 0 8.16%\n",
      "diary_832.xml 111 7 0 6.31%\n",
      "diary_833.xml 71 3 0 4.23%\n",
      "diary_834.xml 92 11 0 11.96%\n",
      "diary_835.xml 106 5 0 4.72%\n",
      "diary_836.xml 168 21 0 12.5%\n",
      "diary_837.xml 140 15 0 10.71%\n",
      "diary_838.xml 132 12 0 9.09%\n",
      "diary_839.xml 94 11 0 11.7%\n",
      "diary_840.xml 96 11 0 11.46%\n",
      "diary_841.xml 104 10 0 9.62%\n",
      "diary_842.xml 86 9 0 10.47%\n",
      "diary_843.xml 88 10 0 11.36%\n",
      "diary_844.xml 201 24 0 11.94%\n",
      "diary_845.xml 178 21 0 11.8%\n",
      "diary_846.xml 247 28 0 11.34%\n",
      "diary_847.xml 173 42 0 24.28%\n",
      "diary_848.xml 215 34 0 15.81%\n",
      "diary_849.xml 245 37 1 15.51%\n",
      "diary_850.xml 219 33 0 15.07%\n",
      "diary_851.xml 174 21 0 12.07%\n",
      "diary_852.xml 285 36 0 12.63%\n",
      "diary_853.xml 178 21 1 12.36%\n",
      "diary_854.xml 243 22 0 9.05%\n",
      "diary_855.xml 127 13 0 10.24%\n",
      "diary_856.xml 146 22 0 15.07%\n",
      "diary_857.xml 149 19 0 12.75%\n",
      "diary_858.xml 207 24 0 11.59%\n",
      "diary_859.xml 163 23 0 14.11%\n",
      "diary_860.xml 192 22 0 11.46%\n",
      "diary_861.xml 206 30 0 14.56%\n",
      "diary_862.xml 193 16 0 8.29%\n",
      "diary_863.xml 186 21 1 11.83%\n",
      "diary_864.xml 111 8 0 7.21%\n",
      "diary_865.xml 227 17 0 7.49%\n",
      "diary_866.xml 177 30 0 16.95%\n",
      "diary_867.xml 132 9 0 6.82%\n",
      "diary_868.xml 155 22 0 14.19%\n",
      "diary_869.xml 170 30 0 17.65%\n",
      "diary_870.xml 121 20 0 16.53%\n",
      "diary_871.xml 145 20 0 13.79%\n",
      "diary_872.xml 144 19 0 13.19%\n",
      "diary_873.xml 107 12 0 11.21%\n",
      "diary_874.xml 159 21 0 13.21%\n",
      "diary_875.xml 81 3 0 3.7%\n",
      "diary_876.xml 123 13 0 10.57%\n",
      "diary_877.xml 151 19 0 12.58%\n",
      "diary_878.xml 147 11 0 7.48%\n",
      "diary_879.xml 105 6 0 5.71%\n",
      "diary_880.xml 114 15 0 13.16%\n",
      "diary_881.xml 77 8 0 10.39%\n",
      "diary_882.xml 84 7 0 8.33%\n",
      "diary_883.xml 77 6 0 7.79%\n",
      "diary_884.xml 151 15 0 9.93%\n",
      "diary_885.xml 99 9 0 9.09%\n",
      "diary_886.xml 138 20 0 14.49%\n",
      "diary_887.xml 100 13 0 13.0%\n",
      "diary_888.xml 83 6 0 7.23%\n",
      "diary_889.xml 76 4 0 5.26%\n",
      "diary_890.xml 145 12 0 8.28%\n",
      "diary_891.xml 127 11 0 8.66%\n",
      "diary_892.xml 111 12 0 10.81%\n",
      "diary_893.xml 89 5 0 5.62%\n",
      "diary_894.xml 112 11 0 9.82%\n",
      "diary_895.xml 140 14 0 10.0%\n",
      "diary_896.xml 116 22 0 18.97%\n",
      "diary_897.xml 92 9 0 9.78%\n",
      "diary_898.xml 65 6 0 9.23%\n",
      "diary_899.xml 135 14 0 10.37%\n",
      "diary_900.xml 39 3 0 7.69%\n",
      "diary_901.xml 56 8 0 14.29%\n",
      "diary_902.xml 86 11 0 12.79%\n",
      "diary_903.xml 97 11 0 11.34%\n",
      "diary_904.xml 115 21 0 18.26%\n",
      "diary_905.xml 53 1 0 1.89%\n",
      "diary_906.xml 39 2 0 5.13%\n",
      "diary_907.xml 91 6 0 6.59%\n",
      "diary_908.xml 138 14 0 10.14%\n",
      "diary_909.xml 164 14 0 8.54%\n",
      "diary_910.xml 177 25 0 14.12%\n",
      "diary_911.xml 96 21 0 21.88%\n",
      "diary_912.xml 220 34 0 15.45%\n",
      "diary_913.xml 70 4 0 5.71%\n",
      "diary_914.xml 136 8 0 5.88%\n",
      "diary_915.xml 107 12 0 11.21%\n",
      "diary_916.xml 172 18 0 10.47%\n",
      "diary_917.xml 102 6 0 5.88%\n",
      "diary_918.xml 54 4 0 7.41%\n",
      "diary_919.xml 74 11 0 14.86%\n",
      "diary_920.xml 137 20 0 14.6%\n",
      "diary_921.xml 133 15 0 11.28%\n",
      "diary_922.xml 74 8 0 10.81%\n",
      "diary_923.xml 76 9 0 11.84%\n",
      "diary_924.xml 91 3 0 3.3%\n",
      "diary_925.xml 124 13 0 10.48%\n",
      "diary_926.xml 116 9 0 7.76%\n",
      "diary_927.xml 93 11 0 11.83%\n",
      "diary_928.xml 124 15 0 12.1%\n",
      "diary_929.xml 157 22 0 14.01%\n",
      "diary_930.xml 178 17 0 9.55%\n",
      "diary_931.xml 148 10 0 6.76%\n",
      "diary_932.xml 112 9 0 8.04%\n",
      "diary_933.xml 141 13 0 9.22%\n",
      "diary_934.xml 85 7 0 8.24%\n",
      "diary_935.xml 57 4 0 7.02%\n",
      "diary_936.xml 129 10 2 9.3%\n",
      "diary_937.xml 81 11 0 13.58%\n",
      "diary_938.xml 77 6 0 7.79%\n",
      "diary_939.xml 56 2 0 3.57%\n",
      "diary_940.xml 77 8 0 10.39%\n",
      "diary_941.xml 62 6 0 9.68%\n",
      "diary_942.xml 152 21 0 13.82%\n",
      "diary_943.xml 197 13 0 6.6%\n",
      "diary_944.xml 164 21 0 12.8%\n",
      "diary_945.xml 32 3 0 9.38%\n",
      "180742 17923 108 9.98%\n"
     ]
    }
   ],
   "source": [
    "#問題句子所在比例分析\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import time\n",
    "\n",
    "file_path = \"C:/Users/user/Desktop/temp/\"\n",
    "file_list = []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    file_list.append(file)\n",
    "\n",
    "all_num = 0\n",
    "all_error_word = 0  \n",
    "all_error_split = 0\n",
    "\n",
    "for file in file_list:\n",
    "    tree = ET.parse(file_path+file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    num = 0\n",
    "    error_word = 0\n",
    "    error_split = 0\n",
    "\n",
    "    \n",
    "    for child in root:\n",
    "        for sentence in child[8]:\n",
    "            num = num + 1\n",
    "            if len(sentence.attrib) > 0:\n",
    "                if sentence.attrib['error'] == '古字':\n",
    "                    error_word = error_word + 1\n",
    "                elif sentence.attrib['error'] == '斷詞失敗':\n",
    "                    error_split = error_split + 1\n",
    "                else:\n",
    "                    print ('other')\n",
    "    error_count = (error_word+error_split)*100/num\n",
    "    print (file,num,error_word,error_split,str(round(error_count,2))+'%')\n",
    "    \n",
    "    all_num = all_num + num\n",
    "    all_error_word = all_error_word + error_word\n",
    "    all_error_split = all_error_split + error_split\n",
    "    \n",
    "print (all_num,all_error_word,all_error_split,str(round((all_error_split+all_error_word)*100/all_num,2))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "37\n",
      "14964\n",
      "18031\n",
      "要(ADV) 4474\n",
      "可(ADV) 2178\n",
      "得(T) 1628\n",
      "可以(ADV) 1015\n",
      "應(ADV) 946\n",
      "會(ADV) 897\n",
      "該(DET) 603\n",
      "能(ADV) 537\n",
      "要(Vt) 403\n",
      "當(P) 352\n",
      "必須(ADV) 338\n",
      "須(ADV) 320\n",
      "會(N) 209\n",
      "應該(ADV) 209\n",
      "得(Vt) 176\n",
      "該(ADV) 161\n",
      "得(ADV) 91\n",
      "需要(Vt) 88\n",
      "需(Vt) 55\n",
      "當(Vt) 48\n",
      "當(ADV) 36\n",
      "可(Vi) 36\n",
      "能夠(ADV) 35\n",
      "需(ADV) 27\n",
      "應(P) 21\n",
      "能(Vt) 17\n",
      "可以(Vi) 17\n",
      "應該(Vi) 12\n",
      "需要(N) 11\n",
      "會(Vt) 7\n",
      "應當(ADV) 6\n",
      "應(Vt) 5\n",
      "要(Nv) 2\n",
      "能(N) 1\n",
      "需(Nv) 1\n",
      "當(N) 1\n",
      "得(ASP) 1\n"
     ]
    }
   ],
   "source": [
    "#diary XML內容抓取 one 情態動詞\n",
    "import codecs\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import sys\n",
    "\n",
    "modalverb = [\"應\",\"要\",\"可\",\"能\",\"可以\",\"須\",\"應該\",\"必須\",\"會\",\"得\",\"需要\",\"當\",\"應當\",\"能夠\",\"該\",\"需\"]\n",
    "file_path = '../../desktop/temp/'\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    file_list.append(file)\n",
    "\n",
    "one_verb = {} \n",
    "    \n",
    "error_num = 0\n",
    "skip = 0\n",
    "\n",
    "for file in file_list:\n",
    "    \n",
    "    tree = ET.parse(file_path+file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for sentence in root.iter('sentence'):\n",
    "        if len(sentence.attrib) > 0:\n",
    "            skip = skip + 1\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            temp = sentence.text.split()\n",
    "\n",
    "            verb_list = []\n",
    "            \n",
    "            for i in temp:\n",
    "                word = i.split('(')\n",
    "                word[1] = '('+word[1].split('[')[0]\n",
    "\n",
    "                if word[0] in modalverb:\n",
    "                    verb_list.append(''.join(word))\n",
    "\n",
    "            if len(verb_list) > 0:\n",
    "                for l in verb_list:\n",
    "                    if l in one_verb:\n",
    "                        one_verb[l] = one_verb[l] + 1\n",
    "                    else:\n",
    "                        one_verb[l] = 1\n",
    "     \n",
    "        except:\n",
    "            '''e = sys.exc_info()[0]\n",
    "            print (e)\n",
    "            time.sleep(0.3)'''\n",
    "            error_num = error_num + 1\n",
    "\n",
    "one_verb_count = 0\n",
    "\n",
    "for i in one_verb:\n",
    "    one_verb_count = one_verb_count + one_verb[i]\n",
    "\n",
    "print (error_num) #0\n",
    "print (len(one_verb)) #37\n",
    "print (one_verb_count) #14964\n",
    "print (skip) #18031\n",
    "\n",
    "one_verb = sorted(one_verb.items(), key=lambda d:d[1], reverse = True)\n",
    "\n",
    "for i in one_verb:\n",
    "    print (i[0],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "14\n",
      "160\n",
      "561\n",
      "17989\n",
      "162873\n",
      "('要(ADV)', '能(ADV)') 41\n",
      "('當(P)', '可(ADV)') 40\n",
      "('可(ADV)', '得(Vt)') 29\n",
      "('要(ADV)', '可(ADV)') 21\n",
      "('該(ADV)', '會(ADV)') 16\n",
      "('該(DET)', '會(N)') 16\n",
      "('要(ADV)', '要(ADV)') 14\n",
      "('可(ADV)', '得(T)') 12\n",
      "('要(ADV)', '會(ADV)') 12\n",
      "('會(ADV)', '要(ADV)') 11\n",
      "('應(ADV)', '可(ADV)') 11\n",
      "('可以(ADV)', '得(T)') 10\n",
      "('該(DET)', '可(ADV)') 9\n",
      "('必須(ADV)', '可(ADV)') 8\n",
      "('須(ADV)', '可(ADV)') 8\n",
      "('要(ADV)', '該(DET)') 8\n",
      "('當(ADV)', '可(ADV)') 8\n",
      "('必須(ADV)', '能(ADV)') 8\n",
      "('可(ADV)', '可(ADV)') 7\n",
      "('得(T)', '要(ADV)') 7\n",
      "('該(DET)', '要(ADV)') 7\n",
      "('會(ADV)', '會(N)') 6\n",
      "('要(ADV)', '應(ADV)') 6\n",
      "('必須(ADV)', '要(ADV)') 6\n",
      "('會(ADV)', '可以(ADV)') 5\n",
      "('要(ADV)', '得(T)') 5\n",
      "('會(ADV)', '會(ADV)') 5\n",
      "('要(ADV)', '可以(ADV)') 5\n",
      "('能(ADV)', '能(ADV)') 5\n",
      "('應(ADV)', '要(ADV)') 5\n",
      "('要(Vt)', '要(ADV)') 5\n",
      "('該(DET)', '得(T)') 5\n",
      "('要(ADV)', '能(Vt)') 5\n",
      "('可以(ADV)', '得(Vt)') 4\n",
      "('該(DET)', '會(ADV)') 4\n",
      "('要(ADV)', '得(Vt)') 4\n",
      "('應(ADV)', '應(ADV)') 4\n",
      "('應(ADV)', '會(ADV)') 3\n",
      "('會(N)', '會(ADV)') 3\n",
      "('該(DET)', '可以(ADV)') 3\n",
      "('能(ADV)', '得(T)') 3\n",
      "('會(ADV)', '得(T)') 3\n",
      "('要(ADV)', '要(Vt)') 3\n",
      "('可(ADV)', '要(ADV)') 3\n",
      "('應(ADV)', '得(Vt)') 3\n",
      "('能(ADV)', '可(ADV)') 3\n",
      "('能(ADV)', '可以(ADV)') 3\n",
      "('需(Vt)', '可(ADV)') 3\n",
      "('需(ADV)', '可(ADV)') 3\n",
      "('當(P)', '能(ADV)') 3\n",
      "('會(ADV)', '可(ADV)') 3\n",
      "('當(P)', '要(ADV)') 3\n",
      "('應該(ADV)', '可以(ADV)') 2\n",
      "('可以(ADV)', '可以(ADV)') 2\n",
      "('要(ADV)', '能夠(ADV)') 2\n",
      "('應(ADV)', '該(ADV)') 2\n",
      "('要(ADV)', '必須(ADV)') 2\n",
      "('要(ADV)', '會(N)') 2\n",
      "('當(P)', '該(DET)') 2\n",
      "('會(ADV)', '能(ADV)') 2\n",
      "('必須(ADV)', '可以(ADV)') 2\n",
      "('該(DET)', '要(Vt)') 2\n",
      "('要(ADV)', '須(ADV)') 2\n",
      "('該(ADV)', '要(ADV)') 2\n",
      "('需要(Vt)', '可(ADV)') 2\n",
      "('會(ADV)', '需要(Vt)') 2\n",
      "('可(ADV)', '應(ADV)') 2\n",
      "('必須(ADV)', '會(ADV)') 2\n",
      "('可(ADV)', '要(Vt)') 2\n",
      "('可以(ADV)', '當(P)') 2\n",
      "('應(ADV)', '得(T)') 2\n",
      "('須(ADV)', '會(ADV)') 2\n",
      "('得(T)', '得(Vt)') 2\n",
      "('可(ADV)', '必須(ADV)') 2\n",
      "('要(ADV)', '該(ADV)') 2\n",
      "('應(ADV)', '該(DET)') 2\n",
      "('須(ADV)', '可(Vi)') 2\n",
      "('能(ADV)', '要(ADV)') 2\n",
      "('得(ADV)', '要(ADV)') 1\n",
      "('該(DET)', '該(DET)') 1\n",
      "('得(T)', '可(ADV)') 1\n",
      "('得(Vt)', '可(ADV)') 1\n",
      "('該(ADV)', '可(ADV)') 1\n",
      "('能(ADV)', '會(ADV)') 1\n",
      "('能(ADV)', '得(Vt)') 1\n",
      "('當(P)', '應該(ADV)') 1\n",
      "('必須(ADV)', '得(T)') 1\n",
      "('應(ADV)', '須(ADV)') 1\n",
      "('需要(Vt)', '能(Vt)') 1\n",
      "('須(ADV)', '要(ADV)') 1\n",
      "('要(Vt)', '能(ADV)') 1\n",
      "('要(Vt)', '得(T)') 1\n",
      "('會(N)', '應該(ADV)') 1\n",
      "('需(ADV)', '要(ADV)') 1\n",
      "('當(ADV)', '應(ADV)') 1\n",
      "('必須(ADV)', '應(ADV)') 1\n",
      "('當(P)', '可以(ADV)') 1\n",
      "('得(Vt)', '要(ADV)') 1\n",
      "('能夠(ADV)', '能(ADV)') 1\n",
      "('當(P)', '得(T)') 1\n",
      "('可以(ADV)', '應(ADV)') 1\n",
      "('可(ADV)', '得(ADV)') 1\n",
      "('會(N)', '要(ADV)') 1\n",
      "('需要(Vt)', '該(DET)') 1\n",
      "('應(ADV)', '能(ADV)') 1\n",
      "('會(ADV)', '須(ADV)') 1\n",
      "('當(ADV)', '可以(ADV)') 1\n",
      "('須(ADV)', '當(Vt)') 1\n",
      "('會(ADV)', '應(ADV)') 1\n",
      "('當(P)', '會(ADV)') 1\n",
      "('得(ADV)', '會(ADV)') 1\n",
      "('得(T)', '該(DET)') 1\n",
      "('當(Vt)', '可(Vi)') 1\n",
      "('會(N)', '能(ADV)') 1\n",
      "('能(ADV)', '要(Vt)') 1\n",
      "('須(ADV)', '能(ADV)') 1\n",
      "('要(ADV)', '當(P)') 1\n",
      "('該(DET)', '當(Vt)') 1\n",
      "('可(ADV)', '需(Vt)') 1\n",
      "('可(ADV)', '可以(ADV)') 1\n",
      "('該(ADV)', '能(ADV)') 1\n",
      "('該(DET)', '能夠(ADV)') 1\n",
      "('會(ADV)', '需(ADV)') 1\n",
      "('應該(ADV)', '應(ADV)') 1\n",
      "('應該(ADV)', '當(Vt)') 1\n",
      "('可(ADV)', '該(DET)') 1\n",
      "('能(ADV)', '需要(Vt)') 1\n",
      "('可以(ADV)', '可(ADV)') 1\n",
      "('可(ADV)', '應該(ADV)') 1\n",
      "('必須(ADV)', '能(Vt)') 1\n",
      "('應(ADV)', '要(Vt)') 1\n",
      "('當(P)', '要(Vt)') 1\n",
      "('當(P)', '應(ADV)') 1\n",
      "('可以(ADV)', '得(ADV)') 1\n",
      "('要(Vt)', '可(ADV)') 1\n",
      "('可以(ADV)', '當(Vt)') 1\n",
      "('必須(ADV)', '可(Vi)') 1\n",
      "('可(ADV)', '會(N)') 1\n",
      "('要(ADV)', '需要(Vt)') 1\n",
      "('需(Vt)', '必須(ADV)') 1\n",
      "('應該(ADV)', '得(T)') 1\n",
      "('當(Vt)', '要(ADV)') 1\n",
      "('應(ADV)', '應(Vt)') 1\n",
      "('會(Vt)', '會(ADV)') 1\n",
      "('當(P)', '可(Vi)') 1\n",
      "('當(ADV)', '會(ADV)') 1\n",
      "('會(ADV)', '要(Vt)') 1\n",
      "('需(Vt)', '可以(ADV)') 1\n",
      "('可(ADV)', '會(ADV)') 1\n",
      "('可(ADV)', '需要(Vt)') 1\n",
      "('須(ADV)', '得(T)') 1\n",
      "('應(ADV)', '必須(ADV)') 1\n",
      "('得(ADV)', '可(ADV)') 1\n",
      "('可(Vi)', '要(ADV)') 1\n",
      "('該(ADV)', '得(Vt)') 1\n",
      "('可以(ADV)', '會(ADV)') 1\n",
      "('必須(ADV)', '能夠(ADV)') 1\n",
      "('需要(Vt)', '會(ADV)') 1\n",
      "('須(ADV)', '須(ADV)') 1\n",
      "('要(Vt)', '會(ADV)') 1\n"
     ]
    }
   ],
   "source": [
    "#diary XML內容抓取 pair情態動詞\n",
    "import codecs\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import sys\n",
    "\n",
    "modalverb = [\"應\",\"要\",\"可\",\"能\",\"可以\",\"須\",\"應該\",\"必須\",\"會\",\"得\",\"需要\",\"當\",\"應當\",\"能夠\",\"該\",\"需\"]\n",
    "file_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\SNA\\\\meeting\\\\source\\\\diary\\\\'\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    file_list.append(file)\n",
    "\n",
    "two_verb = {} \n",
    "    \n",
    "error_num = 0\n",
    "much = 0\n",
    "skip = 0\n",
    "index_line = 0\n",
    "\n",
    "for file in file_list:\n",
    "    \n",
    "    tree = ET.parse(file_path+file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for sentence in root.iter('sentence'):\n",
    "        if len(sentence.attrib) > 0:\n",
    "            skip = skip + 1\n",
    "            continue\n",
    "        \n",
    "        index_line = index_line + 1\n",
    "            \n",
    "        try:\n",
    "            temp = sentence.text.split()\n",
    "\n",
    "            verb_list = []\n",
    "            \n",
    "            for i in temp:\n",
    "                word = i.split('(')\n",
    "                word[1] = '('+word[1].split('[')[0]\n",
    "\n",
    "                if word[0] in modalverb:\n",
    "                    verb_list.append(''.join(word))\n",
    "\n",
    "            if len(verb_list) >= 2:\n",
    "                if len(verb_list) >= 3:\n",
    "                    much = much + 1\n",
    "                for l in range(len(verb_list)-1):\n",
    "                    k = l + 1\n",
    "                    if (verb_list[l],verb_list[k]) in two_verb:\n",
    "                        two_verb[(verb_list[l],verb_list[k])] = two_verb[(verb_list[l],verb_list[k])] + 1\n",
    "                    else:\n",
    "                        two_verb[(verb_list[l],verb_list[k])] = 1\n",
    "     \n",
    "        except:\n",
    "            '''e = sys.exc_info()[0]\n",
    "            print (e)\n",
    "            time.sleep(0.3)'''\n",
    "            error_num = error_num + 1\n",
    "\n",
    "pop = []\n",
    "\n",
    "#是否照順序\n",
    "'''for i in two_verb:\n",
    "    if (i[1],i[0]) in two_verb and i not in pop and i[0] != i[1]:\n",
    "        two_verb[i] = two_verb[i] + two_verb[(i[1],i[0])]\n",
    "        pop.append((i[1],i[0]))\n",
    "\n",
    "print (len(two_verb)) #230/614\n",
    "print (len(pop)) #101/188\n",
    "for j in pop:\n",
    "    two_verb.pop(j)'''\n",
    "\n",
    "two_verb_count = 0\n",
    "\n",
    "for i in two_verb:\n",
    "    two_verb_count = two_verb_count + two_verb[i]\n",
    "\n",
    "two_verb = sorted(two_verb.items(), key=lambda d:d[1], reverse = True)\n",
    "\n",
    "print (error_num) #0\n",
    "print (much) #14\n",
    "print (len(two_verb)) #160\n",
    "print (two_verb_count) #561\n",
    "print (skip) #18031\n",
    "print (index_line)\n",
    "\n",
    "for i in two_verb:\n",
    "    print (i[0],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "並(C)謂(Vt)\u001b[31;46m可(ADV)\u001b[0m候岳軍(N)回來(Vi)再(ADV)說(Vt)，(COMMACATEGORY)\n",
      "樊(b)、(PAUSECATEGORY)胡(N)主張(Vt)\u001b[31;46m可(ADV)\u001b[0m退(Vi)而(C)不能(ADV)登報(Vi)使(Vt)其(DET)崩潰(Vi)。(PERIODCATEGORY)\n",
      "而(C)張(N)則(ADV)謂(Vt)此(DET)機關(N)\u001b[31;46m可(ADV)\u001b[0m設立(Vt)，(COMMACATEGORY)\n",
      "但(C)副總統(N)\u001b[31;46m可(ADV)\u001b[0m自由(Vi)競選(Vt)，(COMMACATEGORY)\n",
      "並(C)云(Vt)今日(N)之(T)共黨(N)遠(Vi)非(Vt)民(N)元(N)時(POST)之(T)袁世凱(N)\u001b[31;46m可(ADV)\u001b[0m比(P)云(Vt)，(COMMACATEGORY)\n",
      "只(ADV)有(Vt)哲生(N)主持(Vt)始(ADV)\u001b[31;46m可(ADV)\u001b[0m安定(Vt)，(COMMACATEGORY)\n",
      "依(P)資望(N)或(C)見解(N)((PARENTHESISCATEGORY)在(P)已(ADV)選出(Vt)之(T)立委(N)中(POST))(PARENTHESISCATEGORY)只(ADV)有(Vt)哲(N)生(Vt)一(DET)人(N)\u001b[31;46m可(ADV)\u001b[0m任(Vt)，(COMMACATEGORY)\n",
      "亦(ADV)\u001b[31;46m可(ADV)\u001b[0m副北(N)人(N)之(T)希望(Vt)也(T)。(PERIODCATEGORY)\n",
      "則(ADV)\u001b[31;46m可(ADV)\u001b[0m選(Vt)吳鐵城任(N)之(T)，(COMMACATEGORY)\n",
      "悉(Vt)民社黨(N)決定(Vt)下(DET)週二(N)該(DET)黨(N)立委(N)\u001b[31;46m可(ADV)\u001b[0m報到(Vi)也(T)，(COMMACATEGORY)\n",
      "蔣(N)、(PAUSECATEGORY)孫(N)二(DET)君告(N)以(P)民社黨(N)立委(N)今晚(N)\u001b[31;46m可(ADV)\u001b[0m坐車(Vi)來(POST)京報(N)到(Vt)，(COMMACATEGORY)\n",
      "深(Vi)\u001b[31;46m可(ADV)\u001b[0m欽佩(Vt)與(C)歡迎(Vt)。(PERIODCATEGORY)\n",
      "下午(N)蔡(N)\u001b[31;46m可(ADV)\u001b[0m成(Vt)夫人(N)由(P)杭(N)來(Vi)京(N)，(COMMACATEGORY)\n",
      "僅(ADV)\u001b[31;46m可(ADV)\u001b[0m派(Vt)人(N)去(ADV)疏通(Vt)。(PERIODCATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m提(Vt)楊永浚(N)，(COMMACATEGORY)\n",
      "渠(N)云(Vt)\u001b[31;46m可(ADV)\u001b[0m設法(Vt)，(COMMACATEGORY)\n",
      "餘(Vt)二(DET)項(M)\u001b[31;46m可(ADV)\u001b[0m採用(Vt)，(COMMACATEGORY)\n",
      "俾(C)\u001b[31;46m可(ADV)\u001b[0m有(Vt)機會(N)參加(Vt)訓練(N)工作(N)、(PAUSECATEGORY)深造(Vi)及(C)求(Vt)上進(Vi)云(Vt)。(PERIODCATEGORY)\n",
      "必須(ADV)大熱(N)始(ADV)\u001b[31;46m可(ADV)\u001b[0m豐收(Vi)。(PERIODCATEGORY)\n",
      "公務員(N)懲戒(Nv)委員(N)\u001b[31;46m可(ADV)\u001b[0m容納(Vt)數(DET)人(N)，(COMMACATEGORY)\n",
      "渠(N)謂(Vt)民社(N)\u001b[31;46m可(ADV)\u001b[0m得(Vt)一(DET)評(Vt)事(N)及(C)懲戒(Nv)委員(N)，(COMMACATEGORY)\n",
      "今後(N)更(ADV)\u001b[31;46m可(ADV)\u001b[0m有(Vt)藉口(N)也(T)。(PERIODCATEGORY)\n",
      "其(DET)責任(N)是否(ADV)中紡(N)公司(N)\u001b[31;46m可(ADV)\u001b[0m負責(Vt)起來(Vi)，(COMMACATEGORY)\n",
      "最後(N)決定(Vt)必要(N)時(POST)\u001b[31;46m可(ADV)\u001b[0m延至(Vt)九月(N)底(POST)。(PERIODCATEGORY)\n",
      "如(P)七(DET)月份(N)之(T)生活(N)指數(N)\u001b[31;46m可(ADV)\u001b[0m用盡(Vt)此(DET)八萬億(DET)元(M)也(T)。(PERIODCATEGORY)\n",
      "始(ADV)\u001b[31;46m可(ADV)\u001b[0m與(P)共黨(N)週旋(Vi)，(COMMACATEGORY)\n",
      "日本(N)亦(ADV)\u001b[31;46m可(ADV)\u001b[0m從(P)技術(N)方面(N)協助(Vt)之(T)。(PERIODCATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m令(Vt)華僑(N)協助(Vt)政府(N)也(T)。(PERIODCATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m及(C)關(N)內(N)二分之一(DET)，(COMMACATEGORY)\n",
      "殊(ADV)\u001b[31;46m可(ADV)\u001b[0m驚人(Vi)。(PERIODCATEGORY)\n",
      "每(DET)日(M)\u001b[31;46m可(ADV)\u001b[0m出(Vt)四十五萬(DET)份(M)，(COMMACATEGORY)\n",
      "應(ADV)請(Vt)明(Vi)劍(N)兄(N)照(P)此(DET)辦理(Vt)\u001b[31;46m可(ADV)\u001b[0m也(ADV)。(PERIODCATEGORY)\n",
      "西德(N)問題(N)\u001b[31;46m可(ADV)\u001b[0m由(P)四(DET)國(N)外交(N)方式(N)解決(Vt)，(COMMACATEGORY)\n",
      "一(DET)、(PAUSECATEGORY)二(DET)年(M)亦(ADV)\u001b[31;46m可(ADV)\u001b[0m渡過(Vt)難關(N)也(T)。(PERIODCATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m不顧(Vt)一切(DET)，(COMMACATEGORY)\n",
      "謂(Vt)廠方(N)每(DET)月(N)\u001b[31;46m可(ADV)\u001b[0m出(Vt)租金(N)麵粉(N)一百(DET)包(M)，(COMMACATEGORY)\n",
      "而(C)新幣(N)則(ADV)非(ADV)在(P)此(DET)三(DET)個(M)月(N)予以(ADV)穩定(Vt)則(ADV)不(ADV)\u001b[31;46m可(ADV)\u001b[0m也(ADV)，(COMMACATEGORY)\n",
      "報紙(N)\u001b[31;46m可(ADV)\u001b[0m減至(Vt)日出(Vi)一(DET)張(M)，(COMMACATEGORY)\n",
      "儘(ADV)\u001b[31;46m可(ADV)\u001b[0m撤換(Vt)，(COMMACATEGORY)\n",
      "名稱(N)當(ADV)\u001b[31;46m可(ADV)\u001b[0m改(Vt)之(T)。(PERIODCATEGORY)\n",
      "何(DET)敬(N)之(T)尚(ADV)有(Vt)一段(N)話(N)不(ADV)\u001b[31;46m可(ADV)\u001b[0m不(ADV)記(Vt)，(COMMACATEGORY)\n",
      "除非(C)投降(Vi)則(ADV)\u001b[31;46m可(ADV)\u001b[0m不要(ADV)花錢(Vi)。(PERIODCATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m省處(N)亦(ADV)應(ADV)節省(Vt)，(COMMACATEGORY)\n",
      "總統(N)則(ADV)謂(Vt)\u001b[31;46m可(ADV)\u001b[0m不(ADV)經(P)立法院(N)而(C)增加(Vt)二(DET)人(N)，(COMMACATEGORY)\n",
      "行政院(N)原(A)規定(N)政務(N)委員(N)\u001b[31;46m可(ADV)\u001b[0m撥(Vt)車(N)一(DET)輛(M)，(COMMACATEGORY)\n",
      "以後(N)說話(Vi)幾(DET)無(Vt)人(N)\u001b[31;46m可(ADV)\u001b[0m相信(Vt)也(T)。(PERIODCATEGORY)\n",
      "我(N)\u001b[31;46m可(ADV)\u001b[0m出來(Vi)任(Vt)此(DET)工作(N)云云(T)。(PERIODCATEGORY)\n",
      "渠(N)云(Vt)我(N)\u001b[31;46m可(ADV)\u001b[0m去(ADV)見見(Vt)總統(N)，(COMMACATEGORY)\n",
      "渠(N)說(Vt)本(DET)黨(N)所(ADV)提(Vt)之(T)人均(N)無(Vt)資格(N)\u001b[31;46m可(ADV)\u001b[0m言(Vt)，(COMMACATEGORY)\n",
      "俾(C)通車(Vi)\u001b[31;46m可(ADV)\u001b[0m增(Vt)安全(Vi)，(COMMACATEGORY)\n",
      "任何(DET)人(N)都(ADV)\u001b[31;46m可(ADV)\u001b[0m坐車(Vi)，(COMMACATEGORY)\n",
      "一旦(C)必要(N)需(ADV)用(Vt)時(POST)仍(ADV)\u001b[31;46m可(ADV)\u001b[0m有效(Vi)，(COMMACATEGORY)\n",
      "車主(N)可以(ADV)此(DET)油(N)使(Vt)他(N)車(N)仍(ADV)\u001b[31;46m可(ADV)\u001b[0m走動(Vi)也(T)。(PERIODCATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m防(Vt)蟲(N)又(ADV)\u001b[31;46m可(ADV)\u001b[0m殺(Vt)蟲(N)也(T)。(PERIODCATEGORY)\n",
      "誠(ADV)\u001b[31;46m可(ADV)\u001b[0m駭人(Vi)，(COMMACATEGORY)\n",
      "金(Vi)元(M)券(N)之前(POST)途(N)不(ADV)言(Vt)\u001b[31;46m可(ADV)\u001b[0m知(Vt)，(COMMACATEGORY)\n",
      "殊(ADV)\u001b[31;46m可(ADV)\u001b[0m駭人(Vi)。(PERIODCATEGORY)\n",
      "松岫(N)當(ADV)\u001b[31;46m可(ADV)\u001b[0m補(Vt)，(COMMACATEGORY)\n",
      "要(ADV)鐵(N)老(Vi)答應(Vt)始(ADV)\u001b[31;46m可(ADV)\u001b[0m，(COMMACATEGORY)\n",
      "觀(Vt)其(DET)以(P)所(ADV)藏(Vt)金銀(N)兌換(Vt)金(N)元(M)券(N)\u001b[31;46m可(ADV)\u001b[0m知(Vt)，(COMMACATEGORY)\n",
      "日(N)\u001b[31;46m可(ADV)\u001b[0m出(Vt)一(DET)、(PAUSECATEGORY)二十(DET)噸(M)也(ADV)，(COMMACATEGORY)\n",
      "預計(Vt)六月(N)後(POST)\u001b[31;46m可(ADV)\u001b[0m出(Vt)煤(N)。(PERIODCATEGORY)\n",
      "其(DET)習慣(N)自(P)非(Vt)一(DET)日(M)\u001b[31;46m可(ADV)\u001b[0m改(Vt)，(COMMACATEGORY)\n",
      "軍隊(N)核實(Vi)自(P)\u001b[31;46m可(ADV)\u001b[0m矯正(Vt)，(COMMACATEGORY)\n",
      "反(ADV)\u001b[31;46m可(ADV)\u001b[0m利用(Vt)，(COMMACATEGORY)\n",
      "行政院長(N)人選(N)亦(ADV)\u001b[31;46m可(ADV)\u001b[0m由(P)此(DET)處(M)產生(Vt)，(COMMACATEGORY)\n",
      "當(P)\u001b[31;46m可(ADV)\u001b[0m阻止(Vt)。(PERIODCATEGORY)\n",
      "亦(ADV)\u001b[31;46m可(ADV)\u001b[0m云(Vt)秋高氣爽(Vi)。(PERIODCATEGORY)\n",
      "謂(Vt)一切(DET)\u001b[31;46m可(ADV)\u001b[0m代(P)其(DET)計劃(N)，(COMMACATEGORY)\n",
      "此(DET)案(N)請(Vt)作(Vt)原則(N)之(T)決定(N)\u001b[31;46m可(ADV)\u001b[0m也(ADV)。(PERIODCATEGORY)\n",
      "原金元(N)二元(A)\u001b[31;46m可(ADV)\u001b[0m兌(Vt)銀幣(N)壹(DET)元(M)，(COMMACATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m同時(N)以(P)壹(DET)千金(N)元(N)兌(Vt)黃金(N)一兩(DET)或(C)存(Vt)金元(N)十(DET)元(M)，(COMMACATEGORY)\n",
      "另(C)以(P)十(DET)元(M)\u001b[31;46m可(ADV)\u001b[0m兌(Vt)銀幣(N)一(DET)元(M)；(SEMICOLONCATEGORY)修正案(N)其(DET)主要(A)精神(N)在(P)此(DET)，(COMMACATEGORY)\n",
      "由(P)政府(N)及(C)美援(N)款(N)內(N)\u001b[31;46m可(ADV)\u001b[0m撥(Vt)八千萬(DET)美元(M)作(Vt)基金(N)。(PERIODCATEGORY)\n",
      "當(P)\u001b[31;46m可(ADV)\u001b[0m設法(Vt)通過(Vt)。(PERIODCATEGORY)\n",
      "或(C)\u001b[31;46m可(ADV)\u001b[0m與(P)共黨(N)決(Vt)一(DET)雌雄(N)，(COMMACATEGORY)\n",
      "無(Vt)地(N)\u001b[31;46m可(ADV)\u001b[0m容(Vt)，(COMMACATEGORY)\n",
      "詢問(Vt)補助費(N)事(N)何時(N)\u001b[31;46m可(ADV)\u001b[0m發下(Vt)，(COMMACATEGORY)\n",
      "拂丞(N)、(PAUSECATEGORY)粲(b)生來(ADV)告(Vt)公務員(N)每(DET)人(N)\u001b[31;46m可(ADV)\u001b[0m購(Vt)黃金(N)五兩(DET)。(PERIODCATEGORY)\n",
      "報告(N)新閣(N)不日(ADV)\u001b[31;46m可(ADV)\u001b[0m成(Vt)，(COMMACATEGORY)\n",
      "林(N)\u001b[31;46m可(ADV)\u001b[0m識(Vt)晨(N)來(ADV)談(Vt)，(COMMACATEGORY)\n",
      "其(DET)頑固(Vi)\u001b[31;46m可(ADV)\u001b[0m知(Vt)，(COMMACATEGORY)\n",
      "白(Vi)秘書(N)工作(N)\u001b[31;46m可(ADV)\u001b[0m繼(P)潘鳳騫(N)之(T)缺(Nv)，(COMMACATEGORY)\n",
      "我(N)退職(Vi)後(POST)\u001b[31;46m可(ADV)\u001b[0m解決(Vt)一(DET)個(M)問題(N)。(PERIODCATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m得(Vt)小安(N)，(COMMACATEGORY)\n",
      "則(ADV)一切(DET)\u001b[31;46m可(ADV)\u001b[0m上軌道(Vi)也(T)。(PERIODCATEGORY)\n",
      "俾(C)\u001b[31;46m可(ADV)\u001b[0m共同(ADV)負責(Vt)，(COMMACATEGORY)\n",
      "仍(ADV)\u001b[31;46m可(ADV)\u001b[0m再(ADV)來(ADV)。(PERIODCATEGORY)\n",
      "雪艇告(N)以(P)今日(N)非(Vt)十七(DET)年(M)\u001b[31;46m可(ADV)\u001b[0m比(Vt)也(T)。(PERIODCATEGORY)\n",
      "一切(DET)方(ADV)\u001b[31;46m可(ADV)\u001b[0m改革(Vt)，(COMMACATEGORY)\n",
      "或(C)持(Vt)湯公(N)片子(N)亦(ADV)\u001b[31;46m可(ADV)\u001b[0m，(COMMACATEGORY)\n",
      "俾(C)旅客(N)\u001b[31;46m可(ADV)\u001b[0m從容(Vi)入舟(N)也(ADV)，(COMMACATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m由(P)此(DET)門(M)入(Vt)。(PERIODCATEGORY)\n",
      "必須(ADV)許多(DET)次(M)始(ADV)\u001b[31;46m可(ADV)\u001b[0m搬上(Vt)也(T)。(PERIODCATEGORY)\n",
      "其(DET)無(Vt)秩序(N)\u001b[31;46m可(ADV)\u001b[0m想(Vt)而(C)知(Vt)，(COMMACATEGORY)\n",
      "使(Vt)主和(Vi)者(N)無言(Vi)\u001b[31;46m可(ADV)\u001b[0m說(Vt)，(COMMACATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m云(Vt)超黨派(N)的(T)聯合(Nv)反共(Nv)人士(N)，(COMMACATEGORY)\n",
      "且(C)\u001b[31;46m可(ADV)\u001b[0m進入(Vt)地(N)下(POST)。(PERIODCATEGORY)\n",
      "渠(N)意(N)\u001b[31;46m可(ADV)\u001b[0m用(P)指導(Vt)部(M)名稱(N)，(COMMACATEGORY)\n",
      "在(P)海(N)上(N)二(DET)日(M)當(P)\u001b[31;46m可(ADV)\u001b[0m休息(Vi)也(T)。(PERIODCATEGORY)\n",
      "始(ADV)出席(Vt)之(T)決議(N)似(ADV)\u001b[31;46m可(ADV)\u001b[0m修正(Vt)，(COMMACATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m至(P)廣州(N)辦公(Nv)，(COMMACATEGORY)\n",
      "亦(ADV)\u001b[31;46m可(ADV)\u001b[0m到(Vt)廣州(N)，(COMMACATEGORY)\n",
      "並(C)\u001b[31;46m可(ADV)\u001b[0m依(P)憲法(N)第五十七(DET)條(M)第二(DET)項(M)之(T)職權(N)，(COMMACATEGORY)\n",
      "李(N)對(P)人(N)表示(Vt)內閣(N)\u001b[31;46m可(ADV)\u001b[0m改組(Vi)，(COMMACATEGORY)\n",
      "每(DET)月(N)\u001b[31;46m可(ADV)\u001b[0m增(Vt)發(Vt)一(DET)倍(N)，(COMMACATEGORY)\n",
      "德公(N)並(C)云岳軍(N)\u001b[31;46m可(ADV)\u001b[0m來(Vi)京(N)一(DET)行(N)。(PERIODCATEGORY)\n",
      "要(ADV)使(Vt)經濟(N)平等(Vi)才(ADV)\u001b[31;46m可(ADV)\u001b[0m收拾(Vt)人心(N)，(COMMACATEGORY)\n",
      "而(C)鬥爭(Vt)之(T)目標(N)亦(ADV)\u001b[31;46m可(ADV)\u001b[0m明瞭(Vt)。(PERIODCATEGORY)\n",
      "我(N)建議(Vt)在(P)立院(N)開會(Vi)時(POST)\u001b[31;46m可(ADV)\u001b[0m約(ADV)集(Vt)志同道合(Vi)者(N)談談(Vt)，(COMMACATEGORY)\n",
      "如(P)蔣公(N)\u001b[31;46m可(ADV)\u001b[0m尊重(Vt)我(N)等(Vt)意見(N)則(ADV)擁戴(Vt)之(T)，(COMMACATEGORY)\n",
      "蔣公(N)如(P)能(ADV)實行(Vt)一(DET)個(M)亦(ADV)\u001b[31;46m可(ADV)\u001b[0m治國(Vi)，(COMMACATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m藉(P)此(DET)擴充(Vt)自己(N)勢力(N)，(COMMACATEGORY)\n",
      "正(ADV)\u001b[31;46m可(ADV)\u001b[0m藉(P)共黨(N)之(T)過江(N)以(P)消除(Vt)之(T)，(COMMACATEGORY)\n",
      "自然(N)形勢(N)\u001b[31;46m可(ADV)\u001b[0m轉好(Vt)，(COMMACATEGORY)\n",
      "大權(N)自(ADV)\u001b[31;46m可(ADV)\u001b[0m集中(Vt)於(P)一(DET)人(N)也(T)。(PERIODCATEGORY)\n",
      "更(ADV)\u001b[31;46m可(ADV)\u001b[0m不成(Vi)問題(N)，(COMMACATEGORY)\n",
      "渠(N)亦(ADV)\u001b[31;46m可(ADV)\u001b[0m做(Vt)。(PERIODCATEGORY)\n",
      "惟(ADV)須(ADV)洪蘭友(N)去(ADV)信(Vt)始(ADV)\u001b[31;46m可(ADV)\u001b[0m發表(Vt)，(COMMACATEGORY)\n",
      "此(DET)事(N)\u001b[31;46m可(ADV)\u001b[0m由(P)兩(DET)人(N)當面(ADV)洽妥(Vt)也(T)。(PERIODCATEGORY)\n",
      "不獨(C)外國(N)無(Vt)處(N)\u001b[31;46m可(ADV)\u001b[0m去(Vt)，(COMMACATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m亭(N)不(ADV)贊成(Vt)此(DET)意見(N)，(COMMACATEGORY)\n",
      "應(ADV)如何(ADV)\u001b[31;46m可(ADV)\u001b[0m守(Vt)江(N)，(COMMACATEGORY)\n",
      "明日(N)\u001b[31;46m可(ADV)\u001b[0m辦妥(Vt)手續(N)，(COMMACATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m告(ADV)無罪(Vi)於(P)國人(N)也(ADV)」(PARENTHESISCATEGORY)。(PERIODCATEGORY)\n",
      "適之(N)\u001b[31;46m可(ADV)\u001b[0m說明(Vt)其(DET)意見(N)，(COMMACATEGORY)\n",
      "使(Vt)恩伯(N)亦(ADV)\u001b[31;46m可(ADV)\u001b[0m了解(Vt)外間(N)之(T)空氣(N)。(PERIODCATEGORY)\n",
      "包山(N)\u001b[31;46m可(ADV)\u001b[0m云亂雜無章(N)，(COMMACATEGORY)\n",
      "生活(N)簡陋(Vi)\u001b[31;46m可(ADV)\u001b[0m知(Vt)，(COMMACATEGORY)\n",
      "何君(N)當(P)\u001b[31;46m可(ADV)\u001b[0m提出(Vt)復議(Vt)，(COMMACATEGORY)\n",
      "我(N)當(ADV)\u001b[31;46m可(ADV)\u001b[0m幫忙(Vt)，(COMMACATEGORY)\n",
      "飛機(N)\u001b[31;46m可(ADV)\u001b[0m載重(Vi)四(DET)噸(M)，(COMMACATEGORY)\n",
      "此(DET)機(N)原來(ADV)二小時(N)三(DET)刻(M)\u001b[31;46m可(ADV)\u001b[0m到(Vt)臺(N)，(COMMACATEGORY)\n",
      "今晚(N)\u001b[31;46m可(ADV)\u001b[0m返(Vt)。(PERIODCATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m一(DET)面辦(N)週刊(N)，(COMMACATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m云(Vt)全部(DET)不(ADV)贊成(Vt)，(COMMACATEGORY)\n",
      "汽車(N)二十餘(DET)分鐘(M)\u001b[31;46m可(ADV)\u001b[0m達(Vt)，(COMMACATEGORY)\n",
      "\u001b[31;46m可(ADV)\u001b[0m同時(N)出(Vt)週刊(N)。(PERIODCATEGORY)\n",
      "一切(DET)煩惱(N)當(ADV)\u001b[31;46m可(ADV)\u001b[0m自(P)去(Vt)。(PERIODCATEGORY)\n",
      "並(C)說(Vt)\u001b[31;46m可(ADV)\u001b[0m約(Vt)蔣廷黻(N)及(C)陳通伯(N)參加(Vt)。(PERIODCATEGORY)\n",
      "接受(Vt)投降(Nv)條件(N)\u001b[31;46m可(ADV)\u001b[0m代(P)其(DET)負(Vt)一(DET)部分(DET)責任(N)。(PERIODCATEGORY)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-acd4df1babbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mverb_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mverb_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                         print (''.join(sentence.text.split()))'''\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#找出符合要求的句子(重複句沒抓) one\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import time\n",
    "from colorama import init\n",
    "\n",
    "modalverb = [\"應\",\"要\",\"可\",\"能\",\"可以\",\"須\",\"應該\",\"必須\",\"會\",\"得\",\"需要\",\"當\",\"應當\",\"能夠\",\"該\",\"需\"]\n",
    "file_path = \"C:/Users/user/Desktop/temp/\"\n",
    "file_list = []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    file_list.append(file)\n",
    "\n",
    "find = '可(ADV)'   \n",
    "    \n",
    "for file in file_list:\n",
    "    tree = ET.parse(file_path+file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for child in root:\n",
    "        for sentence in child[8]:\n",
    "            if len(sentence.attrib) == 0:\n",
    "                temp = sentence.text.split()\n",
    "                \n",
    "                lis = []\n",
    "                \n",
    "                if find in temp:\n",
    "                    for ch in temp:\n",
    "                        if ch == find:\n",
    "                            lis.append('\\033[31;46m' + ch + '\\033[0m') \n",
    "                        else:\n",
    "                            lis.append(ch)\n",
    "                    print (''.join(lis))\n",
    "\n",
    "                '''for i in temp:\n",
    "\n",
    "                    word = i.split('(')\n",
    "                    word[1] = '('+word[1].split('[')[0]\n",
    "\n",
    "                    if word[0] in modalverb:\n",
    "                        verb_list.append(''.join(word))\n",
    "                        verb_index.append(vi)\n",
    "\n",
    "                    vi = vi + 1\n",
    "                    \n",
    "                if len(verb_list) == 2:\n",
    "                    if verb_list[0] == find[0] and verb_list[1] == find[1]:\n",
    "                        print (''.join(sentence.text.split()))'''\n",
    "        time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "故(C)盼(Vt)我(N)任(Vt)該(DET)會(N)之(T)秘書長(N)，(COMMACATEGORY)\n",
      "予(ADV)係(Vt)該(DET)會(N)主任(N)委員(N)，(COMMACATEGORY)\n",
      "故(C)今日(N)會議(N)請(Vt)該(DET)會(N)秘書長(N)洪蘭友(N)出席(Vt)。(PERIODCATEGORY)\n",
      "據(P)勻田云(Vi)在(P)該(DET)黨(N)中委(N)談話(N)會(N)中(POST)，(COMMACATEGORY)\n",
      "決定(Vt)本(DET)月(N)底(POST)結束(Vt)該(DET)會(N)，(COMMACATEGORY)\n",
      "謂(Vt)該(DET)會(N)份子(N)複雜(Vi)，(COMMACATEGORY)\n",
      "渠(N)囑(Vt)我(N)做(Vt)該(DET)會(N)之(T)秘書長(N)。(PERIODCATEGORY)\n",
      "他(N)接到(Vt)該(DET)會(N)總幹事(N)陳魯仲(N)一(DET)張(M)油印品(N)，(COMMACATEGORY)\n",
      "該(DET)會(N)欠款(N)三十萬(DET)元(M)，(COMMACATEGORY)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4eca60d72921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\envs\\py34\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(source, parser)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     \"\"\"\n\u001b[0;32m   1185\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m     \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\envs\\py34\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, source, parser)\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m             \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#找出符合要求的句子(重複句沒抓) two\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import time\n",
    "\n",
    "modalverb = [\"應\",\"要\",\"可\",\"能\",\"可以\",\"須\",\"應該\",\"必須\",\"會\",\"得\",\"需要\",\"當\",\"應當\",\"能夠\",\"該\",\"需\"]\n",
    "file_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\SNA\\\\meeting\\\\source\\\\diary\\\\\"\n",
    "file_list = []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    file_list.append(file)\n",
    "\n",
    "find = ['該(DET)', '會(N)']    \n",
    "    \n",
    "for file in file_list:\n",
    "    tree = ET.parse(file_path+file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for child in root:\n",
    "        for sentence in child[8]:\n",
    "            if len(sentence.attrib) == 0:\n",
    "                temp = sentence.text.split()\n",
    "                \n",
    "                verb_list = []  #情態動詞陣列\n",
    "                verb_index = []  #情態動詞所在位置陣列\n",
    "                \n",
    "                vi = 0 #index計算\n",
    "\n",
    "                for i in temp:\n",
    "\n",
    "                    word = i.split('(')\n",
    "                    word[1] = '('+word[1].split('[')[0]\n",
    "\n",
    "                    if word[0] in modalverb:\n",
    "                        verb_list.append(''.join(word))\n",
    "                        verb_index.append(vi)\n",
    "\n",
    "                    vi = vi + 1\n",
    "                    \n",
    "                if len(verb_list) == 2:\n",
    "                    if verb_list[0] == find[0] and verb_list[1] == find[1]:\n",
    "                        print (''.join(sentence.text.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810901\n"
     ]
    }
   ],
   "source": [
    "#雷震日記內容匯出及抓取\n",
    "import xlrd\n",
    "import codecs\n",
    "import time\n",
    "\n",
    "file = \"C:/Users/user/Desktop/雷震日記全表單-資訊處理-20160329.xls\"\n",
    "book = xlrd.open_workbook(file)\n",
    "\n",
    "sh = book.sheet_by_index(0)\n",
    "\n",
    "num = 0\n",
    "\n",
    "with codecs.open(\"C:/Users/user/Desktop/雷震日記.txt\",'w','utf8') as f:\n",
    "    for rx in range(sh.nrows):\n",
    "        if rx == 0:\n",
    "            continue\n",
    "        content = sh.cell_value(rowx=rx, colx=8)\n",
    "        num = num + len(''.join(content.strip().split())) #1856456/1868713/1810901 strip/no_strip/strip&split \n",
    "        f.write(''.join(content.strip().split())+'\\r\\n')\n",
    "        f.write('\\r\\n')\n",
    "print (num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\n"
     ]
    }
   ],
   "source": [
    "#修正雷震日記XML部分斷詞失敗問題\n",
    "from xml.etree import ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, SubElement, ElementTree\n",
    "import xlrd\n",
    "import time\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "from ckip import CKIPSegmenter, CKIPParser\n",
    "segmenter = CKIPSegmenter('104753018', 'sayanouta')\n",
    "\n",
    "file = \"C:/Users/user/Desktop/雷震日記全表單-資訊處理-20160329.xls\"\n",
    "input_file = \"C:/Users/user/Desktop/diary/\"\n",
    "book = xlrd.open_workbook(file)\n",
    "sh = book.sheet_by_index(0)\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for file in os.listdir(input_file):\n",
    "    file_list.append(file)\n",
    "\n",
    "with codecs.open(\"C:/Users/user/Desktop/new.txt\",'w','utf8') as f:\n",
    "    \n",
    "    for file in file_list:\n",
    "\n",
    "        tree = ET.parse(input_file+file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for article in root:\n",
    "\n",
    "            index = int(article.get('no'))\n",
    "            content = sh.cell_value(rowx=index, colx=8)\n",
    "\n",
    "            lines = []\n",
    "            temp = ''\n",
    "\n",
    "            for word in content:\n",
    "                temp = temp + word\n",
    "                if word == '。' or word == '，':\n",
    "                    lines.append(temp.strip())\n",
    "                    temp = ''\n",
    "\n",
    "            num = len(article[8])\n",
    "\n",
    "            if len(lines) != num:\n",
    "                print (file,index,len(lines),num)\n",
    "                \n",
    "                f.write(file+' no.'+str(index)+'\\r\\n')\n",
    "\n",
    "                for line in lines:\n",
    "                    \n",
    "                    try:\n",
    "                        segmented_result = segmenter.process(line)\n",
    "\n",
    "                        words = []\n",
    "                        check = False\n",
    "\n",
    "                        if segmented_result['status_code'] != '0':\n",
    "                                print ('Process Failed: ' + segmented_result['status'])\n",
    "                        else:\n",
    "                            for sentences in segmented_result['result']:\n",
    "                                for term in sentences:\n",
    "                                    if term['pos'] == 'QUESTIONCATEGORY':\n",
    "                                        check = True\n",
    "                                    words.append(term['term']+'('+term['pos']+')')\n",
    "\n",
    "                            if check:\n",
    "                                f.write('古字：'+line+'\\r\\n')\n",
    "                            else:\n",
    "                                f.write(' '.join(words)+'\\r\\n')\n",
    "                    except:\n",
    "                        f.write('斷詞失敗：'+line+'\\r\\n')\n",
    "                \n",
    "                f.write('\\r\\n')\n",
    "    print ('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "p = IntProgress()\n",
    "p.max = 16\n",
    "p.description = 'start'\n",
    "display(p)\n",
    "\n",
    "#modalverb = [\"應\",\"要\",\"可\",\"能\",\"可以\",\"須\",\"應該\",\"必須\",\"會\",\"得\",\"需要\",\"當\",\"應當\",\"能夠\",\"該\",\"需\"]\n",
    "modalverb = [\"應\",\"要\",\"可\",\"能\",\"可以\",\"須\",\"應該\",\"必須\",\"會\",\"得\",\"需要\",\"當\",\"應當\",\"能夠\",\"該\",\"需\"]\n",
    "file_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\SNA\\\\meeting\\\\source\\\\diary\\\\\"\n",
    "out_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\diary_word\\\\\"\n",
    "file_list = []\n",
    "count = 0\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    file_list.append(file)\n",
    "\n",
    "for find in modalverb: \n",
    "\n",
    "    dic = {}\n",
    "    sen = {}\n",
    "\n",
    "    for file in file_list:\n",
    "        tree = ET.parse(file_path+file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for child in root:\n",
    "            for sentence in child[8]:\n",
    "                if len(sentence.attrib) == 0:\n",
    "                    temp = sentence.text.split()\n",
    "\n",
    "                    index = 0\n",
    "                    pairs = []\n",
    "\n",
    "                    for word in temp:\n",
    "\n",
    "                        words = word.split('(')\n",
    "                        words[1] = '('+words[1]\n",
    "\n",
    "                        if words[0] == find:\n",
    "                            '''if index != 0:\n",
    "                                pairs.append((index-1,index))'''\n",
    "                            if index != len(temp)-1:\n",
    "                                if temp[index+1].split('(')[1][0] != 'V':\n",
    "                                    if temp[index+1].split('(')[1][:-1] != 'COMMACATEGORY' and  \\\n",
    "                                        temp[index+1].split('(')[1][:-1] != 'PERIODCATEGORY':\n",
    "                                        pairs.append((index,index+1))\n",
    "\n",
    "                        index += 1\n",
    "\n",
    "                    for i in pairs:\n",
    "                        if temp[i[0]]+temp[i[1]] not in dic:\n",
    "                            dic[temp[i[0]]+temp[i[1]]] = 1\n",
    "                        else:\n",
    "                            dic[temp[i[0]]+temp[i[1]]] += 1\n",
    "                        \n",
    "                        if temp[i[0]]+temp[i[1]] not in sen:\n",
    "                            sen[temp[i[0]]+temp[i[1]]] = [''.join(temp)]\n",
    "                        elif len(sen[temp[i[0]]+temp[i[1]]]) < 3:\n",
    "                            sen[temp[i[0]]+temp[i[1]]].append(''.join(temp))\n",
    "\n",
    "    dic = sorted(dic.items(), key=lambda d:d[1], reverse = True)\n",
    "    with codecs.open(out_path+find+'.txt','wb','utf8') as f:\n",
    "        for i in dic:\n",
    "            #print (i[0],i[1])\n",
    "            f.write(str(i[0])+str(i[1])+'\\r\\n')\n",
    "            for j in sen[i[0]]:\n",
    "                f.write(j+'\\r\\n')\n",
    "            f.write('\\r\\n')\n",
    "            \n",
    "    count = count + 1\n",
    "    p.value = count\n",
    "    p.description = str(count)\n",
    "p.description = 'end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "p = IntProgress()\n",
    "p.max = 945\n",
    "p.description = 'start'\n",
    "display(p)\n",
    "\n",
    "modalverb = [\"應\",\"要\",\"可\",\"能\",\"可以\",\"須\",\"應該\",\"必須\",\"會\",\"得\",\"需要\",\"當\",\"應當\",\"能夠\",\"該\",\"需\"]\n",
    "file_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\SNA\\\\meeting\\\\source\\\\diary\\\\\"\n",
    "out_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\\"\n",
    "file_list = []\n",
    "count = 0\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    file_list.append(file)\n",
    "\n",
    "dic = {}\n",
    "sen = {}\n",
    "\n",
    "for file in file_list:\n",
    "    tree = ET.parse(file_path+file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for child in root:\n",
    "        for sentence in child[8]:\n",
    "            if len(sentence.attrib) == 0:\n",
    "                temp = sentence.text.split()\n",
    "\n",
    "                index = 0\n",
    "                pairs = []\n",
    "\n",
    "                for word in temp:\n",
    "\n",
    "                    words = word.split('(')\n",
    "                    words[1] = '('+words[1]\n",
    "\n",
    "                    if words[0] in modalverb:\n",
    "                        '''if index != 0:\n",
    "                            pairs.append((index-1,index))'''\n",
    "                        if index != len(temp)-1:\n",
    "                            if (temp[index+1].split('(')[1][0] == 'V' or temp[index+1].split('(')[1][0] == 'A' or \\\n",
    "                               temp[index+1].split('(')[1][0] == 'P') and (words[1] == '(V)' or words[1] == '(ADV)'):\n",
    "                                if temp[index+1].split('(')[1][:-1] != 'COMMACATEGORY' and  \\\n",
    "                                    temp[index+1].split('(')[1][:-1] != 'PERIODCATEGORY':\n",
    "                                    pairs.append(temp[index])\n",
    "\n",
    "                    index += 1\n",
    "\n",
    "                if len(pairs) > 1:\n",
    "                        \n",
    "                    for i in range(len(pairs)-1):    \n",
    "                        \n",
    "                        term = pairs[i]+'_'+pairs[i+1]\n",
    "\n",
    "                        if term not in dic:\n",
    "                            dic[term] = 1\n",
    "                        else:\n",
    "                            dic[term] += 1\n",
    "\n",
    "                        if term not in sen:\n",
    "                            sen[term] = [''.join(temp)]\n",
    "                        elif len(sen[term]) < 3:\n",
    "                            sen[term].append(''.join(temp))\n",
    "    count = count + 1\n",
    "    p.value = count\n",
    "    p.description = str(count)\n",
    "\n",
    "dic = sorted(dic.items(), key=lambda d:d[1], reverse = True)\n",
    "with codecs.open(out_path+'output.txt','wb','utf8') as f:\n",
    "    for i in dic:\n",
    "        #print (i[0],i[1])\n",
    "        f.write(str(i[0])+' '+str(i[1]))\n",
    "        '''for j in sen[i[0]]:\n",
    "            f.write(j+'\\r\\n')'''\n",
    "        f.write('\\r\\n')\n",
    "        \n",
    "p.description = 'end'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
